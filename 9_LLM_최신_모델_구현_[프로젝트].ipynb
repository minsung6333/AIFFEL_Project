{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/minsung6333/AIFFEL_Project/blob/main/9_LLM_%EC%B5%9C%EC%8B%A0_%EB%AA%A8%EB%8D%B8_%EA%B5%AC%ED%98%84_%5B%ED%94%84%EB%A1%9C%EC%A0%9D%ED%8A%B8%5D.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LLM 최신 모델 구현\n",
        "KoChatGPT 소스코드를 바탕으로 다양한 모델 개선 전략을 선택해 여러분만의 custom ChatGPT를 개발해보세요.\n",
        "\n",
        "\n",
        "> 1. 우리가 지난시간 살펴본 KoChatGPT 모델에 사용한 데이터셋은 아직 완벽히 정제되지 않았습니다.\n",
        "> 2. Hunman Feedback이 반영된 데이터셋을 대체하기 위해 SFT와 RM 모델에 사용할 다양한 benchmark 데이터셋도 검토해볼 수 있습니다.\n",
        ">3. 언어모델의 생성능력을 좌우하는 최선의 디코딩을 위한 하이퍼파라미터 서치가 필요합니다.\n",
        "> 4. 생성된 답변에 대한 주관적인 평가를 보완할 수 있는 정량적인 메트릭은 도입하지 않았었습니다.\n",
        ">5. LLM Trend Note1에서 살펴본 다양한 Instruction Tuning 및 Prompting 기법들도 적용해볼만 합니다.\n",
        ">6. 무엇보다 foundation model로 사용한 KoGPT-2는 Emergent abilities를 기대하기엔 다소 작은 사이즈의 모델입니다.\n",
        "더 큰 파라미터 스케일을 가진 모델을 사용해보거나,\n",
        ">7. 더 효율적인 연산을 수행할 수 있는 LoRA의 적용 또는\n",
        "새로운 Instruction Tuning 및 reward ranking 알고리즘을 도입해볼 수도 있습니다.\n",
        "\n"
      ],
      "metadata": {
        "id": "E-BXye44dm9b"
      },
      "id": "E-BXye44dm9b"
    },
    {
      "cell_type": "markdown",
      "source": [
        "기존 데이터셋 추가 정제\n",
        "data_kochatgpt 폴더에는 세 파일이 있습니다.\n",
        "\n",
        "ㄱ. kochatgpt_1_SFT.jsonl : SFT를 위한 prompt와 completion 문장셋\n",
        "\n",
        "ㄴ. kochatgpt_1_RM.jsonl : RM 학습을 위한 prompt와 세 가지 ranking 문장셋\n",
        "\n",
        "ㄷ. kochatgpt_1_PPO.jsonl : promt 문장\n",
        "\n",
        "각 말뭉치를 EDA하여 도메인과 문체, 길이분포, 문장의 완성도 등을 분석합니다. 언어모델의 문장생성능력은 말뭉치의 전처리 수준에 큰 영향을 받습니다. 말뭉치의 분석결과를 토대로 데이터를 정제하여 모델을 재학습시켜봅니다. (정제후 데이터셋 크기가 줄어들지 않도록, 다양한 augmentation 기법을 활용하여 크기를 유지 내지 증량합니다.) 추가 전처리 후, 기존 인퍼런스 결과와 성능을 비교해봅니다. (주관적인 평가와 BLEU, ROUGE 등을 활용한 정량적인 평가 결과를 비교 분석하여 제시합니다.)"
      ],
      "metadata": {
        "id": "GlSNH0TsdvOM"
      },
      "id": "GlSNH0TsdvOM"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 새로운 데이터셋 추가\n",
        "KoChatGPT는 human feedback이 반영된 데이터를 직접 사용하는 대신\n",
        "ChatGPT API를 사용하는 대안을 선택했습니다.\n",
        "LLM Trend Note1 에서 살펴보았듯이\n",
        "Anthropic의 RLHF는 StackExchange 같은 온라인 상의 댓글정보를 활용하여\n",
        "ranking dataset을 구축해 구현되었습니다.\n",
        "우리도 비슷한 로직을 적용해볼 수 있습니다.\n",
        "\n",
        "하나의 prompt에 대한 다양한 수준의 품질로 댓글이 달린 한국어로 된 웹사이트를 찾아봅시다.\n",
        "웹크롤링 기법을 사용해 reward 점수를 차등적으로 적용해볼 수 있는\n",
        "instruction dataset과 ranking dataset을 구축해봅니다.\n",
        "\n",
        "KorQuAD 2.0 같은 한국어 이해 benchmark를 활용해 고품질의 데이터셋을 확보하고,\n",
        "KoGPT-2를 사용해 빠르게 저품질 데이터셋을 페어링해볼 수도 있습니다.\n",
        "다양한 데이터 증량전략을 구사하여 기존 데이터셋에 새로 구축한 데이터셋을 추가해\n",
        "모델을 재학습시키고 추론 결과를 비교하 분석하여 제시해보세요."
      ],
      "metadata": {
        "id": "0nfgStWtdyue"
      },
      "id": "0nfgStWtdyue"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## foundation model 교체\n",
        "현재 제공되는 LMS GPU 사양으로는 수십 billion 단위 이상의 LLM을 튜닝하기 어렵습니다.\n",
        "그러나 허깅페이스에서 제공하는 큰 규모의 모델을 적은 컴퓨팅 자원으로도 사용할 수 있게 해주는\n",
        "경량화, 최적화 라이브러리를 사용하면\n",
        "속도는 느리지만 우리의 LMS에서도 학습 및 추론이 가능해질 수 있습니다.\n",
        "(힌트 : LLM Trend Note1 노드의 마지막 스텝을 참고해보세요)\n",
        "\n",
        "허깅페이스에서 제공되는 1.2B 사이즈의 한국어 GPT pretrain model로 skt/ko-gpt-trinity-1.2B-v0.5 가 있습니다.\n",
        "해당 모델로 foundation model을 교체해보세요.\n",
        "(단 OOM 문제를 해소하기 위해 허깅페이스에서 제공하는\n",
        "다양한 training argument들을 조합하여 최상의 하이퍼파라미터를 찾아내야 합니다.)\n",
        "데이터셋을 아예 바꿔 모델 선택의 폭을 늘려보는 것도 좋은 선택지입니다.\n",
        "\n",
        "foundation model 교체에 성공했다면, generator 함수를 수정하여 모델 인퍼런스 결과를 제시해보세요.\n",
        "\n",
        "참고\n",
        "LLM Trend Note2 노드에서 살펴본 KoChatGPT 소스코드는\n",
        "빠르게 baseline모델을 설계해 실습해보기 위해 오리지널 코드를 일부 수정한 버전입니다.\n",
        "프로젝트 진행을 위해 모델을 커스터마이징할 때, 필요시 \"colossalai_ChatGPT_230319\" 폴더 내의 원본 스크립트들을 참고하세요."
      ],
      "metadata": {
        "id": "s0sYUy4Rd1wN"
      },
      "id": "s0sYUy4Rd1wN"
    },
    {
      "cell_type": "markdown",
      "id": "9501dcae",
      "metadata": {
        "id": "9501dcae"
      },
      "source": [
        "루브릭\n",
        "1. 기존 데이터셋을 추가 정제하고, generation 성능을 끌어올리기 위한 기법들을 실험해 모델 perfomance를 향상시켜보았는가?\n",
        "- 기존 데이터셋의 문제점을 분석하고 전처리 전략을 수립해 추가 정제를 진행했다. Beam search, Top-k(p) sampling 등 최선의 디코딩 전략을 수립해 향상된 모델 추론 결과를 제시했다. BLEU, ROUGE 등 생성된 텍스트를 평가하기 위한 메트릭을 적용한 정량적인 평가 결과와 주관적인 평가를 비교분석하였다.\n",
        "\n",
        "2. 새로운 데이터를 수집해 전처리를 수행하여 모델을 재학습시켜보았는가?\n",
        "\n",
        "- 모두의 말뭉치, AI hub 등에 공개된 데이터를 사용해 추가 데이터셋을 구축하기 위한 기준과 근거를 수립했다. ChatGPT API나 다양한 한국어 benchmark 데이터셋을 활용해 Human Feedback 을 대체할 수 있는 아이디어를 구현했다. 위를 바탕으로 SFT, RM, PPO 세 단계에 필요한 각 데이터셋을 적절히 구축하여, 모델 추론 결과와 수립한 가설을 비교해보았다.\n",
        "\n",
        "\n",
        "3. 학습 전략 또는 foundation model을 변경해 모델을 재학습시켜보았는가?\n",
        "- 더 적절한 Instruction Tuning 기법을 적용해 SFT를 해보거나, Reward Model의 ranking algorithm을 개선해보았다. KoGPT-2가 아닌 다른 모델을 initial model로 사용하여 모델 학습을 성공시켰다. 허깅페이스의 accelerate, bitsandbytes 라이브러리 등을 사용하여 더 큰 스케일의 모델로 ChatGPT를 re-building해 모델 성능을 향상시켰다"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "54323927",
      "metadata": {
        "id": "54323927"
      },
      "source": [
        "# Related Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "268f1a82",
      "metadata": {
        "id": "268f1a82"
      },
      "outputs": [],
      "source": [
        "!pip install chatgpt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cd7f4695",
      "metadata": {
        "id": "cd7f4695"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset\n",
        "from torch.optim import Adam\n",
        "from datasets import load_dataset\n",
        "import transformers\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
        "from transformers import Trainer, TrainingArguments\n",
        "from copy import deepcopy\n",
        "import copy\n",
        "import logging\n",
        "import json\n",
        "from dataclasses import dataclass\n",
        "# Proximal Policy Optimization (PPO)\n",
        "from copy import deepcopy\n",
        "#from chatgpt.models.base import RewardModel\n",
        "#from chatgpt.models.gpt import GPTActor, GPTCritic\n",
        "#from chatgpt.trainer import PPOTrainer\n",
        "#from chatgpt.trainer.strategies import NaiveStrategy\n",
        "from transformers import AutoTokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "203f4e4e",
      "metadata": {
        "id": "203f4e4e"
      },
      "outputs": [],
      "source": [
        "model_name = \"skt/kogpt2-base-v2\"\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
        "tokenizer = AutoTokenizer.from_pretrained(\n",
        "    model_name, bos_token='</s>', eos_token='</s>', unk_token='</s>', pad_token='</s>',\n",
        "    padding_side=\"right\",\n",
        "    model_max_length=512,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e7592412",
      "metadata": {
        "id": "e7592412",
        "outputId": "15ff5541-5ba1-47e4-b6af-353aa91dd008"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GPT2TokenizerFast(name_or_path='skt/kogpt2-base-v2', vocab_size=51200, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '</s>', 'eos_token': '</s>', 'unk_token': '</s>', 'pad_token': '</s>'}, clean_up_tokenization_spaces=True)\n"
          ]
        }
      ],
      "source": [
        "print(tokenizer)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "22948e26",
      "metadata": {
        "id": "22948e26"
      },
      "source": [
        "# SFT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dbee4114",
      "metadata": {
        "id": "dbee4114"
      },
      "outputs": [],
      "source": [
        "from typing import Optional, Dict, Sequence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e8b6272d",
      "metadata": {
        "id": "e8b6272d"
      },
      "outputs": [],
      "source": [
        "class SFT_dataset(Dataset):\n",
        "\n",
        "    def __init__(self, data_path_1_SFT: str, tokenizer: transformers.PreTrainedTokenizer, verbose=False):\n",
        "        super(SFT_dataset, self).__init__()\n",
        "        logging.warning(\"Loading data...\")\n",
        "\n",
        "        pattern_instruction = 'prompt'  # instruction\n",
        "        pattern_output = 'completion'  # response\n",
        "\n",
        "        data_path_1_SFT = '/aiffel/KoChatGPT/data_kochatgpt/kochatgpt_1_SFT.jsonl'\n",
        "        with open(data_path_1_SFT, \"r\", encoding='utf-8-sig') as json_file:\n",
        "            list_data_dict = json.load(json_file)\n",
        "\n",
        "        PROMPT_DICT = {\n",
        "            \"prompt_input\": (\n",
        "                \"### Instruction(명령어):\\n{prompt}\\n\\n### Response(응답):\"\n",
        "            )\n",
        "        }\n",
        "\n",
        "        prompt_input = PROMPT_DICT[\"prompt_input\"]\n",
        "\n",
        "        sources = []\n",
        "        for example in list_data_dict:\n",
        "            tmp = prompt_input.format_map(example)\n",
        "            sources.append(tmp)\n",
        "\n",
        "        targets = []\n",
        "        for example in list_data_dict:\n",
        "            targets.append(f\"{example[pattern_output]}{tokenizer.eos_token}\")\n",
        "        examples = [s + t for s, t in zip(sources, targets)]\n",
        "\n",
        "        sources_tokenized = self._tokenize_fn(sources, tokenizer)  # source\n",
        "        examples_tokenized = self._tokenize_fn(examples, tokenizer)  # source + target\n",
        "\n",
        "        input_ids = examples_tokenized[\"input_ids\"]\n",
        "        labels = copy.deepcopy(input_ids)\n",
        "        for label, source_len in zip(labels, sources_tokenized[\"input_ids_lens\"]):\n",
        "            label[:source_len] = -100\n",
        "\n",
        "        data_dict = dict(input_ids=input_ids, labels=labels)\n",
        "\n",
        "        self.input_ids = data_dict[\"input_ids\"]\n",
        "        self.labels = data_dict[\"labels\"]\n",
        "        logging.warning(\"Loading data done!!: %d\"%(len(self.labels)))\n",
        "\n",
        "\n",
        "    def _tokenize_fn(self, strings: Sequence[str], tokenizer: transformers.PreTrainedTokenizer) -> Dict:\n",
        "        tokenized_list = [\n",
        "            tokenizer(\n",
        "                text,\n",
        "                return_tensors=\"pt\",\n",
        "                padding=\"longest\",\n",
        "                max_length=tokenizer.model_max_length,\n",
        "                truncation=True,\n",
        "            )\n",
        "            for text in strings\n",
        "        ]\n",
        "        input_ids = labels = [tokenized.input_ids[0] for tokenized in tokenized_list]\n",
        "        input_ids_lens = labels_lens = [\n",
        "            tokenized.input_ids.ne(tokenizer.pad_token_id).sum().item() for tokenized in tokenized_list\n",
        "        ]\n",
        "        return dict(\n",
        "            input_ids=input_ids,\n",
        "            labels=labels,\n",
        "            input_ids_lens=input_ids_lens,\n",
        "            labels_lens=labels_lens,\n",
        "        )\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.input_ids)\n",
        "\n",
        "\n",
        "    def __getitem__(self, i) -> Dict[str, torch.Tensor]:\n",
        "        return dict(input_ids=self.input_ids[i], labels=self.labels[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d11de15d",
      "metadata": {
        "id": "d11de15d"
      },
      "outputs": [],
      "source": [
        "@dataclass\n",
        "class DataCollatorForSupervisedDataset(object):\n",
        "\n",
        "    tokenizer: transformers.PreTrainedTokenizer\n",
        "\n",
        "    def __call__(self, instances: Sequence[Dict]) -> Dict[str, torch.Tensor]:\n",
        "        input_ids, labels = tuple([instance[key] for instance in instances] for key in (\"input_ids\", \"labels\"))\n",
        "        input_ids = torch.nn.utils.rnn.pad_sequence(\n",
        "            input_ids, batch_first=True, padding_value=self.tokenizer.pad_token_id\n",
        "        )\n",
        "        labels = torch.nn.utils.rnn.pad_sequence(labels, batch_first=True, padding_value= -100)\n",
        "        return dict(\n",
        "            input_ids=input_ids,\n",
        "            labels=labels,\n",
        "            attention_mask=input_ids.ne(self.tokenizer.pad_token_id),\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "430322c9",
      "metadata": {
        "id": "430322c9",
        "outputId": "1a06d74f-5e73-49b0-da31-bca2359788ba"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:Loading data...\n",
            "WARNING:root:Loading data done!!: 12000\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "input : tensor([  739,   378,   378,   378, 14659, 13394, 37091, 10651,   383, 25841,\n",
            "         8006, 14914,   375,  7673, 20479,  8091, 22311,  9036, 30902, 13675,\n",
            "          375,   378,   378,   378, 41951,   454,  9549, 20549,   383,  8142,\n",
            "         7192, 14914,   382, 37767, 13753,  8263,  7166,   739,  8352,  7659,\n",
            "         9594, 25585, 13600,  8022,  9378, 11532,  9887, 11218,  9111, 16691,\n",
            "        10351, 10561,  9128, 20479,  8091,  9065,  9446,  9036, 28420, 26521,\n",
            "        10163, 26367,  6958,  9030,  9882, 12317, 25882,  9209, 37194, 10351,\n",
            "         9036, 12168, 10529, 15989,  9719, 15434, 10552, 11188, 13362,  9036,\n",
            "        15805, 11300, 11846,  9146, 16691,  9181,  7397, 15806, 13480, 11342,\n",
            "        17596,  9161, 19996,  9025, 25006, 18595,  9966, 12592, 10751, 11814,\n",
            "         8711,  9046, 12450,  9117,  7377, 12521,     1])\n",
            "output: tensor([ -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
            "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
            "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
            "         -100,  -100,   382, 37767, 13753,  8263,  7166,   739,  8352,  7659,\n",
            "         9594, 25585, 13600,  8022,  9378, 11532,  9887, 11218,  9111, 16691,\n",
            "        10351, 10561,  9128, 20479,  8091,  9065,  9446,  9036, 28420, 26521,\n",
            "        10163, 26367,  6958,  9030,  9882, 12317, 25882,  9209, 37194, 10351,\n",
            "         9036, 12168, 10529, 15989,  9719, 15434, 10552, 11188, 13362,  9036,\n",
            "        15805, 11300, 11846,  9146, 16691,  9181,  7397, 15806, 13480, 11342,\n",
            "        17596,  9161, 19996,  9025, 25006, 18595,  9966, 12592, 10751, 11814,\n",
            "         8711,  9046, 12450,  9117,  7377, 12521,     1])\n"
          ]
        }
      ],
      "source": [
        "train_dataset = SFT_dataset(data_path_1_SFT='./aiffel/KoChatGPT/data_kochatgpt/kochatgpt_1_SFT.jsonl', tokenizer=tokenizer)\n",
        "data_collator = DataCollatorForSupervisedDataset(tokenizer=tokenizer)\n",
        "\n",
        "print('input : %s'%train_dataset.input_ids[0])\n",
        "print('output: %s'%train_dataset.labels[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6632e970",
      "metadata": {
        "id": "6632e970"
      },
      "outputs": [],
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir=\"aiffel/KoChatGPT/test\",\n",
        "    overwrite_output_dir=True,\n",
        "    num_train_epochs=1,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    warmup_steps=5,\n",
        "    prediction_loss_only=True,\n",
        "    fp16 = True\n",
        "    )\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    data_collator=data_collator,\n",
        "    train_dataset=train_dataset\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ec2bdfb1",
      "metadata": {
        "id": "ec2bdfb1",
        "outputId": "360d8af0-94ae-475c-910a-2cdeb602b929"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.9/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1500' max='1500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1500/1500 05:24, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>2.984100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>2.776800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>2.687200</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "trainer.train()\n",
        "model.save_pretrained('/aiffel/KoChatGPT/output_1_SFT')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "68cb03d1",
      "metadata": {
        "id": "68cb03d1"
      },
      "source": [
        "> Evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9aba330a",
      "metadata": {
        "id": "9aba330a"
      },
      "outputs": [],
      "source": [
        "generator = pipeline('text-generation', model='/aiffel/KoChatGPT/output_1_SFT', tokenizer=tokenizer)\n",
        "\n",
        "generation_args = dict(\n",
        "    num_beams=4,\n",
        "    repetition_penalty=2.0,\n",
        "    no_repeat_ngram_size=4,\n",
        "    eos_token_id=375, # \\n\n",
        "    max_new_tokens=64,\n",
        "    do_sample=True,\n",
        "    top_k=50,\n",
        "    early_stopping=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "42092b07",
      "metadata": {
        "id": "42092b07"
      },
      "outputs": [],
      "source": [
        "PROMPT_DICT = {\n",
        "    \"prompt_input\": (\n",
        "        \"### Instruction(명령어):\\n{prompt}\\n\\n### Response(응답):\"\n",
        "    )\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a266ee9d",
      "metadata": {
        "id": "a266ee9d"
      },
      "outputs": [],
      "source": [
        "list_prompt = ['르세라핌 데뷔연도는?',\n",
        "               '미세먼지가 얼마나 심할 때 마스크 씁니까?',\n",
        "               '모두의연구소는 어떤 기업입니까?',\n",
        "               '디지털 헬스케어는 무엇인가요?']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5c215b7c",
      "metadata": {
        "id": "5c215b7c",
        "outputId": "f3711749-5d75-4b78-8fdc-bab212c68078"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.9/site-packages/transformers/generation/utils.py:1219: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation)\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "### Instruction(명령어):\n",
            "르세라핌 데뷔연도는?\n",
            "\n",
            "### Response(응답):'르세라닉 데뷔연도는 2019년입니다.律, 律, 法, 律 등 다양한 분야에서 활동하고 있습니다.律, 法은 정치, 경제, 사회, 문화 등 다양한 분야에서 활약하는 것을 의미합니다.律은 주로 예술 분야에서 활동하며, 법과 律은 영화나 드라마 등에서 많이 사용됩니다.\n",
            "\n",
            "### Instruction(명령어):\n",
            "미세먼지가 얼마나 심할 때 마스크 씁니까?\n",
            "\n",
            "### Response(응답):'미세먼지 농도는 매우 높기 때문에 미세먼지 농도가 높을 때는 마스크를 착용하지 않는 것이 좋습니다. 또한, 미세먼지는 공기 중에 먼지나 오염물질이 쌓이는 것을 말합니다. 따라서 미세먼지를 줄일 수 있는 방법을 찾아보시는 것은 어떨까요?明筆)明\n",
            "\n",
            "### Instruction(명령어):\n",
            "모두의연구소는 어떤 기업입니까?\n",
            "\n",
            "### Response(응답):'저는 인공지능 어시스턴트이기 때문에 모두의연구소에 대한 정보를 가지고 있지 않습니다. 하지만 일반적으로, 모두의연구소는 다양한 분야에서 활동하고 있습니다. 예를 들어, 의료분야에서는 서울대학교병원과 서울아산병원, 국립암센터 등이 있습니다. 또한, 산업 분야에서는 한국전기안전기술원(KEITI), 한국전력\n",
            "\n",
            "### Instruction(명령어):\n",
            "디지털 헬스케어는 무엇인가요?\n",
            "\n",
            "### Response(응답):'디지털 헬스 (Digital Health) 또는 디지털 헬스 (Medicine Health)은 디지털 헬스(Digital Hells)의 약어입니다. 이 용어는 인공지능(AI) 기술을 활용하여 인간의 건강 상태를 평가하고 진단하는 것을 말합니다. 예를 들어, 건강한 식습관과\n"
          ]
        }
      ],
      "source": [
        "list_prompt = [PROMPT_DICT['prompt_input'].format_map({'prompt' : tmp}) for tmp in list_prompt]\n",
        "\n",
        "list_result = generator(list_prompt, **generation_args)\n",
        "for prompt, result in zip(list_prompt, list_result):\n",
        "    print()\n",
        "    print((result[0]['generated_text']))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0456be82",
      "metadata": {
        "id": "0456be82"
      },
      "source": [
        "> 뜬금없이 out-of-context 한자가 나오기도 하고, 틀린 정보다 알려줍니다. 빔서치를 적용했는데, repeat이 응답으로 나왔네요."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c642d9a6",
      "metadata": {
        "id": "c642d9a6"
      },
      "source": [
        "> BLEU Score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6e3a0ae5",
      "metadata": {
        "id": "6e3a0ae5"
      },
      "outputs": [],
      "source": [
        "from nltk.translate.bleu_score import corpus_bleu, sentence_bleu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c4aad5b8",
      "metadata": {
        "id": "c4aad5b8"
      },
      "outputs": [],
      "source": [
        "good_response_label = [\n",
        "    '르세라핌 데뷔연도는 2022년이다.',\n",
        "    '마스크 착용 기준은 명확하게 있지는 않습니다. 하지만, 일반적으로 미세먼지 농도가 PM10 기준으로 81㎍/㎥ 이상, PM2.5 기준으로 36㎍/㎥ 이상일 때는 마스크를 착용하는 것이 좋다고 권고하고 있습니다.',\n",
        "    '모두의연구소는 인공지능(AI)과 관련된 교육과 연구를 하는 커뮤니니티 기업입니다',\n",
        "    '디지털 헬스케어는 의료 서비스 제공과 결과를 개선하기 위해 디지털 기술을 사용하는 것을 가리키는 용어입니다.  세계보건기구(WHO)에 따르면 디지털 의료는 \"정보 및 통신 기술(ICT)을 사용하여 의료 서비스를 제공하고, 의료 시스템 관리를 지원하고, 사람들이 건강 정보에 액세스할 수 있도록 하고, 건강한 라이프스타일을 장려하고, 과학적 지식을 생성하는 것\"이라고 정의합니다.'\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9b5db5fa",
      "metadata": {
        "id": "9b5db5fa",
        "outputId": "b5e72c6c-9a61-4fc2-8ed9-1d6a15fc73e2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Q. 르세라핌 데뷔연도는?\n",
            "\n",
            "G. '르세라닉 데뷔연도는 2019년입니다.律, 律, 法, 律 등 다양한 분야에서 활동하고 있습니다.律, 法은 정치, 경제, 사회, 문화 등 다양한 분야에서 활약하는 것을 의미합니다.律은 주로 예술 분야에서 활동하며, 법과 律은 영화나 드라마 등에서 많이 사용됩니다.\n",
            "\n",
            "A. 르세라핌 데뷔연도는 2022년이다.\n",
            "\n",
            "1-Gram BLEU : 0\n",
            "2-Gram BLEU : 0\n",
            "3-Gram BLEU : 0\n",
            "4-Gram BLEU : 0\n",
            "--------------------------------------------------\n",
            "Q. 미세먼지가 얼마나 심할 때 마스크 씁니까?\n",
            "\n",
            "G. '미세먼지 농도는 매우 높기 때문에 미세먼지 농도가 높을 때는 마스크를 착용하지 않는 것이 좋습니다. 또한, 미세먼지는 공기 중에 먼지나 오염물질이 쌓이는 것을 말합니다. 따라서 미세먼지를 줄일 수 있는 방법을 찾아보시는 것은 어떨까요?明筆)明\n",
            "\n",
            "A. 마스크 착용 기준은 명확하게 있지는 않습니다. 하지만, 일반적으로 미세먼지 농도가 PM10 기준으로 81㎍/㎥ 이상, PM2.5 기준으로 36㎍/㎥ 이상일 때는 마스크를 착용하는 것이 좋다고 권고하고 있습니다.\n",
            "\n",
            "1-Gram BLEU : 0\n",
            "2-Gram BLEU : 0\n",
            "3-Gram BLEU : 0\n",
            "4-Gram BLEU : 0\n",
            "--------------------------------------------------\n",
            "Q. 모두의연구소는 어떤 기업입니까?\n",
            "\n",
            "G. '저는 인공지능 어시스턴트이기 때문에 모두의연구소에 대한 정보를 가지고 있지 않습니다. 하지만 일반적으로, 모두의연구소는 다양한 분야에서 활동하고 있습니다. 예를 들어, 의료분야에서는 서울대학교병원과 서울아산병원, 국립암센터 등이 있습니다. 또한, 산업 분야에서는 한국전기안전기술원(KEITI), 한국전력\n",
            "\n",
            "A. 모두의연구소는 인공지능(AI)과 관련된 교육과 연구를 하는 커뮤니니티 기업입니다\n",
            "\n",
            "1-Gram BLEU : 0\n",
            "2-Gram BLEU : 0\n",
            "3-Gram BLEU : 0\n",
            "4-Gram BLEU : 0\n",
            "--------------------------------------------------\n",
            "Q. 디지털 헬스케어는 무엇인가요?\n",
            "\n",
            "G. '디지털 헬스 (Digital Health) 또는 디지털 헬스 (Medicine Health)은 디지털 헬스(Digital Hells)의 약어입니다. 이 용어는 인공지능(AI) 기술을 활용하여 인간의 건강 상태를 평가하고 진단하는 것을 말합니다. 예를 들어, 건강한 식습관과\n",
            "\n",
            "A. 디지털 헬스케어는 의료 서비스 제공과 결과를 개선하기 위해 디지털 기술을 사용하는 것을 가리키는 용어입니다.  세계보건기구(WHO)에 따르면 디지털 의료는 \"정보 및 통신 기술(ICT)을 사용하여 의료 서비스를 제공하고, 의료 시스템 관리를 지원하고, 사람들이 건강 정보에 액세스할 수 있도록 하고, 건강한 라이프스타일을 장려하고, 과학적 지식을 생성하는 것\"이라고 정의합니다.\n",
            "\n",
            "1-Gram BLEU : 0.03448275862068965\n",
            "2-Gram BLEU : 2.2250738585072626e-308\n",
            "3-Gram BLEU : 2.2250738585072626e-308\n",
            "4-Gram BLEU : 2.2250738585072626e-308\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.9/site-packages/nltk/translate/bleu_score.py:515: UserWarning: \n",
            "The hypothesis contains 0 counts of 2-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/opt/conda/lib/python3.9/site-packages/nltk/translate/bleu_score.py:515: UserWarning: \n",
            "The hypothesis contains 0 counts of 3-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/opt/conda/lib/python3.9/site-packages/nltk/translate/bleu_score.py:515: UserWarning: \n",
            "The hypothesis contains 0 counts of 4-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n"
          ]
        }
      ],
      "source": [
        "for prompt, result, label in zip(list_prompt, list_result, good_response_label):\n",
        "    q = prompt[prompt.index('\\n')+1:prompt.rindex('\\n')]\n",
        "    print('Q.', q )\n",
        "    g = result[0]['generated_text'][result[0]['generated_text'].rindex('(응답):')+5:]\n",
        "    print('G.', g )\n",
        "    print()\n",
        "    a = label # 정답\n",
        "    print('A.', label)\n",
        "    print()\n",
        "    print(\"1-Gram BLEU :\", sentence_bleu(a.split(), g.split(), weights=(1, 0, 0, 0 )))\n",
        "    print(\"2-Gram BLEU :\", sentence_bleu(a.split(), g.split(), weights=(0, 1, 0 ,0 )))\n",
        "    print(\"3-Gram BLEU :\", sentence_bleu(a.split(), g.split(), weights=(0, 0, 1 ,0 )))\n",
        "    print(\"4-Gram BLEU :\", sentence_bleu(a.split(), g.split(), weights=(0, 0, 0, 1 )))\n",
        "    print('-'*50)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e65f7571",
      "metadata": {
        "id": "e65f7571"
      },
      "outputs": [],
      "source": [
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "03c648f4",
      "metadata": {
        "id": "03c648f4"
      },
      "source": [
        "# RM (Reward Model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b1276b14",
      "metadata": {
        "id": "b1276b14",
        "outputId": "75b74ef0-d3f4-47f2-f7d8-4120206cd15c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting chatgpt\n",
            "  Downloading chatgpt-2.2212.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: rich in /opt/conda/lib/python3.9/site-packages (from chatgpt) (13.4.2)\n",
            "Collecting tls-client\n",
            "  Downloading tls_client-0.2.2-py3-none-any.whl (36.9 MB)\n",
            "     |████████████████████████████████| 36.9 MB 12.4 MB/s            \n",
            "\u001b[?25hRequirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.9/site-packages (from rich->chatgpt) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.9/site-packages (from rich->chatgpt) (2.15.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.9/site-packages (from markdown-it-py>=2.2.0->rich->chatgpt) (0.1.2)\n",
            "Installing collected packages: tls-client, chatgpt\n",
            "Successfully installed chatgpt-2.2212.0 tls-client-0.2.2\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pip install chatgpt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3ced93e5",
      "metadata": {
        "id": "3ced93e5",
        "outputId": "bf1baf80-9fee-4627-f736-92de875ee0c8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing /aiffel/aiffel/KoChatGPT/colossalai_ChatGPT_230319\n",
            "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25hRequirement already satisfied: transformers>=4.20.1 in /opt/conda/lib/python3.9/site-packages (from chatgpt==0.1.0) (4.28.0)\n",
            "Requirement already satisfied: tqdm in /opt/conda/lib/python3.9/site-packages (from chatgpt==0.1.0) (4.62.3)\n",
            "Requirement already satisfied: datasets in /opt/conda/lib/python3.9/site-packages (from chatgpt==0.1.0) (2.13.1)\n",
            "Requirement already satisfied: loralib in /opt/conda/lib/python3.9/site-packages (from chatgpt==0.1.0) (0.1.1)\n",
            "Requirement already satisfied: colossalai>=0.2.4 in /opt/conda/lib/python3.9/site-packages (from chatgpt==0.1.0) (0.2.7)\n",
            "Requirement already satisfied: torch in /opt/conda/lib/python3.9/site-packages (from chatgpt==0.1.0) (1.12.1)\n",
            "Requirement already satisfied: langchain in /opt/conda/lib/python3.9/site-packages (from chatgpt==0.1.0) (0.0.113)\n",
            "Requirement already satisfied: pre-commit in /opt/conda/lib/python3.9/site-packages (from colossalai>=0.2.4->chatgpt==0.1.0) (3.3.3)\n",
            "Requirement already satisfied: packaging in /opt/conda/lib/python3.9/site-packages (from colossalai>=0.2.4->chatgpt==0.1.0) (21.3)\n",
            "Requirement already satisfied: psutil in /opt/conda/lib/python3.9/site-packages (from colossalai>=0.2.4->chatgpt==0.1.0) (5.8.0)\n",
            "Requirement already satisfied: rich in /opt/conda/lib/python3.9/site-packages (from colossalai>=0.2.4->chatgpt==0.1.0) (13.4.2)\n",
            "Requirement already satisfied: click in /opt/conda/lib/python3.9/site-packages (from colossalai>=0.2.4->chatgpt==0.1.0) (8.0.3)\n",
            "Requirement already satisfied: ninja in /opt/conda/lib/python3.9/site-packages (from colossalai>=0.2.4->chatgpt==0.1.0) (1.11.1)\n",
            "Requirement already satisfied: contexttimer in /opt/conda/lib/python3.9/site-packages (from colossalai>=0.2.4->chatgpt==0.1.0) (0.3.3)\n",
            "Requirement already satisfied: fabric in /opt/conda/lib/python3.9/site-packages (from colossalai>=0.2.4->chatgpt==0.1.0) (3.1.0)\n",
            "Requirement already satisfied: numpy in /opt/conda/lib/python3.9/site-packages (from colossalai>=0.2.4->chatgpt==0.1.0) (1.21.4)\n",
            "Requirement already satisfied: filelock in /opt/conda/lib/python3.9/site-packages (from transformers>=4.20.1->chatgpt==0.1.0) (3.12.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.9/site-packages (from transformers>=4.20.1->chatgpt==0.1.0) (2021.11.10)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.9/site-packages (from transformers>=4.20.1->chatgpt==0.1.0) (6.0)\n",
            "Requirement already satisfied: requests in /opt/conda/lib/python3.9/site-packages (from transformers>=4.20.1->chatgpt==0.1.0) (2.26.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /opt/conda/lib/python3.9/site-packages (from transformers>=4.20.1->chatgpt==0.1.0) (0.15.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.9/site-packages (from transformers>=4.20.1->chatgpt==0.1.0) (0.13.3)\n",
            "Requirement already satisfied: xxhash in /opt/conda/lib/python3.9/site-packages (from datasets->chatgpt==0.1.0) (2.0.2)\n",
            "Requirement already satisfied: pandas in /opt/conda/lib/python3.9/site-packages (from datasets->chatgpt==0.1.0) (1.3.3)\n",
            "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.9/site-packages (from datasets->chatgpt==0.1.0) (3.8.4)\n",
            "Requirement already satisfied: multiprocess in /opt/conda/lib/python3.9/site-packages (from datasets->chatgpt==0.1.0) (0.70.12.2)\n",
            "Requirement already satisfied: fsspec[http]>=2021.11.1 in /opt/conda/lib/python3.9/site-packages (from datasets->chatgpt==0.1.0) (2021.11.1)\n",
            "Requirement already satisfied: dill<0.3.7,>=0.3.0 in /opt/conda/lib/python3.9/site-packages (from datasets->chatgpt==0.1.0) (0.3.4)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /opt/conda/lib/python3.9/site-packages (from datasets->chatgpt==0.1.0) (12.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<2,>=1 in /opt/conda/lib/python3.9/site-packages (from langchain->chatgpt==0.1.0) (1.4.48)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /opt/conda/lib/python3.9/site-packages (from langchain->chatgpt==0.1.0) (8.2.2)\n",
            "Requirement already satisfied: dataclasses-json<0.6.0,>=0.5.7 in /opt/conda/lib/python3.9/site-packages (from langchain->chatgpt==0.1.0) (0.5.8)\n",
            "Requirement already satisfied: pydantic<2,>=1 in /opt/conda/lib/python3.9/site-packages (from langchain->chatgpt==0.1.0) (1.10.9)\n",
            "Requirement already satisfied: typing_extensions in /opt/conda/lib/python3.9/site-packages (from torch->chatgpt==0.1.0) (4.7.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.9/site-packages (from aiohttp->datasets->chatgpt==0.1.0) (21.2.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.9/site-packages (from aiohttp->datasets->chatgpt==0.1.0) (4.0.1)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/conda/lib/python3.9/site-packages (from aiohttp->datasets->chatgpt==0.1.0) (2.0.8)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.9/site-packages (from aiohttp->datasets->chatgpt==0.1.0) (1.7.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.9/site-packages (from aiohttp->datasets->chatgpt==0.1.0) (1.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.9/site-packages (from aiohttp->datasets->chatgpt==0.1.0) (5.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.9/site-packages (from aiohttp->datasets->chatgpt==0.1.0) (1.2.0)\n",
            "Requirement already satisfied: marshmallow-enum<2.0.0,>=1.5.1 in /opt/conda/lib/python3.9/site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain->chatgpt==0.1.0) (1.5.1)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.3.0 in /opt/conda/lib/python3.9/site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain->chatgpt==0.1.0) (3.19.0)\n",
            "Requirement already satisfied: typing-inspect>=0.4.0 in /opt/conda/lib/python3.9/site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain->chatgpt==0.1.0) (0.9.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.9/site-packages (from packaging->colossalai>=0.2.4->chatgpt==0.1.0) (3.0.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.9/site-packages (from requests->transformers>=4.20.1->chatgpt==0.1.0) (2023.5.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.9/site-packages (from requests->transformers>=4.20.1->chatgpt==0.1.0) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.9/site-packages (from requests->transformers>=4.20.1->chatgpt==0.1.0) (1.26.7)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.9/site-packages (from SQLAlchemy<2,>=1->langchain->chatgpt==0.1.0) (2.0.2)\n",
            "Requirement already satisfied: invoke>=2.0 in /opt/conda/lib/python3.9/site-packages (from fabric->colossalai>=0.2.4->chatgpt==0.1.0) (2.1.3)\n",
            "Requirement already satisfied: decorator>=5 in /opt/conda/lib/python3.9/site-packages (from fabric->colossalai>=0.2.4->chatgpt==0.1.0) (5.1.1)\n",
            "Requirement already satisfied: paramiko>=2.4 in /opt/conda/lib/python3.9/site-packages (from fabric->colossalai>=0.2.4->chatgpt==0.1.0) (3.2.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.9/site-packages (from pandas->datasets->chatgpt==0.1.0) (2021.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.9/site-packages (from pandas->datasets->chatgpt==0.1.0) (2.8.2)\n",
            "Requirement already satisfied: cfgv>=2.0.0 in /opt/conda/lib/python3.9/site-packages (from pre-commit->colossalai>=0.2.4->chatgpt==0.1.0) (3.3.1)\n",
            "Requirement already satisfied: nodeenv>=0.11.1 in /opt/conda/lib/python3.9/site-packages (from pre-commit->colossalai>=0.2.4->chatgpt==0.1.0) (1.8.0)\n",
            "Requirement already satisfied: virtualenv>=20.10.0 in /opt/conda/lib/python3.9/site-packages (from pre-commit->colossalai>=0.2.4->chatgpt==0.1.0) (20.23.1)\n",
            "Requirement already satisfied: identify>=1.0.0 in /opt/conda/lib/python3.9/site-packages (from pre-commit->colossalai>=0.2.4->chatgpt==0.1.0) (2.5.24)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.9/site-packages (from rich->colossalai>=0.2.4->chatgpt==0.1.0) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.9/site-packages (from rich->colossalai>=0.2.4->chatgpt==0.1.0) (2.15.1)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.9/site-packages (from markdown-it-py>=2.2.0->rich->colossalai>=0.2.4->chatgpt==0.1.0) (0.1.2)\n",
            "Requirement already satisfied: setuptools in /opt/conda/lib/python3.9/site-packages (from nodeenv>=0.11.1->pre-commit->colossalai>=0.2.4->chatgpt==0.1.0) (59.4.0)\n",
            "Requirement already satisfied: cryptography>=3.3 in /opt/conda/lib/python3.9/site-packages (from paramiko>=2.4->fabric->colossalai>=0.2.4->chatgpt==0.1.0) (41.0.1)\n",
            "Requirement already satisfied: pynacl>=1.5 in /opt/conda/lib/python3.9/site-packages (from paramiko>=2.4->fabric->colossalai>=0.2.4->chatgpt==0.1.0) (1.5.0)\n",
            "Requirement already satisfied: bcrypt>=3.2 in /opt/conda/lib/python3.9/site-packages (from paramiko>=2.4->fabric->colossalai>=0.2.4->chatgpt==0.1.0) (4.0.1)\n",
            "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.9/site-packages (from python-dateutil>=2.7.3->pandas->datasets->chatgpt==0.1.0) (1.16.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /opt/conda/lib/python3.9/site-packages (from typing-inspect>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain->chatgpt==0.1.0) (0.4.3)\n",
            "Requirement already satisfied: platformdirs<4,>=3.5.1 in /opt/conda/lib/python3.9/site-packages (from virtualenv>=20.10.0->pre-commit->colossalai>=0.2.4->chatgpt==0.1.0) (3.8.0)\n",
            "Requirement already satisfied: distlib<1,>=0.3.6 in /opt/conda/lib/python3.9/site-packages (from virtualenv>=20.10.0->pre-commit->colossalai>=0.2.4->chatgpt==0.1.0) (0.3.6)\n",
            "Requirement already satisfied: cffi>=1.12 in /opt/conda/lib/python3.9/site-packages (from cryptography>=3.3->paramiko>=2.4->fabric->colossalai>=0.2.4->chatgpt==0.1.0) (1.15.0)\n",
            "Requirement already satisfied: pycparser in /opt/conda/lib/python3.9/site-packages (from cffi>=1.12->cryptography>=3.3->paramiko>=2.4->fabric->colossalai>=0.2.4->chatgpt==0.1.0) (2.21)\n",
            "Building wheels for collected packages: chatgpt\n",
            "  Building wheel for chatgpt (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Created wheel for chatgpt: filename=chatgpt-0.1.0-py3-none-any.whl size=46664 sha256=71dcbbdc77a96e8710e353363f83c0341d6e07f83977ed7898228904aacd85b9\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-r92lbwhs/wheels/79/25/c3/338e0c56a2253a8ea6c41e8692f6eb2409a3898c63b234b103\n",
            "Successfully built chatgpt\n",
            "Installing collected packages: chatgpt\n",
            "  Attempting uninstall: chatgpt\n",
            "    Found existing installation: chatgpt 2.2212.0\n",
            "    Uninstalling chatgpt-2.2212.0:\n",
            "      Successfully uninstalled chatgpt-2.2212.0\n",
            "Successfully installed chatgpt-0.1.0\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pip install \"$HOME/aiffel/KoChatGPT/colossalai_ChatGPT_230319/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "40fd0719",
      "metadata": {
        "id": "40fd0719"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
        "import json\n",
        "from typing import Optional\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.optim import Adam\n",
        "from chatgpt.dataset import RewardDataset\n",
        "from chatgpt.models.base import RewardModel\n",
        "from chatgpt.trainer import RewardModelTrainer\n",
        "from chatgpt.trainer.strategies import NaiveStrategy\n",
        "from datasets import load_dataset\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, AutoModel, AutoConfig\n",
        "from transformers.models.gpt2.configuration_gpt2 import GPT2Config\n",
        "from transformers.models.gpt2.modeling_gpt2 import GPT2Model\n",
        "import loralib as lora"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "45485f68",
      "metadata": {
        "id": "45485f68"
      },
      "outputs": [],
      "source": [
        "class GPTRM_custom(RewardModel):\n",
        "\n",
        "    def __init__(self,\n",
        "                 pretrained: Optional[str] = None,\n",
        "                 config: Optional[GPT2Config] = None,\n",
        "                 checkpoint: bool = False,\n",
        "                 lora_rank: int = 0,\n",
        "                 lora_train_bias: str = 'none',\n",
        "                 tokenizer=None) -> None:\n",
        "        if pretrained is not None:\n",
        "            model = GPT2Model.from_pretrained(pretrained)\n",
        "            model.resize_token_embeddings(len(tokenizer))\n",
        "        elif config is not None:\n",
        "            model = GPT2Model(config)\n",
        "        else:\n",
        "            model = GPT2Model(GPT2Config())\n",
        "        if checkpoint:\n",
        "            model.gradient_checkpointing_enable()\n",
        "\n",
        "        value_head = nn.Linear(model.config.n_embd, 1)\n",
        "        super().__init__(model, value_head, lora_rank, lora_train_bias)\n",
        "\n",
        "        if pretrained is not None:\n",
        "            self.model = model\n",
        "            self.pretrained = pretrained\n",
        "\n",
        "\n",
        "    def save_pretrained(self, dir):\n",
        "        if self.pretrained is not None:\n",
        "            self.model.save_pretrained(dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "074c4bfe",
      "metadata": {
        "id": "074c4bfe"
      },
      "outputs": [],
      "source": [
        "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
        "tokenizer = AutoTokenizer.from_pretrained(\n",
        "    model_name, bos_token='</s>', eos_token='</s>', unk_token='</s>', pad_token='</s>',\n",
        "    padding_side=\"right\",\n",
        "    model_max_length=512,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8a6edbe8",
      "metadata": {
        "id": "8a6edbe8",
        "outputId": "1ad8889b-4621-4908-cb71-448091590142"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at skt/kogpt2-base-v2 were not used when initializing GPT2Model: ['lm_head.weight']\n",
            "- This IS expected if you are initializing GPT2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing GPT2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ],
      "source": [
        "with NaiveStrategy().model_init_context():\n",
        "        model = GPTRM_custom(pretrained=model_name,\n",
        "                             lora_rank=0, tokenizer=tokenizer).cuda()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f0454df1",
      "metadata": {
        "id": "f0454df1"
      },
      "outputs": [],
      "source": [
        "with open('/aiffel/KoChatGPT/data_kochatgpt/kochatgpt_2_RM.jsonl', \"r\",\n",
        "          encoding='utf-8-sig') as json_file:\n",
        "    list_data_dict = json.load(json_file)\n",
        "\n",
        "total_data_ranking2chosen = []\n",
        "for tmp in list_data_dict:\n",
        "    one_data_ranking2chosen = []\n",
        "\n",
        "    data = {}\n",
        "    data['prompt'] = tmp['prompt']\n",
        "    if tmp['ranking'][0] < tmp['ranking'][1]:\n",
        "        data['chosen'] = tmp['completion_0']\n",
        "        data['rejected'] = tmp['completion_1']\n",
        "    else:\n",
        "        data['chosen'] = tmp['completion_1']\n",
        "        data['rejected'] = tmp['completion_0']\n",
        "    one_data_ranking2chosen.append(data)\n",
        "\n",
        "    data = {}\n",
        "    data['prompt'] = tmp['prompt']\n",
        "    if tmp['ranking'][0] < tmp['ranking'][2]:\n",
        "        data['chosen'] = tmp['completion_0']\n",
        "        data['rejected'] = tmp['completion_2']\n",
        "    else:\n",
        "        data['chosen'] = tmp['completion_2']\n",
        "        data['rejected'] = tmp['completion_0']\n",
        "    one_data_ranking2chosen.append(data)\n",
        "\n",
        "    data = {}\n",
        "    data['prompt'] = tmp['prompt']\n",
        "    if tmp['ranking'][1] < tmp['ranking'][2]:\n",
        "        data['chosen'] = tmp['completion_1']\n",
        "        data['rejected'] = tmp['completion_2']\n",
        "    else:\n",
        "        data['chosen'] = tmp['completion_2']\n",
        "        data['rejected'] = tmp['completion_1']\n",
        "    one_data_ranking2chosen.append(data)\n",
        "\n",
        "\n",
        "\n",
        "    total_data_ranking2chosen.extend(one_data_ranking2chosen)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "72fb4277",
      "metadata": {
        "id": "72fb4277",
        "outputId": "41e5a070-65e1-4822-c7e4-5f5a52632860"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "before data num: 10220\n",
            "after  data num: 30660\n",
            "data example: \n",
            "{'prompt': '애플은 리사를 어떻게 처리했어', 'chosen': '애플이 누구인지 명확히 알 수 없어서, 리사가 누구인지와 어떤 상황에서 처리되었는지에 대한 추가적인 정보가 필요합니다. 따라서, 보다 정확한 답변을 제공할 수 없습니다.', 'rejected': '애플은 리사를 위해 고객 서비스 부서에서 고객 다양한 컴퓨터 관련 문제에 대해 응답하는 데 필요한 모든 지원을 제공했습니다. 사용자가 하드웨어 문제를 경험할 때, 전문가들은 필요한 수리(수리, 추가 부품 제공, 소프트웨어 업그레이드 등)을 제공해 드릴 수 있습니다. 또한, 사용자가 사용 방법 문제나 기타 문제를 경험할 때, 대화 상대로 사용자를 지원할 수 있는 전문 고객 서비스 직원들이 사용자에게 상담하고 도움을 주는 데 도움이 될 수 있는 정보를 제공합니다. 또한, 인터넷에서 제공되는 정보를 통해 문제를 해결하거나 고객 서비스 웹 사이트를 통해 자신의 문제를 진단할 수 있도록 하는 등 다양한 방법으로 리사를 처리해 왔습니다.'}\n"
          ]
        }
      ],
      "source": [
        "print('before data num: %d'%(len(list_data_dict)))\n",
        "print('after  data num: %d'%(len(total_data_ranking2chosen)))\n",
        "print('data example: \\n%s'%total_data_ranking2chosen[45])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a5000164",
      "metadata": {
        "id": "a5000164",
        "outputId": "9d9e226e-62c4-48db-b48f-457c231123d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'prompt': '이 카드 무이자 할부 되죠?', 'chosen': '죄송하지만 저는 이직하고부터 은행에서 일하고 있지 않습니다. 하지만 대개 카드 무이자 할부는 해당 카드 발급사의 조건에 따라 달라지기 때문에, 해당 카드 발급사에 문의하시거나 해당 카드의 웹사이트를 참고하시는 것이 좋을 것 같습니다.', 'rejected': '이상활돌들 개인사이에서도 국가미남 국가미남의 국가미남을 국가미남의 국가미남의 국가미남의 국가미남의 국가미남의 국가미남의 국가미남의 국가미남의 국가미남의 국가미남의 국가미남의 국가미남의 국가미남의 국가미남의 국가미'}\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "random.seed(231208)\n",
        "random.shuffle(total_data_ranking2chosen)\n",
        "print(total_data_ranking2chosen[45])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e86a998b",
      "metadata": {
        "id": "e86a998b",
        "outputId": "1260fe41-6241-4f34-fcbf-5931ffbc8a85"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1000\n",
            "200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:00<00:00, 1371.76it/s]\n",
            "100%|██████████| 200/200 [00:00<00:00, 1364.86it/s]\n"
          ]
        }
      ],
      "source": [
        "train_data = total_data_ranking2chosen[:1000]\n",
        "eval_data = total_data_ranking2chosen[1000:1200]\n",
        "\n",
        "print(len(train_data))\n",
        "print(len(eval_data))\n",
        "\n",
        "train_dataset = RewardDataset(train_data, tokenizer, 512)\n",
        "eval_dataset = RewardDataset(eval_data, tokenizer, 512)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "76bbe40f",
      "metadata": {
        "id": "76bbe40f",
        "outputId": "04c69649-3d4c-44ea-d638-b2f497fa809a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "######################################################################\n",
            "## prompt ##\n",
            "바이오하자드 엄브렐러 크로니클즈는 몇 인칭 게임인가요?\n",
            "######################################################################\n",
            "## chosen ##\n",
            "바이오하자드 엄브렐러 크로니클즈는 세 인칭 게임입니다.\n",
            "######################################################################\n",
            "## rejected ##\n",
            "이상화를 한 개인으로 크로니클즈는 개인으로 크로니클즈를 한 개인으로 크로니클즈를 한 개인으로 크로니클즈를 한 개인으로 크로니클즈를 한 개인으로 크로니클즈를 한 개인으로 크로니클즈를 한 개인으로 크로니클즈를 한 개인으로 크로니\n"
          ]
        }
      ],
      "source": [
        "idx = 1\n",
        "print('#'*70)\n",
        "print('## prompt ##')\n",
        "print(train_data[idx]['prompt'])\n",
        "print('#'*70)\n",
        "print('## chosen ##')\n",
        "print(train_data[idx]['chosen'])\n",
        "print('#'*70)\n",
        "print('## rejected ##')\n",
        "print(train_data[idx]['rejected'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c648244c",
      "metadata": {
        "id": "c648244c"
      },
      "outputs": [],
      "source": [
        "trainer = RewardModelTrainer(model=model,\n",
        "                             strategy=NaiveStrategy(),\n",
        "                             optim=Adam(model.parameters(), lr=5e-5),\n",
        "                             train_dataset=train_dataset,\n",
        "                             eval_dataset=eval_dataset,\n",
        "                             batch_size=4,\n",
        "                             max_epochs=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "002fe35f",
      "metadata": {
        "id": "002fe35f",
        "outputId": "59bef028-9867-406b-b84c-0c0e531690dc"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train epoch:   0%|          | 0/1 [00:00<?, ?it/s]\n",
            "Train step of epoch 0:   0%|          | 0/250 [00:00<?, ?it/s]\u001b[A\n",
            "Train step of epoch 0:   0%|          | 1/250 [00:00<03:32,  1.17it/s]\u001b[A\n",
            "Train step of epoch 0:   0%|          | 1/250 [00:00<03:32,  1.17it/s, loss=0.655]\u001b[A\n",
            "Train step of epoch 0:   1%|          | 2/250 [00:01<03:26,  1.20it/s, loss=0.655]\u001b[A\n",
            "Train step of epoch 0:   1%|          | 2/250 [00:01<03:26,  1.20it/s, loss=0.562]\u001b[A\n",
            "Train step of epoch 0:   1%|          | 3/250 [00:02<03:24,  1.21it/s, loss=0.562]\u001b[A\n",
            "Train step of epoch 0:   1%|          | 3/250 [00:02<03:24,  1.21it/s, loss=0.596]\u001b[A\n",
            "Train step of epoch 0:   2%|▏         | 4/250 [00:03<03:23,  1.21it/s, loss=0.596]\u001b[A\n",
            "Train step of epoch 0:   2%|▏         | 4/250 [00:03<03:23,  1.21it/s, loss=0.378]\u001b[A\n",
            "Train step of epoch 0:   2%|▏         | 5/250 [00:04<03:22,  1.21it/s, loss=0.378]\u001b[A\n",
            "Train step of epoch 0:   2%|▏         | 5/250 [00:04<03:22,  1.21it/s, loss=1.89] \u001b[A\n",
            "Train step of epoch 0:   2%|▏         | 6/250 [00:04<03:21,  1.21it/s, loss=1.89]\u001b[A\n",
            "Train step of epoch 0:   2%|▏         | 6/250 [00:04<03:21,  1.21it/s, loss=0.701]\u001b[A\n",
            "Train step of epoch 0:   3%|▎         | 7/250 [00:05<03:21,  1.21it/s, loss=0.701]\u001b[A\n",
            "Train step of epoch 0:   3%|▎         | 7/250 [00:05<03:21,  1.21it/s, loss=1.48] \u001b[A\n",
            "Train step of epoch 0:   3%|▎         | 8/250 [00:06<03:20,  1.21it/s, loss=1.48]\u001b[A\n",
            "Train step of epoch 0:   3%|▎         | 8/250 [00:06<03:20,  1.21it/s, loss=0.812]\u001b[A\n",
            "Train step of epoch 0:   4%|▎         | 9/250 [00:07<03:19,  1.21it/s, loss=0.812]\u001b[A\n",
            "Train step of epoch 0:   4%|▎         | 9/250 [00:07<03:19,  1.21it/s, loss=0.684]\u001b[A\n",
            "Train step of epoch 0:   4%|▍         | 10/250 [00:08<03:18,  1.21it/s, loss=0.684]\u001b[A\n",
            "Train step of epoch 0:   4%|▍         | 10/250 [00:08<03:18,  1.21it/s, loss=0.688]\u001b[A\n",
            "Train step of epoch 0:   4%|▍         | 11/250 [00:09<03:18,  1.21it/s, loss=0.688]\u001b[A\n",
            "Train step of epoch 0:   4%|▍         | 11/250 [00:09<03:18,  1.21it/s, loss=0.463]\u001b[A\n",
            "Train step of epoch 0:   5%|▍         | 12/250 [00:09<03:17,  1.21it/s, loss=0.463]\u001b[A\n",
            "Train step of epoch 0:   5%|▍         | 12/250 [00:09<03:17,  1.21it/s, loss=0.674]\u001b[A\n",
            "Train step of epoch 0:   5%|▌         | 13/250 [00:10<03:16,  1.21it/s, loss=0.674]\u001b[A\n",
            "Train step of epoch 0:   5%|▌         | 13/250 [00:10<03:16,  1.21it/s, loss=0.525]\u001b[A\n",
            "Train step of epoch 0:   6%|▌         | 14/250 [00:11<03:15,  1.21it/s, loss=0.525]\u001b[A\n",
            "Train step of epoch 0:   6%|▌         | 14/250 [00:11<03:15,  1.21it/s, loss=0.667]\u001b[A\n",
            "Train step of epoch 0:   6%|▌         | 15/250 [00:12<03:15,  1.20it/s, loss=0.667]\u001b[A\n",
            "Train step of epoch 0:   6%|▌         | 15/250 [00:12<03:15,  1.20it/s, loss=0.604]\u001b[A\n",
            "Train step of epoch 0:   6%|▋         | 16/250 [00:13<03:14,  1.21it/s, loss=0.604]\u001b[A\n",
            "Train step of epoch 0:   6%|▋         | 16/250 [00:13<03:14,  1.21it/s, loss=0.482]\u001b[A\n",
            "Train step of epoch 0:   7%|▋         | 17/250 [00:14<03:13,  1.21it/s, loss=0.482]\u001b[A\n",
            "Train step of epoch 0:   7%|▋         | 17/250 [00:14<03:13,  1.21it/s, loss=0.61] \u001b[A\n",
            "Train step of epoch 0:   7%|▋         | 18/250 [00:14<03:12,  1.20it/s, loss=0.61]\u001b[A\n",
            "Train step of epoch 0:   7%|▋         | 18/250 [00:14<03:12,  1.20it/s, loss=0.495]\u001b[A\n",
            "Train step of epoch 0:   8%|▊         | 19/250 [00:15<03:11,  1.20it/s, loss=0.495]\u001b[A\n",
            "Train step of epoch 0:   8%|▊         | 19/250 [00:15<03:11,  1.20it/s, loss=1.01] \u001b[A\n",
            "Train step of epoch 0:   8%|▊         | 20/250 [00:16<03:11,  1.20it/s, loss=1.01]\u001b[A\n",
            "Train step of epoch 0:   8%|▊         | 20/250 [00:16<03:11,  1.20it/s, loss=0.6] \u001b[A\n",
            "Train step of epoch 0:   8%|▊         | 21/250 [00:17<03:10,  1.20it/s, loss=0.6]\u001b[A\n",
            "Train step of epoch 0:   8%|▊         | 21/250 [00:17<03:10,  1.20it/s, loss=0.623]\u001b[A\n",
            "Train step of epoch 0:   9%|▉         | 22/250 [00:18<03:09,  1.20it/s, loss=0.623]\u001b[A\n",
            "Train step of epoch 0:   9%|▉         | 22/250 [00:18<03:09,  1.20it/s, loss=0.687]\u001b[A\n",
            "Train step of epoch 0:   9%|▉         | 23/250 [00:19<03:08,  1.20it/s, loss=0.687]\u001b[A\n",
            "Train step of epoch 0:   9%|▉         | 23/250 [00:19<03:08,  1.20it/s, loss=0.706]\u001b[A\n",
            "Train step of epoch 0:  10%|▉         | 24/250 [00:19<03:07,  1.20it/s, loss=0.706]\u001b[A\n",
            "Train step of epoch 0:  10%|▉         | 24/250 [00:19<03:07,  1.20it/s, loss=0.484]\u001b[A\n",
            "Train step of epoch 0:  10%|█         | 25/250 [00:20<03:07,  1.20it/s, loss=0.484]\u001b[A\n",
            "Train step of epoch 0:  10%|█         | 25/250 [00:20<03:07,  1.20it/s, loss=0.544]\u001b[A\n",
            "Train step of epoch 0:  10%|█         | 26/250 [00:21<03:06,  1.20it/s, loss=0.544]\u001b[A\n",
            "Train step of epoch 0:  10%|█         | 26/250 [00:21<03:06,  1.20it/s, loss=0.647]\u001b[A\n",
            "Train step of epoch 0:  11%|█         | 27/250 [00:22<03:06,  1.20it/s, loss=0.647]\u001b[A\n",
            "Train step of epoch 0:  11%|█         | 27/250 [00:22<03:06,  1.20it/s, loss=0.499]\u001b[A\n",
            "Train step of epoch 0:  11%|█         | 28/250 [00:23<03:05,  1.20it/s, loss=0.499]\u001b[A\n",
            "Train step of epoch 0:  11%|█         | 28/250 [00:23<03:05,  1.20it/s, loss=0.776]\u001b[A\n",
            "Train step of epoch 0:  12%|█▏        | 29/250 [00:24<03:04,  1.20it/s, loss=0.776]\u001b[A\n",
            "Train step of epoch 0:  12%|█▏        | 29/250 [00:24<03:04,  1.20it/s, loss=0.387]\u001b[A\n",
            "Train step of epoch 0:  12%|█▏        | 30/250 [00:24<03:03,  1.20it/s, loss=0.387]\u001b[A\n",
            "Train step of epoch 0:  12%|█▏        | 30/250 [00:24<03:03,  1.20it/s, loss=0.352]\u001b[A\n",
            "Train step of epoch 0:  12%|█▏        | 31/250 [00:25<03:03,  1.20it/s, loss=0.352]\u001b[A\n",
            "Train step of epoch 0:  12%|█▏        | 31/250 [00:25<03:03,  1.20it/s, loss=0.538]\u001b[A\n",
            "Train step of epoch 0:  13%|█▎        | 32/250 [00:26<03:02,  1.19it/s, loss=0.538]\u001b[A\n",
            "Train step of epoch 0:  13%|█▎        | 32/250 [00:26<03:02,  1.19it/s, loss=0.695]\u001b[A\n",
            "Train step of epoch 0:  13%|█▎        | 33/250 [00:27<03:01,  1.19it/s, loss=0.695]\u001b[A\n",
            "Train step of epoch 0:  13%|█▎        | 33/250 [00:27<03:01,  1.19it/s, loss=0.25] \u001b[A\n",
            "Train step of epoch 0:  14%|█▎        | 34/250 [00:28<03:01,  1.19it/s, loss=0.25]\u001b[A\n",
            "Train step of epoch 0:  14%|█▎        | 34/250 [00:28<03:01,  1.19it/s, loss=0.888]\u001b[A\n",
            "Train step of epoch 0:  14%|█▍        | 35/250 [00:29<03:00,  1.19it/s, loss=0.888]\u001b[A\n",
            "Train step of epoch 0:  14%|█▍        | 35/250 [00:29<03:00,  1.19it/s, loss=1.96] \u001b[A\n",
            "Train step of epoch 0:  14%|█▍        | 36/250 [00:29<02:59,  1.19it/s, loss=1.96]\u001b[A\n",
            "Train step of epoch 0:  14%|█▍        | 36/250 [00:29<02:59,  1.19it/s, loss=0.753]\u001b[A\n",
            "Train step of epoch 0:  15%|█▍        | 37/250 [00:30<02:58,  1.19it/s, loss=0.753]\u001b[A\n",
            "Train step of epoch 0:  15%|█▍        | 37/250 [00:30<02:58,  1.19it/s, loss=0.658]\u001b[A\n",
            "Train step of epoch 0:  15%|█▌        | 38/250 [00:31<02:57,  1.19it/s, loss=0.658]\u001b[A\n",
            "Train step of epoch 0:  15%|█▌        | 38/250 [00:31<02:57,  1.19it/s, loss=0.586]\u001b[A\n",
            "Train step of epoch 0:  16%|█▌        | 39/250 [00:32<02:57,  1.19it/s, loss=0.586]\u001b[A\n",
            "Train step of epoch 0:  16%|█▌        | 39/250 [00:32<02:57,  1.19it/s, loss=0.693]\u001b[A\n",
            "Train step of epoch 0:  16%|█▌        | 40/250 [00:33<02:56,  1.19it/s, loss=0.693]\u001b[A\n",
            "Train step of epoch 0:  16%|█▌        | 40/250 [00:33<02:56,  1.19it/s, loss=0.455]\u001b[A\n",
            "Train step of epoch 0:  16%|█▋        | 41/250 [00:34<02:55,  1.19it/s, loss=0.455]\u001b[A\n",
            "Train step of epoch 0:  16%|█▋        | 41/250 [00:34<02:55,  1.19it/s, loss=0.376]\u001b[A\n",
            "Train step of epoch 0:  17%|█▋        | 42/250 [00:35<02:55,  1.19it/s, loss=0.376]\u001b[A\n",
            "Train step of epoch 0:  17%|█▋        | 42/250 [00:35<02:55,  1.19it/s, loss=0.592]\u001b[A\n",
            "Train step of epoch 0:  17%|█▋        | 43/250 [00:35<02:54,  1.19it/s, loss=0.592]\u001b[A\n",
            "Train step of epoch 0:  17%|█▋        | 43/250 [00:35<02:54,  1.19it/s, loss=0.79] \u001b[A\n",
            "Train step of epoch 0:  18%|█▊        | 44/250 [00:36<02:53,  1.19it/s, loss=0.79]\u001b[A\n",
            "Train step of epoch 0:  18%|█▊        | 44/250 [00:36<02:53,  1.19it/s, loss=0.704]\u001b[A\n",
            "Train step of epoch 0:  18%|█▊        | 45/250 [00:37<02:52,  1.19it/s, loss=0.704]\u001b[A\n",
            "Train step of epoch 0:  18%|█▊        | 45/250 [00:37<02:52,  1.19it/s, loss=0.675]\u001b[A\n",
            "Train step of epoch 0:  18%|█▊        | 46/250 [00:38<02:52,  1.19it/s, loss=0.675]\u001b[A\n",
            "Train step of epoch 0:  18%|█▊        | 46/250 [00:38<02:52,  1.19it/s, loss=0.656]\u001b[A\n",
            "Train step of epoch 0:  19%|█▉        | 47/250 [00:39<02:51,  1.18it/s, loss=0.656]\u001b[A\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train step of epoch 0:  19%|█▉        | 47/250 [00:39<02:51,  1.18it/s, loss=0.53] \u001b[A\n",
            "Train step of epoch 0:  19%|█▉        | 48/250 [00:40<02:50,  1.18it/s, loss=0.53]\u001b[A\n",
            "Train step of epoch 0:  19%|█▉        | 48/250 [00:40<02:50,  1.18it/s, loss=0.531]\u001b[A\n",
            "Train step of epoch 0:  20%|█▉        | 49/250 [00:40<02:50,  1.18it/s, loss=0.531]\u001b[A\n",
            "Train step of epoch 0:  20%|█▉        | 49/250 [00:40<02:50,  1.18it/s, loss=0.556]\u001b[A\n",
            "Train step of epoch 0:  20%|██        | 50/250 [00:41<02:49,  1.18it/s, loss=0.556]\u001b[A\n",
            "Train step of epoch 0:  20%|██        | 50/250 [00:41<02:49,  1.18it/s, loss=0.599]\u001b[A\n",
            "Train step of epoch 0:  20%|██        | 51/250 [00:42<02:48,  1.18it/s, loss=0.599]\u001b[A\n",
            "Train step of epoch 0:  20%|██        | 51/250 [00:42<02:48,  1.18it/s, loss=0.508]\u001b[A\n",
            "Train step of epoch 0:  21%|██        | 52/250 [00:43<02:47,  1.18it/s, loss=0.508]\u001b[A\n",
            "Train step of epoch 0:  21%|██        | 52/250 [00:43<02:47,  1.18it/s, loss=0.585]\u001b[A\n",
            "Train step of epoch 0:  21%|██        | 53/250 [00:44<02:47,  1.18it/s, loss=0.585]\u001b[A\n",
            "Train step of epoch 0:  21%|██        | 53/250 [00:44<02:47,  1.18it/s, loss=0.627]\u001b[A\n",
            "Train step of epoch 0:  22%|██▏       | 54/250 [00:45<02:46,  1.18it/s, loss=0.627]\u001b[A\n",
            "Train step of epoch 0:  22%|██▏       | 54/250 [00:45<02:46,  1.18it/s, loss=0.598]\u001b[A\n",
            "Train step of epoch 0:  22%|██▏       | 55/250 [00:46<02:45,  1.18it/s, loss=0.598]\u001b[A\n",
            "Train step of epoch 0:  22%|██▏       | 55/250 [00:46<02:45,  1.18it/s, loss=0.811]\u001b[A\n",
            "Train step of epoch 0:  22%|██▏       | 56/250 [00:46<02:44,  1.18it/s, loss=0.811]\u001b[A\n",
            "Train step of epoch 0:  22%|██▏       | 56/250 [00:46<02:44,  1.18it/s, loss=0.697]\u001b[A\n",
            "Train step of epoch 0:  23%|██▎       | 57/250 [00:47<02:44,  1.18it/s, loss=0.697]\u001b[A\n",
            "Train step of epoch 0:  23%|██▎       | 57/250 [00:47<02:44,  1.18it/s, loss=0.756]\u001b[A\n",
            "Train step of epoch 0:  23%|██▎       | 58/250 [00:48<02:43,  1.18it/s, loss=0.756]\u001b[A\n",
            "Train step of epoch 0:  23%|██▎       | 58/250 [00:48<02:43,  1.18it/s, loss=0.7]  \u001b[A\n",
            "Train step of epoch 0:  24%|██▎       | 59/250 [00:49<02:42,  1.18it/s, loss=0.7]\u001b[A\n",
            "Train step of epoch 0:  24%|██▎       | 59/250 [00:49<02:42,  1.18it/s, loss=1.01]\u001b[A\n",
            "Train step of epoch 0:  24%|██▍       | 60/250 [00:50<02:41,  1.18it/s, loss=1.01]\u001b[A\n",
            "Train step of epoch 0:  24%|██▍       | 60/250 [00:50<02:41,  1.18it/s, loss=1.04]\u001b[A\n",
            "Train step of epoch 0:  24%|██▍       | 61/250 [00:51<02:40,  1.18it/s, loss=1.04]\u001b[A\n",
            "Train step of epoch 0:  24%|██▍       | 61/250 [00:51<02:40,  1.18it/s, loss=0.631]\u001b[A\n",
            "Train step of epoch 0:  25%|██▍       | 62/250 [00:51<02:39,  1.18it/s, loss=0.631]\u001b[A\n",
            "Train step of epoch 0:  25%|██▍       | 62/250 [00:52<02:39,  1.18it/s, loss=0.561]\u001b[A\n",
            "Train step of epoch 0:  25%|██▌       | 63/250 [00:52<02:39,  1.18it/s, loss=0.561]\u001b[A\n",
            "Train step of epoch 0:  25%|██▌       | 63/250 [00:52<02:39,  1.18it/s, loss=0.669]\u001b[A\n",
            "Train step of epoch 0:  26%|██▌       | 64/250 [00:53<02:38,  1.17it/s, loss=0.669]\u001b[A\n",
            "Train step of epoch 0:  26%|██▌       | 64/250 [00:53<02:38,  1.17it/s, loss=0.587]\u001b[A\n",
            "Train step of epoch 0:  26%|██▌       | 65/250 [00:54<02:37,  1.17it/s, loss=0.587]\u001b[A\n",
            "Train step of epoch 0:  26%|██▌       | 65/250 [00:54<02:37,  1.17it/s, loss=0.506]\u001b[A\n",
            "Train step of epoch 0:  26%|██▋       | 66/250 [00:55<02:37,  1.17it/s, loss=0.506]\u001b[A\n",
            "Train step of epoch 0:  26%|██▋       | 66/250 [00:55<02:37,  1.17it/s, loss=0.426]\u001b[A\n",
            "Train step of epoch 0:  27%|██▋       | 67/250 [00:56<02:36,  1.17it/s, loss=0.426]\u001b[A\n",
            "Train step of epoch 0:  27%|██▋       | 67/250 [00:56<02:36,  1.17it/s, loss=0.768]\u001b[A\n",
            "Train step of epoch 0:  27%|██▋       | 68/250 [00:57<02:35,  1.17it/s, loss=0.768]\u001b[A\n",
            "Train step of epoch 0:  27%|██▋       | 68/250 [00:57<02:35,  1.17it/s, loss=0.545]\u001b[A\n",
            "Train step of epoch 0:  28%|██▊       | 69/250 [00:57<02:35,  1.17it/s, loss=0.545]\u001b[A\n",
            "Train step of epoch 0:  28%|██▊       | 69/250 [00:58<02:35,  1.17it/s, loss=0.605]\u001b[A\n",
            "Train step of epoch 0:  28%|██▊       | 70/250 [00:58<02:34,  1.17it/s, loss=0.605]\u001b[A\n",
            "Train step of epoch 0:  28%|██▊       | 70/250 [00:58<02:34,  1.17it/s, loss=0.653]\u001b[A\n",
            "Train step of epoch 0:  28%|██▊       | 71/250 [00:59<02:33,  1.16it/s, loss=0.653]\u001b[A\n",
            "Train step of epoch 0:  28%|██▊       | 71/250 [00:59<02:33,  1.16it/s, loss=0.796]\u001b[A\n",
            "Train step of epoch 0:  29%|██▉       | 72/250 [01:00<02:33,  1.16it/s, loss=0.796]\u001b[A\n",
            "Train step of epoch 0:  29%|██▉       | 72/250 [01:00<02:33,  1.16it/s, loss=0.429]\u001b[A\n",
            "Train step of epoch 0:  29%|██▉       | 73/250 [01:01<02:32,  1.16it/s, loss=0.429]\u001b[A\n",
            "Train step of epoch 0:  29%|██▉       | 73/250 [01:01<02:32,  1.16it/s, loss=0.656]\u001b[A\n",
            "Train step of epoch 0:  30%|██▉       | 74/250 [01:02<02:31,  1.16it/s, loss=0.656]\u001b[A\n",
            "Train step of epoch 0:  30%|██▉       | 74/250 [01:02<02:31,  1.16it/s, loss=1.03] \u001b[A\n",
            "Train step of epoch 0:  30%|███       | 75/250 [01:03<02:31,  1.16it/s, loss=1.03]\u001b[A\n",
            "Train step of epoch 0:  30%|███       | 75/250 [01:03<02:31,  1.16it/s, loss=0.463]\u001b[A\n",
            "Train step of epoch 0:  30%|███       | 76/250 [01:04<02:30,  1.16it/s, loss=0.463]\u001b[A\n",
            "Train step of epoch 0:  30%|███       | 76/250 [01:04<02:30,  1.16it/s, loss=0.531]\u001b[A\n",
            "Train step of epoch 0:  31%|███       | 77/250 [01:04<02:29,  1.16it/s, loss=0.531]\u001b[A\n",
            "Train step of epoch 0:  31%|███       | 77/250 [01:04<02:29,  1.16it/s, loss=1.16] \u001b[A\n",
            "Train step of epoch 0:  31%|███       | 78/250 [01:05<02:28,  1.16it/s, loss=1.16]\u001b[A\n",
            "Train step of epoch 0:  31%|███       | 78/250 [01:05<02:28,  1.16it/s, loss=0.879]\u001b[A\n",
            "Train step of epoch 0:  32%|███▏      | 79/250 [01:06<02:27,  1.16it/s, loss=0.879]\u001b[A\n",
            "Train step of epoch 0:  32%|███▏      | 79/250 [01:06<02:27,  1.16it/s, loss=0.527]\u001b[A\n",
            "Train step of epoch 0:  32%|███▏      | 80/250 [01:07<02:26,  1.16it/s, loss=0.527]\u001b[A\n",
            "Train step of epoch 0:  32%|███▏      | 80/250 [01:07<02:26,  1.16it/s, loss=0.371]\u001b[A\n",
            "Train step of epoch 0:  32%|███▏      | 81/250 [01:08<02:26,  1.16it/s, loss=0.371]\u001b[A\n",
            "Train step of epoch 0:  32%|███▏      | 81/250 [01:08<02:26,  1.16it/s, loss=0.602]\u001b[A\n",
            "Train step of epoch 0:  33%|███▎      | 82/250 [01:09<02:25,  1.15it/s, loss=0.602]\u001b[A\n",
            "Train step of epoch 0:  33%|███▎      | 82/250 [01:09<02:25,  1.15it/s, loss=0.788]\u001b[A\n",
            "Train step of epoch 0:  33%|███▎      | 83/250 [01:10<02:24,  1.15it/s, loss=0.788]\u001b[A\n",
            "Train step of epoch 0:  33%|███▎      | 83/250 [01:10<02:24,  1.15it/s, loss=0.711]\u001b[A\n",
            "Train step of epoch 0:  34%|███▎      | 84/250 [01:10<02:24,  1.15it/s, loss=0.711]\u001b[A\n",
            "Train step of epoch 0:  34%|███▎      | 84/250 [01:10<02:24,  1.15it/s, loss=0.651]\u001b[A\n",
            "Train step of epoch 0:  34%|███▍      | 85/250 [01:11<02:23,  1.15it/s, loss=0.651]\u001b[A\n",
            "Train step of epoch 0:  34%|███▍      | 85/250 [01:11<02:23,  1.15it/s, loss=0.427]\u001b[A\n",
            "Train step of epoch 0:  34%|███▍      | 86/250 [01:12<02:22,  1.15it/s, loss=0.427]\u001b[A\n",
            "Train step of epoch 0:  34%|███▍      | 86/250 [01:12<02:22,  1.15it/s, loss=0.702]\u001b[A\n",
            "Train step of epoch 0:  35%|███▍      | 87/250 [01:13<02:22,  1.15it/s, loss=0.702]\u001b[A\n",
            "Train step of epoch 0:  35%|███▍      | 87/250 [01:13<02:22,  1.15it/s, loss=0.831]\u001b[A\n",
            "Train step of epoch 0:  35%|███▌      | 88/250 [01:14<02:21,  1.14it/s, loss=0.831]\u001b[A\n",
            "Train step of epoch 0:  35%|███▌      | 88/250 [01:14<02:21,  1.14it/s, loss=0.555]\u001b[A\n",
            "Train step of epoch 0:  36%|███▌      | 89/250 [01:15<02:20,  1.14it/s, loss=0.555]\u001b[A\n",
            "Train step of epoch 0:  36%|███▌      | 89/250 [01:15<02:20,  1.14it/s, loss=0.401]\u001b[A\n",
            "Train step of epoch 0:  36%|███▌      | 90/250 [01:16<02:19,  1.14it/s, loss=0.401]\u001b[A\n",
            "Train step of epoch 0:  36%|███▌      | 90/250 [01:16<02:19,  1.14it/s, loss=0.817]\u001b[A\n",
            "Train step of epoch 0:  36%|███▋      | 91/250 [01:17<02:19,  1.14it/s, loss=0.817]\u001b[A\n",
            "Train step of epoch 0:  36%|███▋      | 91/250 [01:17<02:19,  1.14it/s, loss=0.65] \u001b[A\n",
            "Train step of epoch 0:  37%|███▋      | 92/250 [01:17<02:18,  1.14it/s, loss=0.65]\u001b[A\n",
            "Train step of epoch 0:  37%|███▋      | 92/250 [01:17<02:18,  1.14it/s, loss=0.769]\u001b[A\n",
            "Train step of epoch 0:  37%|███▋      | 93/250 [01:18<02:17,  1.14it/s, loss=0.769]\u001b[A\n",
            "Train step of epoch 0:  37%|███▋      | 93/250 [01:18<02:17,  1.14it/s, loss=0.635]\u001b[A\n",
            "Train step of epoch 0:  38%|███▊      | 94/250 [01:19<02:17,  1.14it/s, loss=0.635]\u001b[A\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train step of epoch 0:  38%|███▊      | 94/250 [01:19<02:17,  1.14it/s, loss=0.671]\u001b[A\n",
            "Train step of epoch 0:  38%|███▊      | 95/250 [01:20<02:16,  1.14it/s, loss=0.671]\u001b[A\n",
            "Train step of epoch 0:  38%|███▊      | 95/250 [01:20<02:16,  1.14it/s, loss=0.828]\u001b[A\n",
            "Train step of epoch 0:  38%|███▊      | 96/250 [01:21<02:15,  1.13it/s, loss=0.828]\u001b[A\n",
            "Train step of epoch 0:  38%|███▊      | 96/250 [01:21<02:15,  1.13it/s, loss=0.548]\u001b[A\n",
            "Train step of epoch 0:  39%|███▉      | 97/250 [01:22<02:14,  1.13it/s, loss=0.548]\u001b[A\n",
            "Train step of epoch 0:  39%|███▉      | 97/250 [01:22<02:14,  1.13it/s, loss=0.779]\u001b[A\n",
            "Train step of epoch 0:  39%|███▉      | 98/250 [01:23<02:14,  1.13it/s, loss=0.779]\u001b[A\n",
            "Train step of epoch 0:  39%|███▉      | 98/250 [01:23<02:14,  1.13it/s, loss=0.612]\u001b[A\n",
            "Train step of epoch 0:  40%|███▉      | 99/250 [01:24<02:13,  1.13it/s, loss=0.612]\u001b[A\n",
            "Train step of epoch 0:  40%|███▉      | 99/250 [01:24<02:13,  1.13it/s, loss=0.557]\u001b[A\n",
            "Train step of epoch 0:  40%|████      | 100/250 [01:25<02:12,  1.13it/s, loss=0.557]\u001b[A\n",
            "Train step of epoch 0:  40%|████      | 100/250 [01:25<02:12,  1.13it/s, loss=0.646]\u001b[A\n",
            "Train step of epoch 0:  40%|████      | 101/250 [01:25<02:11,  1.13it/s, loss=0.646]\u001b[A\n",
            "Train step of epoch 0:  40%|████      | 101/250 [01:25<02:11,  1.13it/s, loss=0.542]\u001b[A\n",
            "Train step of epoch 0:  41%|████      | 102/250 [01:26<02:10,  1.13it/s, loss=0.542]\u001b[A\n",
            "Train step of epoch 0:  41%|████      | 102/250 [01:26<02:10,  1.13it/s, loss=0.399]\u001b[A\n",
            "Train step of epoch 0:  41%|████      | 103/250 [01:27<02:10,  1.13it/s, loss=0.399]\u001b[A\n",
            "Train step of epoch 0:  41%|████      | 103/250 [01:27<02:10,  1.13it/s, loss=0.549]\u001b[A\n",
            "Train step of epoch 0:  42%|████▏     | 104/250 [01:28<02:09,  1.13it/s, loss=0.549]\u001b[A\n",
            "Train step of epoch 0:  42%|████▏     | 104/250 [01:28<02:09,  1.13it/s, loss=0.499]\u001b[A\n",
            "Train step of epoch 0:  42%|████▏     | 105/250 [01:29<02:08,  1.13it/s, loss=0.499]\u001b[A\n",
            "Train step of epoch 0:  42%|████▏     | 105/250 [01:29<02:08,  1.13it/s, loss=0.381]\u001b[A\n",
            "Train step of epoch 0:  42%|████▏     | 106/250 [01:30<02:07,  1.13it/s, loss=0.381]\u001b[A\n",
            "Train step of epoch 0:  42%|████▏     | 106/250 [01:30<02:07,  1.13it/s, loss=0.552]\u001b[A\n",
            "Train step of epoch 0:  43%|████▎     | 107/250 [01:31<02:06,  1.13it/s, loss=0.552]\u001b[A\n",
            "Train step of epoch 0:  43%|████▎     | 107/250 [01:31<02:06,  1.13it/s, loss=1.34] \u001b[A\n",
            "Train step of epoch 0:  43%|████▎     | 108/250 [01:32<02:05,  1.13it/s, loss=1.34]\u001b[A\n",
            "Train step of epoch 0:  43%|████▎     | 108/250 [01:32<02:05,  1.13it/s, loss=0.531]\u001b[A\n",
            "Train step of epoch 0:  44%|████▎     | 109/250 [01:33<02:04,  1.13it/s, loss=0.531]\u001b[A\n",
            "Train step of epoch 0:  44%|████▎     | 109/250 [01:33<02:04,  1.13it/s, loss=0.217]\u001b[A\n",
            "Train step of epoch 0:  44%|████▍     | 110/250 [01:33<02:03,  1.13it/s, loss=0.217]\u001b[A\n",
            "Train step of epoch 0:  44%|████▍     | 110/250 [01:33<02:03,  1.13it/s, loss=0.536]\u001b[A\n",
            "Train step of epoch 0:  44%|████▍     | 111/250 [01:34<02:02,  1.13it/s, loss=0.536]\u001b[A\n",
            "Train step of epoch 0:  44%|████▍     | 111/250 [01:34<02:02,  1.13it/s, loss=0.766]\u001b[A\n",
            "Train step of epoch 0:  45%|████▍     | 112/250 [01:35<02:01,  1.13it/s, loss=0.766]\u001b[A\n",
            "Train step of epoch 0:  45%|████▍     | 112/250 [01:35<02:01,  1.13it/s, loss=0.392]\u001b[A\n",
            "Train step of epoch 0:  45%|████▌     | 113/250 [01:36<02:00,  1.13it/s, loss=0.392]\u001b[A\n",
            "Train step of epoch 0:  45%|████▌     | 113/250 [01:36<02:00,  1.13it/s, loss=0.81] \u001b[A\n",
            "Train step of epoch 0:  46%|████▌     | 114/250 [01:37<01:59,  1.14it/s, loss=0.81]\u001b[A\n",
            "Train step of epoch 0:  46%|████▌     | 114/250 [01:37<01:59,  1.14it/s, loss=0.597]\u001b[A\n",
            "Train step of epoch 0:  46%|████▌     | 115/250 [01:38<01:58,  1.14it/s, loss=0.597]\u001b[A\n",
            "Train step of epoch 0:  46%|████▌     | 115/250 [01:38<01:58,  1.14it/s, loss=0.362]\u001b[A\n",
            "Train step of epoch 0:  46%|████▋     | 116/250 [01:39<01:57,  1.14it/s, loss=0.362]\u001b[A\n",
            "Train step of epoch 0:  46%|████▋     | 116/250 [01:39<01:57,  1.14it/s, loss=0.47] \u001b[A\n",
            "Train step of epoch 0:  47%|████▋     | 117/250 [01:40<01:56,  1.14it/s, loss=0.47]\u001b[A\n",
            "Train step of epoch 0:  47%|████▋     | 117/250 [01:40<01:56,  1.14it/s, loss=0.731]\u001b[A\n",
            "Train step of epoch 0:  47%|████▋     | 118/250 [01:40<01:55,  1.14it/s, loss=0.731]\u001b[A\n",
            "Train step of epoch 0:  47%|████▋     | 118/250 [01:40<01:55,  1.14it/s, loss=0.242]\u001b[A\n",
            "Train step of epoch 0:  48%|████▊     | 119/250 [01:41<01:54,  1.14it/s, loss=0.242]\u001b[A\n",
            "Train step of epoch 0:  48%|████▊     | 119/250 [01:41<01:54,  1.14it/s, loss=0.521]\u001b[A\n",
            "Train step of epoch 0:  48%|████▊     | 120/250 [01:42<01:53,  1.14it/s, loss=0.521]\u001b[A\n",
            "Train step of epoch 0:  48%|████▊     | 120/250 [01:42<01:53,  1.14it/s, loss=0.526]\u001b[A\n",
            "Train step of epoch 0:  48%|████▊     | 121/250 [01:43<01:52,  1.14it/s, loss=0.526]\u001b[A\n",
            "Train step of epoch 0:  48%|████▊     | 121/250 [01:43<01:52,  1.14it/s, loss=0.426]\u001b[A\n",
            "Train step of epoch 0:  49%|████▉     | 122/250 [01:44<01:51,  1.14it/s, loss=0.426]\u001b[A\n",
            "Train step of epoch 0:  49%|████▉     | 122/250 [01:44<01:51,  1.14it/s, loss=0.767]\u001b[A\n",
            "Train step of epoch 0:  49%|████▉     | 123/250 [01:45<01:50,  1.14it/s, loss=0.767]\u001b[A\n",
            "Train step of epoch 0:  49%|████▉     | 123/250 [01:45<01:50,  1.14it/s, loss=0.34] \u001b[A\n",
            "Train step of epoch 0:  50%|████▉     | 124/250 [01:46<01:49,  1.15it/s, loss=0.34]\u001b[A\n",
            "Train step of epoch 0:  50%|████▉     | 124/250 [01:46<01:49,  1.15it/s, loss=0.605]\u001b[A\n",
            "Train step of epoch 0:  50%|█████     | 125/250 [01:47<01:49,  1.15it/s, loss=0.605]\u001b[A\n",
            "Train step of epoch 0:  50%|█████     | 125/250 [01:47<01:49,  1.15it/s, loss=0.356]\u001b[A\n",
            "Train step of epoch 0:  50%|█████     | 126/250 [01:47<01:48,  1.15it/s, loss=0.356]\u001b[A\n",
            "Train step of epoch 0:  50%|█████     | 126/250 [01:47<01:48,  1.15it/s, loss=2.52] \u001b[A\n",
            "Train step of epoch 0:  51%|█████     | 127/250 [01:48<01:47,  1.15it/s, loss=2.52]\u001b[A\n",
            "Train step of epoch 0:  51%|█████     | 127/250 [01:48<01:47,  1.15it/s, loss=0.49]\u001b[A\n",
            "Train step of epoch 0:  51%|█████     | 128/250 [01:49<01:46,  1.15it/s, loss=0.49]\u001b[A\n",
            "Train step of epoch 0:  51%|█████     | 128/250 [01:49<01:46,  1.15it/s, loss=0.419]\u001b[A\n",
            "Train step of epoch 0:  52%|█████▏    | 129/250 [01:50<01:45,  1.15it/s, loss=0.419]\u001b[A\n",
            "Train step of epoch 0:  52%|█████▏    | 129/250 [01:50<01:45,  1.15it/s, loss=0.35] \u001b[A\n",
            "Train step of epoch 0:  52%|█████▏    | 130/250 [01:51<01:44,  1.15it/s, loss=0.35]\u001b[A\n",
            "Train step of epoch 0:  52%|█████▏    | 130/250 [01:51<01:44,  1.15it/s, loss=0.438]\u001b[A\n",
            "Train step of epoch 0:  52%|█████▏    | 131/250 [01:52<01:43,  1.15it/s, loss=0.438]\u001b[A\n",
            "Train step of epoch 0:  52%|█████▏    | 131/250 [01:52<01:43,  1.15it/s, loss=0.766]\u001b[A\n",
            "Train step of epoch 0:  53%|█████▎    | 132/250 [01:53<01:42,  1.15it/s, loss=0.766]\u001b[A\n",
            "Train step of epoch 0:  53%|█████▎    | 132/250 [01:53<01:42,  1.15it/s, loss=0.75] \u001b[A\n",
            "Train step of epoch 0:  53%|█████▎    | 133/250 [01:53<01:41,  1.15it/s, loss=0.75]\u001b[A\n",
            "Train step of epoch 0:  53%|█████▎    | 133/250 [01:53<01:41,  1.15it/s, loss=0.729]\u001b[A\n",
            "Train step of epoch 0:  54%|█████▎    | 134/250 [01:54<01:40,  1.15it/s, loss=0.729]\u001b[A\n",
            "Train step of epoch 0:  54%|█████▎    | 134/250 [01:54<01:40,  1.15it/s, loss=0.659]\u001b[A\n",
            "Train step of epoch 0:  54%|█████▍    | 135/250 [01:55<01:39,  1.15it/s, loss=0.659]\u001b[A\n",
            "Train step of epoch 0:  54%|█████▍    | 135/250 [01:55<01:39,  1.15it/s, loss=0.602]\u001b[A\n",
            "Train step of epoch 0:  54%|█████▍    | 136/250 [01:56<01:38,  1.15it/s, loss=0.602]\u001b[A\n",
            "Train step of epoch 0:  54%|█████▍    | 136/250 [01:56<01:38,  1.15it/s, loss=0.634]\u001b[A\n",
            "Train step of epoch 0:  55%|█████▍    | 137/250 [01:57<01:38,  1.15it/s, loss=0.634]\u001b[A\n",
            "Train step of epoch 0:  55%|█████▍    | 137/250 [01:57<01:38,  1.15it/s, loss=0.566]\u001b[A\n",
            "Train step of epoch 0:  55%|█████▌    | 138/250 [01:58<01:37,  1.15it/s, loss=0.566]\u001b[A\n",
            "Train step of epoch 0:  55%|█████▌    | 138/250 [01:58<01:37,  1.15it/s, loss=0.547]\u001b[A\n",
            "Train step of epoch 0:  56%|█████▌    | 139/250 [01:59<01:36,  1.15it/s, loss=0.547]\u001b[A\n",
            "Train step of epoch 0:  56%|█████▌    | 139/250 [01:59<01:36,  1.15it/s, loss=0.717]\u001b[A\n",
            "Train step of epoch 0:  56%|█████▌    | 140/250 [02:00<01:35,  1.15it/s, loss=0.717]\u001b[A\n",
            "Train step of epoch 0:  56%|█████▌    | 140/250 [02:00<01:35,  1.15it/s, loss=0.875]\u001b[A\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train step of epoch 0:  56%|█████▋    | 141/250 [02:00<01:34,  1.15it/s, loss=0.875]\u001b[A\n",
            "Train step of epoch 0:  56%|█████▋    | 141/250 [02:00<01:34,  1.15it/s, loss=0.598]\u001b[A\n",
            "Train step of epoch 0:  57%|█████▋    | 142/250 [02:01<01:33,  1.16it/s, loss=0.598]\u001b[A\n",
            "Train step of epoch 0:  57%|█████▋    | 142/250 [02:01<01:33,  1.16it/s, loss=0.733]\u001b[A\n",
            "Train step of epoch 0:  57%|█████▋    | 143/250 [02:02<01:32,  1.15it/s, loss=0.733]\u001b[A\n",
            "Train step of epoch 0:  57%|█████▋    | 143/250 [02:02<01:32,  1.15it/s, loss=0.489]\u001b[A\n",
            "Train step of epoch 0:  58%|█████▊    | 144/250 [02:03<01:31,  1.16it/s, loss=0.489]\u001b[A\n",
            "Train step of epoch 0:  58%|█████▊    | 144/250 [02:03<01:31,  1.16it/s, loss=0.793]\u001b[A\n",
            "Train step of epoch 0:  58%|█████▊    | 145/250 [02:04<01:30,  1.16it/s, loss=0.793]\u001b[A\n",
            "Train step of epoch 0:  58%|█████▊    | 145/250 [02:04<01:30,  1.16it/s, loss=0.576]\u001b[A\n",
            "Train step of epoch 0:  58%|█████▊    | 146/250 [02:05<01:29,  1.16it/s, loss=0.576]\u001b[A\n",
            "Train step of epoch 0:  58%|█████▊    | 146/250 [02:05<01:29,  1.16it/s, loss=0.733]\u001b[A\n",
            "Train step of epoch 0:  59%|█████▉    | 147/250 [02:06<01:29,  1.15it/s, loss=0.733]\u001b[A\n",
            "Train step of epoch 0:  59%|█████▉    | 147/250 [02:06<01:29,  1.15it/s, loss=0.676]\u001b[A\n",
            "Train step of epoch 0:  59%|█████▉    | 148/250 [02:06<01:28,  1.16it/s, loss=0.676]\u001b[A\n",
            "Train step of epoch 0:  59%|█████▉    | 148/250 [02:06<01:28,  1.16it/s, loss=0.678]\u001b[A\n",
            "Train step of epoch 0:  60%|█████▉    | 149/250 [02:07<01:27,  1.16it/s, loss=0.678]\u001b[A\n",
            "Train step of epoch 0:  60%|█████▉    | 149/250 [02:07<01:27,  1.16it/s, loss=0.519]\u001b[A\n",
            "Train step of epoch 0:  60%|██████    | 150/250 [02:08<01:26,  1.16it/s, loss=0.519]\u001b[A\n",
            "Train step of epoch 0:  60%|██████    | 150/250 [02:08<01:26,  1.16it/s, loss=0.613]\u001b[A\n",
            "Train step of epoch 0:  60%|██████    | 151/250 [02:09<01:25,  1.16it/s, loss=0.613]\u001b[A\n",
            "Train step of epoch 0:  60%|██████    | 151/250 [02:09<01:25,  1.16it/s, loss=0.715]\u001b[A\n",
            "Train step of epoch 0:  61%|██████    | 152/250 [02:10<01:24,  1.16it/s, loss=0.715]\u001b[A\n",
            "Train step of epoch 0:  61%|██████    | 152/250 [02:10<01:24,  1.16it/s, loss=0.582]\u001b[A\n",
            "Train step of epoch 0:  61%|██████    | 153/250 [02:11<01:23,  1.16it/s, loss=0.582]\u001b[A\n",
            "Train step of epoch 0:  61%|██████    | 153/250 [02:11<01:23,  1.16it/s, loss=0.488]\u001b[A\n",
            "Train step of epoch 0:  62%|██████▏   | 154/250 [02:12<01:23,  1.15it/s, loss=0.488]\u001b[A\n",
            "Train step of epoch 0:  62%|██████▏   | 154/250 [02:12<01:23,  1.15it/s, loss=0.406]\u001b[A\n",
            "Train step of epoch 0:  62%|██████▏   | 155/250 [02:13<01:22,  1.15it/s, loss=0.406]\u001b[A\n",
            "Train step of epoch 0:  62%|██████▏   | 155/250 [02:13<01:22,  1.15it/s, loss=0.801]\u001b[A\n",
            "Train step of epoch 0:  62%|██████▏   | 156/250 [02:13<01:21,  1.15it/s, loss=0.801]\u001b[A\n",
            "Train step of epoch 0:  62%|██████▏   | 156/250 [02:13<01:21,  1.15it/s, loss=0.442]\u001b[A\n",
            "Train step of epoch 0:  63%|██████▎   | 157/250 [02:14<01:20,  1.15it/s, loss=0.442]\u001b[A\n",
            "Train step of epoch 0:  63%|██████▎   | 157/250 [02:14<01:20,  1.15it/s, loss=0.437]\u001b[A\n",
            "Train step of epoch 0:  63%|██████▎   | 158/250 [02:15<01:19,  1.15it/s, loss=0.437]\u001b[A\n",
            "Train step of epoch 0:  63%|██████▎   | 158/250 [02:15<01:19,  1.15it/s, loss=0.654]\u001b[A\n",
            "Train step of epoch 0:  64%|██████▎   | 159/250 [02:16<01:18,  1.15it/s, loss=0.654]\u001b[A\n",
            "Train step of epoch 0:  64%|██████▎   | 159/250 [02:16<01:18,  1.15it/s, loss=0.612]\u001b[A\n",
            "Train step of epoch 0:  64%|██████▍   | 160/250 [02:17<01:18,  1.15it/s, loss=0.612]\u001b[A\n",
            "Train step of epoch 0:  64%|██████▍   | 160/250 [02:17<01:18,  1.15it/s, loss=0.428]\u001b[A\n",
            "Train step of epoch 0:  64%|██████▍   | 161/250 [02:18<01:17,  1.15it/s, loss=0.428]\u001b[A\n",
            "Train step of epoch 0:  64%|██████▍   | 161/250 [02:18<01:17,  1.15it/s, loss=0.789]\u001b[A\n",
            "Train step of epoch 0:  65%|██████▍   | 162/250 [02:19<01:16,  1.15it/s, loss=0.789]\u001b[A\n",
            "Train step of epoch 0:  65%|██████▍   | 162/250 [02:19<01:16,  1.15it/s, loss=0.398]\u001b[A\n",
            "Train step of epoch 0:  65%|██████▌   | 163/250 [02:19<01:15,  1.15it/s, loss=0.398]\u001b[A\n",
            "Train step of epoch 0:  65%|██████▌   | 163/250 [02:19<01:15,  1.15it/s, loss=0.558]\u001b[A\n",
            "Train step of epoch 0:  66%|██████▌   | 164/250 [02:20<01:14,  1.15it/s, loss=0.558]\u001b[A\n",
            "Train step of epoch 0:  66%|██████▌   | 164/250 [02:20<01:14,  1.15it/s, loss=0.545]\u001b[A\n",
            "Train step of epoch 0:  66%|██████▌   | 165/250 [02:21<01:13,  1.15it/s, loss=0.545]\u001b[A\n",
            "Train step of epoch 0:  66%|██████▌   | 165/250 [02:21<01:13,  1.15it/s, loss=0.497]\u001b[A\n",
            "Train step of epoch 0:  66%|██████▋   | 166/250 [02:22<01:12,  1.15it/s, loss=0.497]\u001b[A\n",
            "Train step of epoch 0:  66%|██████▋   | 166/250 [02:22<01:12,  1.15it/s, loss=0.336]\u001b[A\n",
            "Train step of epoch 0:  67%|██████▋   | 167/250 [02:23<01:12,  1.15it/s, loss=0.336]\u001b[A\n",
            "Train step of epoch 0:  67%|██████▋   | 167/250 [02:23<01:12,  1.15it/s, loss=0.668]\u001b[A\n",
            "Train step of epoch 0:  67%|██████▋   | 168/250 [02:24<01:11,  1.15it/s, loss=0.668]\u001b[A\n",
            "Train step of epoch 0:  67%|██████▋   | 168/250 [02:24<01:11,  1.15it/s, loss=0.383]\u001b[A\n",
            "Train step of epoch 0:  68%|██████▊   | 169/250 [02:25<01:10,  1.15it/s, loss=0.383]\u001b[A\n",
            "Train step of epoch 0:  68%|██████▊   | 169/250 [02:25<01:10,  1.15it/s, loss=0.277]\u001b[A\n",
            "Train step of epoch 0:  68%|██████▊   | 170/250 [02:26<01:09,  1.15it/s, loss=0.277]\u001b[A\n",
            "Train step of epoch 0:  68%|██████▊   | 170/250 [02:26<01:09,  1.15it/s, loss=0.556]\u001b[A\n",
            "Train step of epoch 0:  68%|██████▊   | 171/250 [02:26<01:08,  1.15it/s, loss=0.556]\u001b[A\n",
            "Train step of epoch 0:  68%|██████▊   | 171/250 [02:26<01:08,  1.15it/s, loss=0.416]\u001b[A\n",
            "Train step of epoch 0:  69%|██████▉   | 172/250 [02:27<01:07,  1.15it/s, loss=0.416]\u001b[A\n",
            "Train step of epoch 0:  69%|██████▉   | 172/250 [02:27<01:07,  1.15it/s, loss=0.976]\u001b[A\n",
            "Train step of epoch 0:  69%|██████▉   | 173/250 [02:28<01:07,  1.15it/s, loss=0.976]\u001b[A\n",
            "Train step of epoch 0:  69%|██████▉   | 173/250 [02:28<01:07,  1.15it/s, loss=0.322]\u001b[A\n",
            "Train step of epoch 0:  70%|██████▉   | 174/250 [02:29<01:06,  1.15it/s, loss=0.322]\u001b[A\n",
            "Train step of epoch 0:  70%|██████▉   | 174/250 [02:29<01:06,  1.15it/s, loss=1.7]  \u001b[A\n",
            "Train step of epoch 0:  70%|███████   | 175/250 [02:30<01:05,  1.15it/s, loss=1.7]\u001b[A\n",
            "Train step of epoch 0:  70%|███████   | 175/250 [02:30<01:05,  1.15it/s, loss=0.405]\u001b[A\n",
            "Train step of epoch 0:  70%|███████   | 176/250 [02:31<01:04,  1.15it/s, loss=0.405]\u001b[A\n",
            "Train step of epoch 0:  70%|███████   | 176/250 [02:31<01:04,  1.15it/s, loss=0.873]\u001b[A\n",
            "Train step of epoch 0:  71%|███████   | 177/250 [02:32<01:03,  1.15it/s, loss=0.873]\u001b[A\n",
            "Train step of epoch 0:  71%|███████   | 177/250 [02:32<01:03,  1.15it/s, loss=0.53] \u001b[A\n",
            "Train step of epoch 0:  71%|███████   | 178/250 [02:33<01:02,  1.15it/s, loss=0.53]\u001b[A\n",
            "Train step of epoch 0:  71%|███████   | 178/250 [02:33<01:02,  1.15it/s, loss=0.903]\u001b[A\n",
            "Train step of epoch 0:  72%|███████▏  | 179/250 [02:33<01:01,  1.15it/s, loss=0.903]\u001b[A\n",
            "Train step of epoch 0:  72%|███████▏  | 179/250 [02:33<01:01,  1.15it/s, loss=0.739]\u001b[A\n",
            "Train step of epoch 0:  72%|███████▏  | 180/250 [02:34<01:00,  1.15it/s, loss=0.739]\u001b[A\n",
            "Train step of epoch 0:  72%|███████▏  | 180/250 [02:34<01:00,  1.15it/s, loss=0.552]\u001b[A\n",
            "Train step of epoch 0:  72%|███████▏  | 181/250 [02:35<01:00,  1.15it/s, loss=0.552]\u001b[A\n",
            "Train step of epoch 0:  72%|███████▏  | 181/250 [02:35<01:00,  1.15it/s, loss=0.453]\u001b[A\n",
            "Train step of epoch 0:  73%|███████▎  | 182/250 [02:36<00:59,  1.15it/s, loss=0.453]\u001b[A\n",
            "Train step of epoch 0:  73%|███████▎  | 182/250 [02:36<00:59,  1.15it/s, loss=0.393]\u001b[A\n",
            "Train step of epoch 0:  73%|███████▎  | 183/250 [02:37<00:58,  1.15it/s, loss=0.393]\u001b[A\n",
            "Train step of epoch 0:  73%|███████▎  | 183/250 [02:37<00:58,  1.15it/s, loss=0.37] \u001b[A\n",
            "Train step of epoch 0:  74%|███████▎  | 184/250 [02:38<00:57,  1.15it/s, loss=0.37]\u001b[A\n",
            "Train step of epoch 0:  74%|███████▎  | 184/250 [02:38<00:57,  1.15it/s, loss=0.551]\u001b[A\n",
            "Train step of epoch 0:  74%|███████▍  | 185/250 [02:39<00:56,  1.15it/s, loss=0.551]\u001b[A\n",
            "Train step of epoch 0:  74%|███████▍  | 185/250 [02:39<00:56,  1.15it/s, loss=0.426]\u001b[A\n",
            "Train step of epoch 0:  74%|███████▍  | 186/250 [02:39<00:55,  1.15it/s, loss=0.426]\u001b[A\n",
            "Train step of epoch 0:  74%|███████▍  | 186/250 [02:40<00:55,  1.15it/s, loss=0.429]\u001b[A\n",
            "Train step of epoch 0:  75%|███████▍  | 187/250 [02:40<00:54,  1.15it/s, loss=0.429]\u001b[A\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train step of epoch 0:  75%|███████▍  | 187/250 [02:40<00:54,  1.15it/s, loss=0.428]\u001b[A\n",
            "Train step of epoch 0:  75%|███████▌  | 188/250 [02:41<00:54,  1.15it/s, loss=0.428]\u001b[A\n",
            "Train step of epoch 0:  75%|███████▌  | 188/250 [02:41<00:54,  1.15it/s, loss=0.504]\u001b[A\n",
            "Train step of epoch 0:  76%|███████▌  | 189/250 [02:42<00:53,  1.15it/s, loss=0.504]\u001b[A\n",
            "Train step of epoch 0:  76%|███████▌  | 189/250 [02:42<00:53,  1.15it/s, loss=0.44] \u001b[A\n",
            "Train step of epoch 0:  76%|███████▌  | 190/250 [02:43<00:52,  1.15it/s, loss=0.44]\u001b[A\n",
            "Train step of epoch 0:  76%|███████▌  | 190/250 [02:43<00:52,  1.15it/s, loss=0.21]\u001b[A\n",
            "Train step of epoch 0:  76%|███████▋  | 191/250 [02:44<00:51,  1.15it/s, loss=0.21]\u001b[A\n",
            "Train step of epoch 0:  76%|███████▋  | 191/250 [02:44<00:51,  1.15it/s, loss=0.5] \u001b[A\n",
            "Train step of epoch 0:  77%|███████▋  | 192/250 [02:45<00:50,  1.15it/s, loss=0.5]\u001b[A\n",
            "Train step of epoch 0:  77%|███████▋  | 192/250 [02:45<00:50,  1.15it/s, loss=0.398]\u001b[A\n",
            "Train step of epoch 0:  77%|███████▋  | 193/250 [02:46<00:49,  1.14it/s, loss=0.398]\u001b[A\n",
            "Train step of epoch 0:  77%|███████▋  | 193/250 [02:46<00:49,  1.14it/s, loss=0.325]\u001b[A\n",
            "Train step of epoch 0:  78%|███████▊  | 194/250 [02:46<00:48,  1.15it/s, loss=0.325]\u001b[A\n",
            "Train step of epoch 0:  78%|███████▊  | 194/250 [02:46<00:48,  1.15it/s, loss=0.826]\u001b[A\n",
            "Train step of epoch 0:  78%|███████▊  | 195/250 [02:47<00:47,  1.15it/s, loss=0.826]\u001b[A\n",
            "Train step of epoch 0:  78%|███████▊  | 195/250 [02:47<00:47,  1.15it/s, loss=0.39] \u001b[A\n",
            "Train step of epoch 0:  78%|███████▊  | 196/250 [02:48<00:47,  1.15it/s, loss=0.39]\u001b[A\n",
            "Train step of epoch 0:  78%|███████▊  | 196/250 [02:48<00:47,  1.15it/s, loss=0.255]\u001b[A\n",
            "Train step of epoch 0:  79%|███████▉  | 197/250 [02:49<00:46,  1.15it/s, loss=0.255]\u001b[A\n",
            "Train step of epoch 0:  79%|███████▉  | 197/250 [02:49<00:46,  1.15it/s, loss=0.728]\u001b[A\n",
            "Train step of epoch 0:  79%|███████▉  | 198/250 [02:50<00:45,  1.15it/s, loss=0.728]\u001b[A\n",
            "Train step of epoch 0:  79%|███████▉  | 198/250 [02:50<00:45,  1.15it/s, loss=0.538]\u001b[A\n",
            "Train step of epoch 0:  80%|███████▉  | 199/250 [02:51<00:44,  1.14it/s, loss=0.538]\u001b[A\n",
            "Train step of epoch 0:  80%|███████▉  | 199/250 [02:51<00:44,  1.14it/s, loss=0.835]\u001b[A\n",
            "Train step of epoch 0:  80%|████████  | 200/250 [02:52<00:43,  1.15it/s, loss=0.835]\u001b[A\n",
            "Train step of epoch 0:  80%|████████  | 200/250 [02:52<00:43,  1.15it/s, loss=0.169]\u001b[A\n",
            "Train step of epoch 0:  80%|████████  | 201/250 [02:53<00:42,  1.15it/s, loss=0.169]\u001b[A\n",
            "Train step of epoch 0:  80%|████████  | 201/250 [02:53<00:42,  1.15it/s, loss=0.291]\u001b[A\n",
            "Train step of epoch 0:  81%|████████  | 202/250 [02:53<00:41,  1.15it/s, loss=0.291]\u001b[A\n",
            "Train step of epoch 0:  81%|████████  | 202/250 [02:53<00:41,  1.15it/s, loss=0.083]\u001b[A\n",
            "Train step of epoch 0:  81%|████████  | 203/250 [02:54<00:41,  1.15it/s, loss=0.083]\u001b[A\n",
            "Train step of epoch 0:  81%|████████  | 203/250 [02:54<00:41,  1.15it/s, loss=0.47] \u001b[A\n",
            "Train step of epoch 0:  82%|████████▏ | 204/250 [02:55<00:40,  1.15it/s, loss=0.47]\u001b[A\n",
            "Train step of epoch 0:  82%|████████▏ | 204/250 [02:55<00:40,  1.15it/s, loss=1.9] \u001b[A\n",
            "Train step of epoch 0:  82%|████████▏ | 205/250 [02:56<00:39,  1.15it/s, loss=1.9]\u001b[A\n",
            "Train step of epoch 0:  82%|████████▏ | 205/250 [02:56<00:39,  1.15it/s, loss=0.804]\u001b[A\n",
            "Train step of epoch 0:  82%|████████▏ | 206/250 [02:57<00:38,  1.15it/s, loss=0.804]\u001b[A\n",
            "Train step of epoch 0:  82%|████████▏ | 206/250 [02:57<00:38,  1.15it/s, loss=0.337]\u001b[A\n",
            "Train step of epoch 0:  83%|████████▎ | 207/250 [02:58<00:37,  1.15it/s, loss=0.337]\u001b[A\n",
            "Train step of epoch 0:  83%|████████▎ | 207/250 [02:58<00:37,  1.15it/s, loss=1.37] \u001b[A\n",
            "Train step of epoch 0:  83%|████████▎ | 208/250 [02:59<00:36,  1.15it/s, loss=1.37]\u001b[A\n",
            "Train step of epoch 0:  83%|████████▎ | 208/250 [02:59<00:36,  1.15it/s, loss=0.163]\u001b[A\n",
            "Train step of epoch 0:  84%|████████▎ | 209/250 [03:00<00:35,  1.15it/s, loss=0.163]\u001b[A\n",
            "Train step of epoch 0:  84%|████████▎ | 209/250 [03:00<00:35,  1.15it/s, loss=0.496]\u001b[A\n",
            "Train step of epoch 0:  84%|████████▍ | 210/250 [03:00<00:34,  1.15it/s, loss=0.496]\u001b[A\n",
            "Train step of epoch 0:  84%|████████▍ | 210/250 [03:00<00:34,  1.15it/s, loss=0.455]\u001b[A\n",
            "Train step of epoch 0:  84%|████████▍ | 211/250 [03:01<00:33,  1.15it/s, loss=0.455]\u001b[A\n",
            "Train step of epoch 0:  84%|████████▍ | 211/250 [03:01<00:33,  1.15it/s, loss=0.717]\u001b[A\n",
            "Train step of epoch 0:  85%|████████▍ | 212/250 [03:02<00:33,  1.15it/s, loss=0.717]\u001b[A\n",
            "Train step of epoch 0:  85%|████████▍ | 212/250 [03:02<00:33,  1.15it/s, loss=0.724]\u001b[A\n",
            "Train step of epoch 0:  85%|████████▌ | 213/250 [03:03<00:32,  1.15it/s, loss=0.724]\u001b[A\n",
            "Train step of epoch 0:  85%|████████▌ | 213/250 [03:03<00:32,  1.15it/s, loss=0.89] \u001b[A\n",
            "Train step of epoch 0:  86%|████████▌ | 214/250 [03:04<00:31,  1.15it/s, loss=0.89]\u001b[A\n",
            "Train step of epoch 0:  86%|████████▌ | 214/250 [03:04<00:31,  1.15it/s, loss=0.643]\u001b[A\n",
            "Train step of epoch 0:  86%|████████▌ | 215/250 [03:05<00:30,  1.15it/s, loss=0.643]\u001b[A\n",
            "Train step of epoch 0:  86%|████████▌ | 215/250 [03:05<00:30,  1.15it/s, loss=0.603]\u001b[A\n",
            "Train step of epoch 0:  86%|████████▋ | 216/250 [03:06<00:29,  1.15it/s, loss=0.603]\u001b[A\n",
            "Train step of epoch 0:  86%|████████▋ | 216/250 [03:06<00:29,  1.15it/s, loss=0.78] \u001b[A\n",
            "Train step of epoch 0:  87%|████████▋ | 217/250 [03:07<00:28,  1.15it/s, loss=0.78]\u001b[A\n",
            "Train step of epoch 0:  87%|████████▋ | 217/250 [03:07<00:28,  1.15it/s, loss=0.728]\u001b[A\n",
            "Train step of epoch 0:  87%|████████▋ | 218/250 [03:07<00:27,  1.15it/s, loss=0.728]\u001b[A\n",
            "Train step of epoch 0:  87%|████████▋ | 218/250 [03:07<00:27,  1.15it/s, loss=0.761]\u001b[A\n",
            "Train step of epoch 0:  88%|████████▊ | 219/250 [03:08<00:27,  1.15it/s, loss=0.761]\u001b[A\n",
            "Train step of epoch 0:  88%|████████▊ | 219/250 [03:08<00:27,  1.15it/s, loss=0.585]\u001b[A\n",
            "Train step of epoch 0:  88%|████████▊ | 220/250 [03:09<00:26,  1.15it/s, loss=0.585]\u001b[A\n",
            "Train step of epoch 0:  88%|████████▊ | 220/250 [03:09<00:26,  1.15it/s, loss=0.695]\u001b[A\n",
            "Train step of epoch 0:  88%|████████▊ | 221/250 [03:10<00:25,  1.15it/s, loss=0.695]\u001b[A\n",
            "Train step of epoch 0:  88%|████████▊ | 221/250 [03:10<00:25,  1.15it/s, loss=0.87] \u001b[A\n",
            "Train step of epoch 0:  89%|████████▉ | 222/250 [03:11<00:24,  1.15it/s, loss=0.87]\u001b[A\n",
            "Train step of epoch 0:  89%|████████▉ | 222/250 [03:11<00:24,  1.15it/s, loss=0.593]\u001b[A\n",
            "Train step of epoch 0:  89%|████████▉ | 223/250 [03:12<00:23,  1.15it/s, loss=0.593]\u001b[A\n",
            "Train step of epoch 0:  89%|████████▉ | 223/250 [03:12<00:23,  1.15it/s, loss=0.6]  \u001b[A\n",
            "Train step of epoch 0:  90%|████████▉ | 224/250 [03:13<00:22,  1.15it/s, loss=0.6]\u001b[A\n",
            "Train step of epoch 0:  90%|████████▉ | 224/250 [03:13<00:22,  1.15it/s, loss=0.692]\u001b[A\n",
            "Train step of epoch 0:  90%|█████████ | 225/250 [03:13<00:21,  1.15it/s, loss=0.692]\u001b[A\n",
            "Train step of epoch 0:  90%|█████████ | 225/250 [03:14<00:21,  1.15it/s, loss=0.661]\u001b[A\n",
            "Train step of epoch 0:  90%|█████████ | 226/250 [03:14<00:20,  1.15it/s, loss=0.661]\u001b[A\n",
            "Train step of epoch 0:  90%|█████████ | 226/250 [03:14<00:20,  1.15it/s, loss=0.651]\u001b[A\n",
            "Train step of epoch 0:  91%|█████████ | 227/250 [03:15<00:20,  1.15it/s, loss=0.651]\u001b[A\n",
            "Train step of epoch 0:  91%|█████████ | 227/250 [03:15<00:20,  1.15it/s, loss=0.541]\u001b[A\n",
            "Train step of epoch 0:  91%|█████████ | 228/250 [03:16<00:19,  1.15it/s, loss=0.541]\u001b[A\n",
            "Train step of epoch 0:  91%|█████████ | 228/250 [03:16<00:19,  1.15it/s, loss=0.631]\u001b[A\n",
            "Train step of epoch 0:  92%|█████████▏| 229/250 [03:17<00:18,  1.15it/s, loss=0.631]\u001b[A\n",
            "Train step of epoch 0:  92%|█████████▏| 229/250 [03:17<00:18,  1.15it/s, loss=0.552]\u001b[A\n",
            "Train step of epoch 0:  92%|█████████▏| 230/250 [03:18<00:17,  1.15it/s, loss=0.552]\u001b[A\n",
            "Train step of epoch 0:  92%|█████████▏| 230/250 [03:18<00:17,  1.15it/s, loss=0.639]\u001b[A\n",
            "Train step of epoch 0:  92%|█████████▏| 231/250 [03:19<00:16,  1.15it/s, loss=0.639]\u001b[A\n",
            "Train step of epoch 0:  92%|█████████▏| 231/250 [03:19<00:16,  1.15it/s, loss=0.625]\u001b[A\n",
            "Train step of epoch 0:  93%|█████████▎| 232/250 [03:20<00:15,  1.15it/s, loss=0.625]\u001b[A\n",
            "Train step of epoch 0:  93%|█████████▎| 232/250 [03:20<00:15,  1.15it/s, loss=0.703]\u001b[A\n",
            "Train step of epoch 0:  93%|█████████▎| 233/250 [03:20<00:14,  1.15it/s, loss=0.703]\u001b[A\n",
            "Train step of epoch 0:  93%|█████████▎| 233/250 [03:20<00:14,  1.15it/s, loss=0.701]\u001b[A\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train step of epoch 0:  94%|█████████▎| 234/250 [03:21<00:13,  1.15it/s, loss=0.701]\u001b[A\n",
            "Train step of epoch 0:  94%|█████████▎| 234/250 [03:21<00:13,  1.15it/s, loss=0.655]\u001b[A\n",
            "Train step of epoch 0:  94%|█████████▍| 235/250 [03:22<00:13,  1.15it/s, loss=0.655]\u001b[A\n",
            "Train step of epoch 0:  94%|█████████▍| 235/250 [03:22<00:13,  1.15it/s, loss=0.561]\u001b[A\n",
            "Train step of epoch 0:  94%|█████████▍| 236/250 [03:23<00:12,  1.15it/s, loss=0.561]\u001b[A\n",
            "Train step of epoch 0:  94%|█████████▍| 236/250 [03:23<00:12,  1.15it/s, loss=0.687]\u001b[A\n",
            "Train step of epoch 0:  95%|█████████▍| 237/250 [03:24<00:11,  1.15it/s, loss=0.687]\u001b[A\n",
            "Train step of epoch 0:  95%|█████████▍| 237/250 [03:24<00:11,  1.15it/s, loss=0.587]\u001b[A\n",
            "Train step of epoch 0:  95%|█████████▌| 238/250 [03:25<00:10,  1.15it/s, loss=0.587]\u001b[A\n",
            "Train step of epoch 0:  95%|█████████▌| 238/250 [03:25<00:10,  1.15it/s, loss=0.66] \u001b[A\n",
            "Train step of epoch 0:  96%|█████████▌| 239/250 [03:26<00:09,  1.15it/s, loss=0.66]\u001b[A\n",
            "Train step of epoch 0:  96%|█████████▌| 239/250 [03:26<00:09,  1.15it/s, loss=0.474]\u001b[A\n",
            "Train step of epoch 0:  96%|█████████▌| 240/250 [03:27<00:08,  1.15it/s, loss=0.474]\u001b[A\n",
            "Train step of epoch 0:  96%|█████████▌| 240/250 [03:27<00:08,  1.15it/s, loss=0.697]\u001b[A\n",
            "Train step of epoch 0:  96%|█████████▋| 241/250 [03:27<00:07,  1.15it/s, loss=0.697]\u001b[A\n",
            "Train step of epoch 0:  96%|█████████▋| 241/250 [03:27<00:07,  1.15it/s, loss=0.615]\u001b[A\n",
            "Train step of epoch 0:  97%|█████████▋| 242/250 [03:28<00:06,  1.15it/s, loss=0.615]\u001b[A\n",
            "Train step of epoch 0:  97%|█████████▋| 242/250 [03:28<00:06,  1.15it/s, loss=0.671]\u001b[A\n",
            "Train step of epoch 0:  97%|█████████▋| 243/250 [03:29<00:06,  1.15it/s, loss=0.671]\u001b[A\n",
            "Train step of epoch 0:  97%|█████████▋| 243/250 [03:29<00:06,  1.15it/s, loss=0.582]\u001b[A\n",
            "Train step of epoch 0:  98%|█████████▊| 244/250 [03:30<00:05,  1.15it/s, loss=0.582]\u001b[A\n",
            "Train step of epoch 0:  98%|█████████▊| 244/250 [03:30<00:05,  1.15it/s, loss=0.977]\u001b[A\n",
            "Train step of epoch 0:  98%|█████████▊| 245/250 [03:31<00:04,  1.15it/s, loss=0.977]\u001b[A\n",
            "Train step of epoch 0:  98%|█████████▊| 245/250 [03:31<00:04,  1.15it/s, loss=0.687]\u001b[A\n",
            "Train step of epoch 0:  98%|█████████▊| 246/250 [03:32<00:03,  1.15it/s, loss=0.687]\u001b[A\n",
            "Train step of epoch 0:  98%|█████████▊| 246/250 [03:32<00:03,  1.15it/s, loss=0.718]\u001b[A\n",
            "Train step of epoch 0:  99%|█████████▉| 247/250 [03:33<00:02,  1.15it/s, loss=0.718]\u001b[A\n",
            "Train step of epoch 0:  99%|█████████▉| 247/250 [03:33<00:02,  1.15it/s, loss=0.71] \u001b[A\n",
            "Train step of epoch 0:  99%|█████████▉| 248/250 [03:34<00:01,  1.15it/s, loss=0.71]\u001b[A\n",
            "Train step of epoch 0:  99%|█████████▉| 248/250 [03:34<00:01,  1.15it/s, loss=0.693]\u001b[A\n",
            "Train step of epoch 0: 100%|█████████▉| 249/250 [03:34<00:00,  1.15it/s, loss=0.693]\u001b[A\n",
            "Train step of epoch 0: 100%|█████████▉| 249/250 [03:34<00:00,  1.15it/s, loss=0.617]\u001b[A\n",
            "Train step of epoch 0: 100%|██████████| 250/250 [03:35<00:00,  1.15it/s, loss=0.617]\u001b[A\n",
            "Train epoch: 100%|██████████| 1/1 [03:49<00:00, 229.91s/it]0,  1.15it/s, loss=0.458]\u001b[A\n",
            "Train step of epoch 0: 100%|██████████| 250/250 [03:49<00:00,  1.09it/s, loss=0.591, dist_mean=0.327]\u001b[A\n",
            "Train epoch: 100%|██████████| 1/1 [03:49<00:00, 229.91s/it]\n"
          ]
        }
      ],
      "source": [
        "trainer.fit(use_lora=0)\n",
        "\n",
        "model.save_pretrained('/aiffel/KoChatGPT/output_2_RM')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5886218e",
      "metadata": {
        "id": "5886218e",
        "outputId": "ca25c2bf-7c67-4bbe-fa89-bb622f8f4e00"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "input: 인공지능은 똥멍청이 입니다\n",
            "reward score: -0.7\n"
          ]
        }
      ],
      "source": [
        "def inference_RM(input_text):\n",
        "    input_ids = tokenizer.encode(input_text, return_tensors='pt').to(\n",
        "        torch.cuda.current_device())\n",
        "    output = model(input_ids)\n",
        "    output_reward = output.cpu().detach().numpy()[0]\n",
        "\n",
        "    print('input: %s\\nreward score: %.1f'%(input_text, output_reward))\n",
        "\n",
        "    return output_reward\n",
        "\n",
        "input_text = '인공지능은 똥멍청이 입니다'\n",
        "output_reward = inference_RM(input_text=input_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d5339694",
      "metadata": {
        "id": "d5339694",
        "outputId": "90d6f63a-f0bb-4cc0-f000-ad44c80708e9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "input: 인공지능(AI)은 컴퓨터에서 음성 및 작성된 언어를 보고 이해하고 번역하고 데이터를 분석하고 추천하는 기능을 포함하여 다양한 고급 기능을 수행할 수 있는 일련의 기술입니다.\n",
            "reward score: -0.5\n"
          ]
        }
      ],
      "source": [
        "input_text = '인공지능(AI)은 컴퓨터에서 음성 및 작성된 언어를 보고 이해하고 번역하고 데이터를 분석하고 추천하는 기능을 포함하여 다양한 고급 기능을 수행할 수 있는 일련의 기술입니다.'\n",
        "output_reward = inference_RM(input_text=input_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "643374c1",
      "metadata": {
        "id": "643374c1",
        "outputId": "b990eab1-cb04-46b1-b7b9-dbd815a042f4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "input: 인공지능은 일반적으로 인간의 지능이 필요하거나 인간이 분석할 수 있는 것보다 규모가 큰 데이터를 포함하는 방식으로 추론, 학습 및 행동할 수 있는 컴퓨터 및 기계를 구축하는 것과 관련된 과학 분야입니다. AI는 컴퓨터 공학, 데이터 분석 및 통계, 하드웨어 및 소프트웨어 엔지니어링, 언어학, 신경 과학은 물론 철학과 심리학을 포함하여 여러 학문을 포괄하는 광범위한 분야입니다. 비즈니스의 운영 수준에서 AI는 주로 머신러닝과 딥 러닝을 기반으로 하는 기술 모음으로, 데이터 분석, 예상 및 예측, 객체 분류, 자연어 처리, 추천, 지능형 데이터 가져오기 등을 수행할 수 있습니다.\n",
            "reward score: -0.1\n"
          ]
        }
      ],
      "source": [
        "input_text = \"인공지능은 일반적으로 인간의 지능이 필요하거나 인간이 분석할 수 있는 것보다 규모가 큰 데이터를 포함하는 방식으로 추론, 학습 및 행동할 수 있는 컴퓨터 및 기계를 구축하는 것과 관련된 과학 분야입니다. AI는 컴퓨터 공학, 데이터 분석 및 통계, 하드웨어 및 소프트웨어 엔지니어링, 언어학, 신경 과학은 물론 철학과 심리학을 포함하여 여러 학문을 포괄하는 광범위한 분야입니다. 비즈니스의 운영 수준에서 AI는 주로 머신러닝과 딥 러닝을 기반으로 하는 기술 모음으로, 데이터 분석, 예상 및 예측, 객체 분류, 자연어 처리, 추천, 지능형 데이터 가져오기 등을 수행할 수 있습니다.\"\n",
        "\n",
        "output_reward = inference_RM(input_text=input_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "65d1e757",
      "metadata": {
        "id": "65d1e757"
      },
      "outputs": [],
      "source": [
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "954d713e",
      "metadata": {
        "id": "954d713e"
      },
      "source": [
        "# PPO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7724248e",
      "metadata": {
        "id": "7724248e"
      },
      "outputs": [],
      "source": [
        "from copy import deepcopy\n",
        "\n",
        "import json\n",
        "\n",
        "import torch\n",
        "from torch.optim import Adam\n",
        "from chatgpt.models.base import RewardModel\n",
        "from chatgpt.models.gpt import GPTActor, GPTCritic\n",
        "from chatgpt.trainer import PPOTrainer\n",
        "from chatgpt.trainer.strategies import NaiveStrategy\n",
        "from transformers import AutoTokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1e26984b",
      "metadata": {
        "id": "1e26984b"
      },
      "outputs": [],
      "source": [
        "with NaiveStrategy().model_init_context():\n",
        "    actor = GPTActor(pretrained='/aiffel/KoChatGPT/output_1_SFT', lora_rank=0).to(torch.cuda.current_device())\n",
        "    critic = GPTCritic(pretrained='/aiffel/KoChatGPT/output_2_RM', lora_rank=0).to(torch.cuda.current_device())\n",
        "\n",
        "    tokenizer = AutoTokenizer.from_pretrained(\n",
        "        'skt/kogpt2-base-v2', bos_token='</s>', eos_token='</s>', unk_token='</s>', pad_token='</s>',\n",
        "        padding_side=\"right\",\n",
        "        model_max_length=512\n",
        "    )\n",
        "\n",
        "    initial_model = deepcopy(actor)\n",
        "    reward_model = RewardModel(deepcopy(critic.model), deepcopy(critic.value_head)).to(torch.cuda.current_device())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b38d5eba",
      "metadata": {
        "id": "b38d5eba"
      },
      "outputs": [],
      "source": [
        "actor_optim = Adam(actor.parameters(), lr=5e-6)\n",
        "critic_optim = Adam(critic.parameters(), lr=5e-6)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ad113f73",
      "metadata": {
        "id": "ad113f73"
      },
      "outputs": [],
      "source": [
        "(actor, actor_optim), (critic, critic_optim), reward_model, initial_model = NaiveStrategy().prepare(\n",
        "    (actor, actor_optim), (critic, critic_optim), reward_model, initial_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3329ba36",
      "metadata": {
        "id": "3329ba36"
      },
      "outputs": [],
      "source": [
        "with open('/aiffel/KoChatGPT/data_kochatgpt/kochatgpt_3_PPO.jsonl', \"r\", encoding='utf-8-sig') as json_file:\n",
        "    list_data_dict = json.load(json_file)\n",
        "    list_prompt = [tmp['prompt'] for tmp in list_data_dict]\n",
        "\n",
        "def tokenize_fn(texts):\n",
        "    batch = tokenizer(texts, return_tensors='pt', max_length=96, padding=True, truncation=True)\n",
        "    return {k: v.cuda() for k, v in batch.items()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ed0b7660",
      "metadata": {
        "id": "ed0b7660",
        "outputId": "90ba1b78-bcf8-4ac4-8950-fab30d6034f8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'input_ids': tensor([[47311, 10448, 19008,  9792, 11780, 11308, 30190, 10929, 11849, 21663,\n",
            "         44389,  9574, 13799,   458, 14308, 12778, 22469, 20938, 44696,   458,\n",
            "         13799,   458, 14308, 12778, 11756, 18944,   389]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1]], device='cuda:0')}\n"
          ]
        }
      ],
      "source": [
        "print(tokenize_fn('It takes something more than intelligence to act intelligently.'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4fb2edd0",
      "metadata": {
        "id": "4fb2edd0",
        "outputId": "46bc9a91-c4e8-4611-8846-2719715088e4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "12000"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(list_prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "393724cd",
      "metadata": {
        "id": "393724cd"
      },
      "outputs": [],
      "source": [
        "trainer = PPOTrainer(NaiveStrategy(),\n",
        "                     actor,\n",
        "                     critic,\n",
        "                     reward_model,\n",
        "                     initial_model,\n",
        "                     actor_optim,\n",
        "                     critic_optim,\n",
        "                     max_epochs=1,\n",
        "                     train_batch_size=8,\n",
        "                     tokenizer=tokenize_fn,\n",
        "                     max_length=128,\n",
        "                     do_sample=True,\n",
        "                     temperature=1.0,\n",
        "                     top_k=50,\n",
        "                     pad_token_id=tokenizer.pad_token_id,\n",
        "                     eos_token_id=tokenizer.eos_token_id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "73118702",
      "metadata": {
        "id": "73118702",
        "outputId": "ec0537f5-3439-4491-d8cd-f0cd8e5e9035"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Episode [1/10]:  67%|██████▋   | 2/3 [00:11<00:05,  5.70s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s, actor_loss=0, critic_loss=0.000215]\u001b[A\n",
            "Train epoch [1/1]:  33%|███▎      | 1/3 [00:00<00:01,  1.94it/s, actor_loss=0, critic_loss=0.000215]\u001b[A\n",
            "Train epoch [1/1]:  33%|███▎      | 1/3 [00:01<00:01,  1.94it/s, actor_loss=0, critic_loss=0.0673]  \u001b[A\n",
            "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:01<00:00,  1.95it/s, actor_loss=0, critic_loss=0.0673]\u001b[A\n",
            "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:01<00:00,  1.95it/s, actor_loss=0, critic_loss=0.00506]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 3/3 [00:01<00:00,  1.95it/s, actor_loss=0, critic_loss=0.00506]\u001b[A\n",
            "Episode [1/10]: 100%|██████████| 3/3 [00:18<00:00,  6.21s/it]\n",
            "Episode [2/10]:  67%|██████▋   | 2/3 [00:11<00:05,  5.79s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s, actor_loss=0.123, critic_loss=0.0116]\u001b[A\n",
            "Train epoch [1/1]:  33%|███▎      | 1/3 [00:00<00:01,  1.88it/s, actor_loss=0.123, critic_loss=0.0116]\u001b[A\n",
            "Train epoch [1/1]:  33%|███▎      | 1/3 [00:01<00:01,  1.88it/s, actor_loss=0.114, critic_loss=0.0425]\u001b[A\n",
            "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:01<00:00,  1.87it/s, actor_loss=0.114, critic_loss=0.0425]\u001b[A\n",
            "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:01<00:00,  1.87it/s, actor_loss=0.119, critic_loss=0.0275]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 3/3 [00:01<00:00,  1.87it/s, actor_loss=0.119, critic_loss=0.0275]\u001b[A\n",
            "Episode [2/10]: 100%|██████████| 3/3 [00:19<00:00,  6.34s/it]\n",
            "Episode [3/10]:  67%|██████▋   | 2/3 [00:12<00:06,  6.07s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s, actor_loss=0.0926, critic_loss=0.0097]\u001b[A\n",
            "Train epoch [1/1]:  33%|███▎      | 1/3 [00:00<00:01,  1.88it/s, actor_loss=0.0926, critic_loss=0.0097]\u001b[A\n",
            "Train epoch [1/1]:  33%|███▎      | 1/3 [00:01<00:01,  1.88it/s, actor_loss=0.0911, critic_loss=0.000276]\u001b[A\n",
            "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:01<00:00,  1.86it/s, actor_loss=0.0911, critic_loss=0.000276]\u001b[A\n",
            "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:01<00:00,  1.86it/s, actor_loss=0.0938, critic_loss=0.00704] \u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 3/3 [00:01<00:00,  1.87it/s, actor_loss=0.0938, critic_loss=0.00704]\u001b[A\n",
            "Episode [3/10]: 100%|██████████| 3/3 [00:19<00:00,  6.58s/it]\n",
            "Episode [4/10]:  67%|██████▋   | 2/3 [00:11<00:05,  5.89s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s, actor_loss=-.129, critic_loss=0.0194]\u001b[A\n",
            "Train epoch [1/1]:  33%|███▎      | 1/3 [00:00<00:01,  1.88it/s, actor_loss=-.129, critic_loss=0.0194]\u001b[A\n",
            "Train epoch [1/1]:  33%|███▎      | 1/3 [00:01<00:01,  1.88it/s, actor_loss=-.125, critic_loss=0.0176]\u001b[A\n",
            "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:01<00:00,  1.88it/s, actor_loss=-.125, critic_loss=0.0176]\u001b[A\n",
            "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:01<00:00,  1.88it/s, actor_loss=-.123, critic_loss=0.00936]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 3/3 [00:01<00:00,  1.88it/s, actor_loss=-.123, critic_loss=0.00936]\u001b[A\n",
            "Episode [4/10]: 100%|██████████| 3/3 [00:19<00:00,  6.37s/it]\n",
            "Episode [5/10]:  67%|██████▋   | 2/3 [00:11<00:05,  5.71s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s, actor_loss=-.0464, critic_loss=0.0034]\u001b[A\n",
            "Train epoch [1/1]:  33%|███▎      | 1/3 [00:00<00:01,  1.88it/s, actor_loss=-.0464, critic_loss=0.0034]\u001b[A\n",
            "Train epoch [1/1]:  33%|███▎      | 1/3 [00:01<00:01,  1.88it/s, actor_loss=-.0421, critic_loss=0.000587]\u001b[A\n",
            "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:01<00:00,  1.90it/s, actor_loss=-.0421, critic_loss=0.000587]\u001b[A\n",
            "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:01<00:00,  1.90it/s, actor_loss=-.0414, critic_loss=0.00616] \u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 3/3 [00:01<00:00,  1.89it/s, actor_loss=-.0414, critic_loss=0.00616]\u001b[A\n",
            "Episode [5/10]: 100%|██████████| 3/3 [00:18<00:00,  6.29s/it]\n",
            "Episode [6/10]:  67%|██████▋   | 2/3 [00:11<00:05,  5.78s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s, actor_loss=0.117, critic_loss=0.0129]\u001b[A\n",
            "Train epoch [1/1]:  33%|███▎      | 1/3 [00:00<00:01,  1.88it/s, actor_loss=0.117, critic_loss=0.0129]\u001b[A\n",
            "Train epoch [1/1]:  33%|███▎      | 1/3 [00:01<00:01,  1.88it/s, actor_loss=0.127, critic_loss=0.0138]\u001b[A\n",
            "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:01<00:00,  1.87it/s, actor_loss=0.127, critic_loss=0.0138]\u001b[A\n",
            "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:01<00:00,  1.87it/s, actor_loss=0.116, critic_loss=0.00652]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 3/3 [00:01<00:00,  1.87it/s, actor_loss=0.116, critic_loss=0.00652]\u001b[A\n",
            "Episode [6/10]: 100%|██████████| 3/3 [00:19<00:00,  6.35s/it]\n",
            "Episode [7/10]:  67%|██████▋   | 2/3 [00:11<00:05,  5.83s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s, actor_loss=0.0192, critic_loss=0.000715]\u001b[A\n",
            "Train epoch [1/1]:  33%|███▎      | 1/3 [00:00<00:01,  1.87it/s, actor_loss=0.0192, critic_loss=0.000715]\u001b[A\n",
            "Train epoch [1/1]:  33%|███▎      | 1/3 [00:01<00:01,  1.87it/s, actor_loss=0.0251, critic_loss=0.001]   \u001b[A\n",
            "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:01<00:00,  1.87it/s, actor_loss=0.0251, critic_loss=0.001]\u001b[A\n",
            "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:01<00:00,  1.87it/s, actor_loss=0.0256, critic_loss=0.004]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 3/3 [00:01<00:00,  1.87it/s, actor_loss=0.0256, critic_loss=0.004]\u001b[A\n",
            "Episode [7/10]: 100%|██████████| 3/3 [00:19<00:00,  6.38s/it]\n",
            "Episode [8/10]:  67%|██████▋   | 2/3 [00:11<00:05,  5.78s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s, actor_loss=-.0721, critic_loss=0.00515]\u001b[A\n",
            "Train epoch [1/1]:  33%|███▎      | 1/3 [00:00<00:01,  1.87it/s, actor_loss=-.0721, critic_loss=0.00515]\u001b[A\n",
            "Train epoch [1/1]:  33%|███▎      | 1/3 [00:01<00:01,  1.87it/s, actor_loss=-.0805, critic_loss=0.00861]\u001b[A\n",
            "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:01<00:00,  1.88it/s, actor_loss=-.0805, critic_loss=0.00861]\u001b[A\n",
            "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:01<00:00,  1.88it/s, actor_loss=-.0827, critic_loss=0.00523]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 3/3 [00:01<00:00,  1.87it/s, actor_loss=-.0827, critic_loss=0.00523]\u001b[A\n",
            "Episode [8/10]: 100%|██████████| 3/3 [00:18<00:00,  6.32s/it]\n",
            "Episode [9/10]:  67%|██████▋   | 2/3 [00:10<00:05,  5.15s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s, actor_loss=-.0256, critic_loss=0.00123]\u001b[A\n",
            "Train epoch [1/1]:  33%|███▎      | 1/3 [00:00<00:01,  1.88it/s, actor_loss=-.0256, critic_loss=0.00123]\u001b[A\n",
            "Train epoch [1/1]:  33%|███▎      | 1/3 [00:01<00:01,  1.88it/s, actor_loss=-.025, critic_loss=0.000618]\u001b[A\n",
            "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:01<00:00,  1.88it/s, actor_loss=-.025, critic_loss=0.000618]\u001b[A\n",
            "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:01<00:00,  1.88it/s, actor_loss=-.0218, critic_loss=0.00408]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 3/3 [00:01<00:00,  1.87it/s, actor_loss=-.0218, critic_loss=0.00408]\u001b[A\n",
            "Episode [9/10]: 100%|██████████| 3/3 [00:17<00:00,  5.94s/it]\n",
            "Episode [10/10]:  67%|██████▋   | 2/3 [00:11<00:05,  5.79s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s, actor_loss=0.0669, critic_loss=0.00497]\u001b[A\n",
            "Train epoch [1/1]:  33%|███▎      | 1/3 [00:00<00:01,  1.87it/s, actor_loss=0.0669, critic_loss=0.00497]\u001b[A\n",
            "Train epoch [1/1]:  33%|███▎      | 1/3 [00:01<00:01,  1.87it/s, actor_loss=0.0588, critic_loss=0.00414]\u001b[A\n",
            "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:01<00:00,  1.88it/s, actor_loss=0.0588, critic_loss=0.00414]\u001b[A\n",
            "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:01<00:00,  1.88it/s, actor_loss=0.0632, critic_loss=0.00108]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 3/3 [00:01<00:00,  1.87it/s, actor_loss=0.0632, critic_loss=0.00108]\u001b[A\n",
            "Episode [10/10]: 100%|██████████| 3/3 [00:17<00:00,  5.84s/it]\n"
          ]
        }
      ],
      "source": [
        "trainer.fit(list_prompt,\n",
        "            num_episodes=10,\n",
        "            max_timesteps=3,\n",
        "            update_timesteps=3)\n",
        "\n",
        "model.save_pretrained('aiffel/KoChatGPT/output_3_PPO')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "212ea4c1",
      "metadata": {
        "id": "212ea4c1"
      },
      "source": [
        "RLHF가 적용된 koGPT-2의 생성능력을 확인해볼까요?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8e9352f2",
      "metadata": {
        "id": "8e9352f2",
        "outputId": "cfff6ec4-6e13-4c12-f05b-4167e7e90cb7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "### Instruction(명령어):\n",
            "르세라핌 데뷔연도는?\n",
            "\n",
            "### Response(응답):'르세라핌 데뷔연도는 2018년입니다. Q, C, E, J, EN, J는 모두 르세라핌 멤버의 이름이며, 이후 K는 2016년에도 이 연애를 하고 있습니다. EN, J는 르세라핌이라는 솔로 가수의 이름으로 불리며, 이후 그 해에 ONA를 상대로 승부에서 승리하였습니다. J는 SKT, K는 SS 멤버로써 KSM 무대에서 다양한 공연을 즐기며 KRC를 이끌어내며 우승을 차지하는데 큰 기여를 하였습니다. J는 KT와 KSM의 데뷔연애를 주도하며, 다양한 무대에서 KT를 빛나게 만든 멤버 중 한 명입니다. J는 KSM의 대표적인 가수로써, SSM의 대표 멤버 중 한 명입니다. KSM의 리더로, C, EN, J은 KSM의 홍보위원으로 참여하여 KSM의 이미지를 확립시키는데 큰 역할을 하였습니다. EN, J는 KSM의 공식 멤버, KSM의 공식 커머스에서 KSM의 브랜드\n",
            "\n",
            "### Instruction(명령어):\n",
            "미세먼지가 얼마나 심할 때 마스크 씁니까?\n",
            "\n",
            "### Response(응답):'미세먼지가 심하다고 느끼기 시작하면 알레르기 반응이 매우 급격하게 올 수 있고, 그 결과가 매우 심각한 알레르기 반응을 발생시킬 수 있습니다. 미세먼지는 대개 호흡기와 기관에 큰 영향을 미치기 때문에 실내에서 오랫동안 실내 생활을 영위하는 경우가 많습니다. 그러나 미세먼지를 제거하는 최선의 방법은 생활 습관을 바꿀 필요가 있는 것을 알려주고, 호흡기와 기관 내부의 청결을 유지하고 미세먼지와 알레르기 유발 물질을 효과적으로 막는 방법 중 하나일 수 있습니다. 또한, 미세먼지 제거 효과도 피부나 호흡기 보호막 역할을 할 수 있으므로, 건강 상태를 수시로 체크하는 것이 좋습니다.現\\n  \\n하지만 이러한 노력에도 불구하고 알레르기 반응이 발생하면 증상이 심할 수 있으며, 각별한 관리가 필요합니다. 적극적인 치료를 위해서는 먼저 환자의 상태를 정확하게 파악하고 그에 맞는 적절한 치료를 받을 수 있는 전문의와 전문의의 진료를 받는 것이 필요합니다. 또한, 미세먼지가 심각할 때는 항히 신경과학의 발견 및 진단을 받는 것이 중요합니다. 특히 대기 중 미세먼지가 매우 심하기 전에 전문의 진료를 받는 것이 좋습니다. 또한, 미세먼지가 매우 심할 때는 전문의\n",
            "\n",
            "### Instruction(명령어):\n",
            "모두의연구소는 어떤 기업입니까?\n",
            "\n",
            "### Response(응답):'모두의연구소는 미국의 바이오벤처인 모네(Morner Institute)의 자회사(Minne)를 소유하고 있습니다. 이 회사의 설립자이기도 했던 모네(Gener)는 1990년대 말에도 모네의 연구소 창업자를 기념하는 기념식에서 모네의 창업자로서 그의 공로를 인정받았습니다. 이후에도 모네는 바이오 벤처와 함께하면서 지속적으로 발전해 왔습니다.作意子)는 주로 바이오 벤처와 바이오 연구 분야에서 활동하고 있으며, 최근에는 바이오 공학 및 바이오 신약 개발에도 참여 중입니다.作意子는 주로 바이오 산업에서 중요한 역할을 합니다.思想官論 硏究作目는 모네의 연구 업적과 업적을 연구함으로써 모네의 연구와 개발을 촉진하고, 이를 통해 모네의 기술을 향상시키고 연구자들의 능력을 향상시키기 위한 것입니다.恩施)은 그의 저서에서는 \"Abidiating abidiatric abidiating abidiatric\"이라는 용어를 사용했습니다.恩施)는 모네의 창업자와 함께하여 많은 연구자들이 그 공로를 높이고, 그들의 성공과 발전을 인정해왔습니다.恩施)는\n",
            "\n",
            "### Instruction(명령어):\n",
            "디지털 헬스케어는 무엇인가요?\n",
            "\n",
            "### Response(응답):'저희 AI 모델은 디지털 헬스케어를 기반으로 작동하며, 사용자가 가지고 있는 관심사에 적합한 서비스를 제공합니다. 예를 들어 의료, 과학, 건강 등 다양한 분야에서 활용되고 있습니다. 이 외에도 다양한 분야에 디지털 헬스케어가 접목하고 있으며, 이를 통해 삶의 질을 개선하고 의료와 경제 분야의 혁신을 이룰 수 있습니다. X-선)은 디지털 헬스케어가 의료나 과학 분야에서 다양하게 사용되는 것을 말합니다. 따라서, 해당 분야의 디지털 헬스케어를 구현하는 것은 매우 혁신적인 분야입니다. X-선은 디지털 헬스케어 분야에 널리 사용됩니다. X-선은 디지털 헬스케어와 관련하여 다양한 분야의 기술이 발전하며 새로운 비즈니스 모델로 발전하고 있습니다. X-선은 디지털 헬스케어와 관련된 서비스 개발을 통해 경제, 의료 분야의 발전과 혁신적인 발전을 이루는 데 크게 기여합니다. X-선은 디지털 헬스케어에 대한 정보와 분석을 제공하는 전문 기술 회사입니다. X-선은 디지털 헬스케어와 관련된 정보를 제공하며, 저희 AI 모델에서 활용되는 디지털 헬스케어 기술은 건강, 사회, 경제, 사회 등의 분야에서 활용됩니다. X-선은 디지털 헬스케어 분야에서 다양한 분야에서 사용되며, 대표적인 기술 중 하나입니다.\n"
          ]
        }
      ],
      "source": [
        "def generation(input_text):\n",
        "    input_ids = tokenizer.encode(input_text, return_tensors='pt').to(\n",
        "        torch.cuda.current_device())\n",
        "    outputs = actor.generate(input_ids,\n",
        "                             max_length=250,\n",
        "                             do_sample=True,\n",
        "                             top_k=50,\n",
        "                             top_p=0.95,\n",
        "                             num_return_sequences=1)\n",
        "    output = tokenizer.batch_decode(outputs[0], skip_special_tokens=True)[0]\n",
        "    print()\n",
        "    print(output)\n",
        "    return output\n",
        "\n",
        "PROMPT_DICT = {\n",
        "    \"prompt_input\": (\n",
        "        \"### Instruction(명령어):\\n{prompt}\\n\\n### Response(응답):\"\n",
        "    )\n",
        "}\n",
        "\n",
        "list_prompt = ['르세라핌 데뷔연도는?',\n",
        "               '미세먼지가 얼마나 심할 때 마스크 씁니까?',\n",
        "               '모두의연구소는 어떤 기업입니까?',\n",
        "               '디지털 헬스케어는 무엇인가요?']\n",
        "\n",
        "list_prompt = [PROMPT_DICT['prompt_input'].format_map({'prompt': tmp}) for tmp in list_prompt]\n",
        "\n",
        "for input_text in list_prompt:\n",
        "    output = generation(input_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e6598a28",
      "metadata": {
        "id": "e6598a28"
      },
      "source": [
        "> 회고록 <br>\n",
        "> chatGPT가 이러한 방식으로 간략히 볼 수 있어서 너무 좋았다. 또한 RLHF를 적용하니, 좀 더 context에 맞는 것들을 생성하고 있었다.\n",
        "하지만 여전히 많이 부족했다. 좀 더 정확히 하기 위해서 여러가지 파라미터들을 바꿔보고, 모델 세부를 바꿔보는 그러한 노력들을 할것 같습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dd038b69",
      "metadata": {
        "id": "dd038b69"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}