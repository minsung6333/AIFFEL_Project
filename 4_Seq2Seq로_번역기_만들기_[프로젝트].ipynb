{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/minsung6333/AIFFEL_Project/blob/main/4_Seq2Seq%EB%A1%9C_%EB%B2%88%EC%97%AD%EA%B8%B0_%EB%A7%8C%EB%93%A4%EA%B8%B0_%5B%ED%94%84%EB%A1%9C%EC%A0%9D%ED%8A%B8%5D.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cf70ebf9",
      "metadata": {
        "id": "cf70ebf9"
      },
      "source": [
        "# Seq2Seq로 번역기 만들기\n",
        "\n",
        "결과를 보고 싶으신 분은 ctrl(cmd)+f를 누르고 '다시 시작'을 색인하시면 됩니다.\n",
        "\n",
        "### 서두에 적는 회고\n",
        "- AI-HUB에 있는 '일상생활 및 구어체 한-영 번역 병렬 말뭉치 데이터'를 사용하여 번역기를 만들었다.\n",
        "- 학습 결과 어떤 문장을 넣어도 i (m, the, have) Company라는 번역문만 출력하는 결과가 보인다.\n",
        "- 이에 대해 대체 어떤 연유로 전청조 스타일로 i'm 회사에요라는 결과값을 내는지 찾지 못했다.\n",
        "- 120만건의 데이터 중 oom문제로 인하여 3만건의 데이터만 불러와서 학습하였다.\n",
        "- 30 epoch로 학습한 모델로 번역을 진행한 결과 동일한 글자가 여러번 나오는 문제가 나와 토큰화를 공백기반으로 진행하여 이러한 결과가 나온줄 알았지만, 다시 학습해보니 형태소 분석 문제는 아니었다. 30epoch 결과와 30만건의 데이터 학습 디버깅은 가장 최하단에 있습니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b040c723",
      "metadata": {
        "id": "b040c723",
        "outputId": "271532f4-cadc-400b-a7e6-87d6cef73d2a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.6.0\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import matplotlib.ticker as ticker\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import time\n",
        "import re\n",
        "import io\n",
        "import os\n",
        "\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5d8dcac2",
      "metadata": {
        "id": "5d8dcac2"
      },
      "outputs": [],
      "source": [
        "data_path = os.getenv('HOME')+'/aiffel/korean_english_aihub'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1795ad92",
      "metadata": {
        "id": "1795ad92"
      },
      "outputs": [],
      "source": [
        "import json, pandas as pd\n",
        "\n",
        "with open(data_path+'/일상생활및구어체_한영_train_set.json') as f:\n",
        "    js = json.loads(f.read()) ## json 라이브러리 이용"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "41ea6cf4",
      "metadata": {
        "id": "41ea6cf4",
        "outputId": "335282fe-7f8d-448b-dbe7-054b1f211cb8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1200000\n",
            "{'sn': 'INTSALDSUT062119042703238', 'data_set': '일상생활및구어체', 'domain': '해외영업', 'subdomain': '도소매유통', 'ko_original': '원하시는 색상을 회신해 주시면 바로 제작 들어가겠습니다.', 'ko': '원하시는 색상을 회신해 주시면 바로 제작 들어가겠습니다.', 'mt': 'If you reply to the color you want, we will start making it right away.', 'en': 'If you reply to the color you want, we will start making it right away.', 'source_language': 'ko', 'target_language': 'en', 'word_count_ko': 7, 'word_count_en': 15, 'word_ratio': 2.143, 'file_name': 'INTSAL_DSUT.xlsx', 'source': '크라우드소싱', 'license': 'open', 'style': '구어체', 'included_unknown_words': False, 'ner': None}\n"
          ]
        }
      ],
      "source": [
        "#AI HUB에서 제공하는 일상생활 및 구어체 한-영 번역 병렬 말뭉치 데이터 데이터 중 train데이터만 사용하고자 함\n",
        "print(len(js['data']))\n",
        "print(js['data'][0]) #여기서 ko가 한국어 원문 , en이 번역, Mt가 기계번역이므로 여기서 사용할 건 Ko,en 두개 변수 사용할 예정"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "856459cf",
      "metadata": {
        "id": "856459cf",
        "outputId": "8bdf916e-f3fb-4df5-8654-a438acb7f469"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sn</th>\n",
              "      <th>data_set</th>\n",
              "      <th>domain</th>\n",
              "      <th>subdomain</th>\n",
              "      <th>ko_original</th>\n",
              "      <th>ko</th>\n",
              "      <th>mt</th>\n",
              "      <th>en</th>\n",
              "      <th>source_language</th>\n",
              "      <th>target_language</th>\n",
              "      <th>word_count_ko</th>\n",
              "      <th>word_count_en</th>\n",
              "      <th>word_ratio</th>\n",
              "      <th>file_name</th>\n",
              "      <th>source</th>\n",
              "      <th>license</th>\n",
              "      <th>style</th>\n",
              "      <th>included_unknown_words</th>\n",
              "      <th>ner</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1199999</th>\n",
              "      <td>KPUS062012215065369</td>\n",
              "      <td>일상생활및구어체</td>\n",
              "      <td>일상생활</td>\n",
              "      <td>구매</td>\n",
              "      <td>&gt;야이, 씨!</td>\n",
              "      <td>&gt;야이, 씨!</td>\n",
              "      <td>Hey, shit!</td>\n",
              "      <td>&gt;See?</td>\n",
              "      <td>ko</td>\n",
              "      <td>en</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0.5</td>\n",
              "      <td>구매_KPUS.xlsx</td>\n",
              "      <td>SBS</td>\n",
              "      <td>open</td>\n",
              "      <td>구어체</td>\n",
              "      <td>False</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                          sn  data_set domain subdomain ko_original       ko  \\\n",
              "1199999  KPUS062012215065369  일상생활및구어체   일상생활        구매     >야이, 씨!  >야이, 씨!   \n",
              "\n",
              "                 mt     en source_language target_language  word_count_ko  \\\n",
              "1199999  Hey, shit!  >See?              ko              en              2   \n",
              "\n",
              "         word_count_en  word_ratio     file_name source license style  \\\n",
              "1199999              1         0.5  구매_KPUS.xlsx    SBS    open   구어체   \n",
              "\n",
              "         included_unknown_words   ner  \n",
              "1199999                   False  None  "
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.DataFrame(js['data'])\n",
        "df.head()\n",
        "df.tail(1) #야이, 씨가 en 번역으로 see?..기계번역이 조금 더 정확한 것 같은데.. 믿어도 될려나"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "44ab0069",
      "metadata": {
        "id": "44ab0069",
        "outputId": "b50aeee4-0cd7-4753-cba5-0227f9406aa4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "710693"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.iloc[757851]\n",
        "len(df[df['mt']==df['en']]) #기계번역과 영어번역이 동일한 경우 약 71만개"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cde7f68f",
      "metadata": {
        "id": "cde7f68f",
        "outputId": "ac668494-3d49-4ada-e18f-165191d39a2b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ko</th>\n",
              "      <th>en</th>\n",
              "      <th>mt</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>형님 제일 웃긴 그림이 뭔지 알아요.</td>\n",
              "      <td>You know what the funniest picture is.</td>\n",
              "      <td>I know what the funniest picture is.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>&gt;속옷을?</td>\n",
              "      <td>&gt;Underwear?</td>\n",
              "      <td>Underwear?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>그래도 가격이 꽤 비싸니까 많이 살게요.</td>\n",
              "      <td>I wont buy a lot though since the price is sti...</td>\n",
              "      <td>However, the price is quite high, so I will bu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>AAA님, 제가 회의에서 화를 냈던 점 정말 사과드리고 싶습니다.</td>\n",
              "      <td>Dear AAA, I really want to apologize for my an...</td>\n",
              "      <td>AAA, I really want to apologize for being upse...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>예 이게 빅데이터 빅이네요.</td>\n",
              "      <td>Yes, the is big data is big.</td>\n",
              "      <td>Yes, this is Big Data Big.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>귀사와의 계약을 취소함에 대해 죄송하게 생각하며, 이에 대한 양해를 구합니다.</td>\n",
              "      <td>We apologize for canceling the contract with y...</td>\n",
              "      <td>We apologize for the cancellation of our contr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>&gt;제가 이걸 보여드리겠습니다.</td>\n",
              "      <td>&gt;Let me show you this.</td>\n",
              "      <td>Let me show you this.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>냉동 만두 주문 의향이 있으시다면 알림 설정을 해주십시오.</td>\n",
              "      <td>If you are willing to order frozen dumplings, ...</td>\n",
              "      <td>If you are interested in ordering frozen dumpl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>우리는 미래를 위한 새로운 솔루션을 제안하기 위해 오래되고 검증된 개념을 채택했습니다.</td>\n",
              "      <td>We have taken old, proven concept to come up w...</td>\n",
              "      <td>We have adopted old and proven concepts to pro...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>&gt;지금도, 지금도 보면 다들 고개를 끄덕끄덕했잖아.</td>\n",
              "      <td>&gt; Even now, everyone is nodding.</td>\n",
              "      <td>&gt; Even now, if you look at it now, everyone no...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>&gt;하다가 못 하겠으면 얘기해요, 포기.</td>\n",
              "      <td>&gt;Let me know if you can't do it, just give up.</td>\n",
              "      <td>Let me know if you can't, give up.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>&gt;형, 뭐야?</td>\n",
              "      <td>&gt;Bro, what's that?</td>\n",
              "      <td>&gt; Hyung, what is this way?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>안녕하세요, 저는 BBB 주방용품 제조사의 AAA 대표이고, 귀사로부터 당사의 신제...</td>\n",
              "      <td>Hi, I am AAA representative of BBB Kitchenware...</td>\n",
              "      <td>Hello, I am the AAA representative of a BBB ki...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>&gt;와우영미.</td>\n",
              "      <td>&gt; WaWooYoungmi.</td>\n",
              "      <td>&gt; Wow, Woo Youngmi.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>유연성은 강철 구조의 주요 장점입니다.</td>\n",
              "      <td>Flexibility is the main advantages of steel st...</td>\n",
              "      <td>Flexibility is the main advantage of steel con...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>&gt;여러분, 이제 두 번째 미션인데요.</td>\n",
              "      <td>&gt;Everyone, this is the second mission.</td>\n",
              "      <td>Everyone, this is the second mission.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>&gt;그래요.</td>\n",
              "      <td>&gt; Okay.</td>\n",
              "      <td>&gt;Yes.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>FFF제품을 500개 주문하였을 때와 1000개 주문하였을 때 견적을 요청하셨는데요.</td>\n",
              "      <td>You asked for an estimate when you ordered 500...</td>\n",
              "      <td>You requested a quote when you ordered 500 FFF...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>&gt;아, OK, OK.</td>\n",
              "      <td>&gt;Oh, okay, okay.</td>\n",
              "      <td>Oh, okay, okay.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>&gt;야, 석진이 형 뒤에 안 했다.</td>\n",
              "      <td>&gt;Hey, Seok-jin didn't do it behind.</td>\n",
              "      <td>&gt; Hey, Seokjin didn't do it behind him.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>&gt;그렇죠?</td>\n",
              "      <td>&gt;Right?</td>\n",
              "      <td>&gt; Right?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>&gt;뭐, 뭐.</td>\n",
              "      <td>&gt;What, what.</td>\n",
              "      <td>&gt; What, what.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>네트워킹 이벤트는 코로나19로 대면 활동이 제한된 환경 속에서 네트워킹과 정보 공유...</td>\n",
              "      <td>Networking events are created for people who c...</td>\n",
              "      <td>Networking events are organized for residents ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>없어도 돼요.</td>\n",
              "      <td>I don't need it.</td>\n",
              "      <td>You don't need it.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50</th>\n",
              "      <td>여기 맞구나.</td>\n",
              "      <td>Here it is.</td>\n",
              "      <td>It's here.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>58</th>\n",
              "      <td>나는 도매가로 농산물을 좀 사고 싶었다.</td>\n",
              "      <td>I was hoping to buy some agricultural goods in...</td>\n",
              "      <td>I wanted to buy some agricultural products at ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65</th>\n",
              "      <td>&gt;아니, 그런 게 아니고 얘는 그냥 심심하면 나오더라고.</td>\n",
              "      <td>&gt;No, it's not like that, he just comes out whe...</td>\n",
              "      <td>&gt; No, it's not like that. He just comes out wh...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>66</th>\n",
              "      <td>&gt;안 뭐지?</td>\n",
              "      <td>&gt;He's An.. what is it?</td>\n",
              "      <td>&gt;What is it?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69</th>\n",
              "      <td>&gt;할 얘기 없다, 할 얘기 없다.</td>\n",
              "      <td>&gt;Nothing to say, nothing to say.</td>\n",
              "      <td>&gt;I have nothing to say, nothing to say.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>71</th>\n",
              "      <td>&gt;아프고 그리고 막 살이 빠져 있고 그러면 이 사람은 정말 내가 아니면 안 되는구나.</td>\n",
              "      <td>&gt;If he gets sick and lose weight, then this pe...</td>\n",
              "      <td>&gt; If you get sick and lose weight, then this p...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>74</th>\n",
              "      <td>저도 한 세 번 걸렸던 것 같습니다.</td>\n",
              "      <td>I think I got caught about 3 times, too.</td>\n",
              "      <td>I think I got caught about three times, too.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>76</th>\n",
              "      <td>&gt;그거부터 시작, 사소한 것부터 시작해서 뭐 난 오늘 슬쩍 저기 산이나 가고 싶은데.</td>\n",
              "      <td>&gt;Starting with that, starting with the little ...</td>\n",
              "      <td>&gt;Starting with that, starting with the little ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>79</th>\n",
              "      <td>최근 제품 주문량이 급증해서 이에 대해 직접 뵙고 설명해 드려야 할 것 같습니다.</td>\n",
              "      <td>Recently, the number of product orders has soa...</td>\n",
              "      <td>Due to the recent surge in product orders, I t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>80</th>\n",
              "      <td>더 알고 싶은 것이 있으면 다시 연락 주세요.</td>\n",
              "      <td>Please contact us again if there is anything e...</td>\n",
              "      <td>If you would like to know more, please contact...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>83</th>\n",
              "      <td>네, 제가 주문한 게 그거예요!</td>\n",
              "      <td>Yes, that's the one that I ordered!</td>\n",
              "      <td>Yes, that's what I ordered!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>86</th>\n",
              "      <td>같은 팀 직원에게 정말 평이 좋은 식당 정보를 미리 알아두었습니다.</td>\n",
              "      <td>I knew in advance the restaurant information t...</td>\n",
              "      <td>I already knew information about restaurants t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>87</th>\n",
              "      <td>&gt;마.</td>\n",
              "      <td>&gt;Ma.</td>\n",
              "      <td>\"Ma.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88</th>\n",
              "      <td>이번에 다양한 스텐 서빙카 주문에 대한 정확한 납기 기일을 문의하고자 연락 드렸습니다.</td>\n",
              "      <td>I'm contacting you to inquire about the exact ...</td>\n",
              "      <td>This time, we have contacted you to inquire ab...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>89</th>\n",
              "      <td>맘스 하우스.</td>\n",
              "      <td>Mom's house.</td>\n",
              "      <td>Mom's House.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>93</th>\n",
              "      <td>그러면 이제 옆에 이제 보면 이렇게 창문이 있으니까 창문으로 이렇게, 이렇게 봤어요...</td>\n",
              "      <td>And we looked her through the windown like thi...</td>\n",
              "      <td>Then, if you look next to you, there is a wind...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>&gt;눈치 챘구나?</td>\n",
              "      <td>&gt;You picked up on that, huh?</td>\n",
              "      <td>&gt; You got it, huh?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>미끼를 던졌다고 해야 되나?</td>\n",
              "      <td>Should I say that you threw the bait?</td>\n",
              "      <td>Should I say that I threw the bait?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>방금 해당하는 파일을 보내드렸습니다만, 다른 궁금하신 신제품은 없으신가요?</td>\n",
              "      <td>I just sent you the corresponding file, but is...</td>\n",
              "      <td>We have just sent you the relevant file, but d...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100</th>\n",
              "      <td>&gt;빨리, 빨리.</td>\n",
              "      <td>&gt;Quick, quick.</td>\n",
              "      <td>&gt;Hurry up. Hurry up.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>102</th>\n",
              "      <td>&gt;대박이다.</td>\n",
              "      <td>&gt;That's awesome.</td>\n",
              "      <td>&gt; That's awesome.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>106</th>\n",
              "      <td>그의 말에 따르면, 당신의 식품 보조 식품은 품질이 우수하고 가격이 저렴하다고 합니다.</td>\n",
              "      <td>According to him, your food supplements were h...</td>\n",
              "      <td>According to him, your food supplements are of...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>107</th>\n",
              "      <td>불편함을 끼쳐 죄송합니다.</td>\n",
              "      <td>I'm sorry for the inconvenience.</td>\n",
              "      <td>Sorry for the inconvenience.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>112</th>\n",
              "      <td>제가 운전이 서툴러서 주차할 때 어려움이 많습니다.</td>\n",
              "      <td>I am not good at driving. I'm having difficult...</td>\n",
              "      <td>I have a lot of difficulties when parking beca...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>113</th>\n",
              "      <td>나는 그들이 게임에 그렇게 애착을 가지길 원하지 않는다.</td>\n",
              "      <td>I don't want them to get so attached to games</td>\n",
              "      <td>I don't want them to be so attached to the game.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>116</th>\n",
              "      <td>넘어갈 질문이 이런 거예요.</td>\n",
              "      <td>This is the question that needs to pass.</td>\n",
              "      <td>This is the next question.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                    ko  \\\n",
              "1                                 형님 제일 웃긴 그림이 뭔지 알아요.   \n",
              "2                                                >속옷을?   \n",
              "3                               그래도 가격이 꽤 비싸니까 많이 살게요.   \n",
              "4                 AAA님, 제가 회의에서 화를 냈던 점 정말 사과드리고 싶습니다.   \n",
              "7                                      예 이게 빅데이터 빅이네요.   \n",
              "9          귀사와의 계약을 취소함에 대해 죄송하게 생각하며, 이에 대한 양해를 구합니다.   \n",
              "10                                    >제가 이걸 보여드리겠습니다.   \n",
              "13                    냉동 만두 주문 의향이 있으시다면 알림 설정을 해주십시오.   \n",
              "16    우리는 미래를 위한 새로운 솔루션을 제안하기 위해 오래되고 검증된 개념을 채택했습니다.   \n",
              "18                        >지금도, 지금도 보면 다들 고개를 끄덕끄덕했잖아.   \n",
              "19                               >하다가 못 하겠으면 얘기해요, 포기.   \n",
              "24                                             >형, 뭐야?   \n",
              "25   안녕하세요, 저는 BBB 주방용품 제조사의 AAA 대표이고, 귀사로부터 당사의 신제...   \n",
              "26                                              >와우영미.   \n",
              "29                               유연성은 강철 구조의 주요 장점입니다.   \n",
              "30                                >여러분, 이제 두 번째 미션인데요.   \n",
              "32                                               >그래요.   \n",
              "36     FFF제품을 500개 주문하였을 때와 1000개 주문하였을 때 견적을 요청하셨는데요.   \n",
              "38                                         >아, OK, OK.   \n",
              "40                                  >야, 석진이 형 뒤에 안 했다.   \n",
              "44                                               >그렇죠?   \n",
              "46                                              >뭐, 뭐.   \n",
              "47   네트워킹 이벤트는 코로나19로 대면 활동이 제한된 환경 속에서 네트워킹과 정보 공유...   \n",
              "48                                             없어도 돼요.   \n",
              "50                                             여기 맞구나.   \n",
              "58                              나는 도매가로 농산물을 좀 사고 싶었다.   \n",
              "65                     >아니, 그런 게 아니고 얘는 그냥 심심하면 나오더라고.   \n",
              "66                                              >안 뭐지?   \n",
              "69                                  >할 얘기 없다, 할 얘기 없다.   \n",
              "71     >아프고 그리고 막 살이 빠져 있고 그러면 이 사람은 정말 내가 아니면 안 되는구나.   \n",
              "74                                저도 한 세 번 걸렸던 것 같습니다.   \n",
              "76     >그거부터 시작, 사소한 것부터 시작해서 뭐 난 오늘 슬쩍 저기 산이나 가고 싶은데.   \n",
              "79       최근 제품 주문량이 급증해서 이에 대해 직접 뵙고 설명해 드려야 할 것 같습니다.   \n",
              "80                           더 알고 싶은 것이 있으면 다시 연락 주세요.   \n",
              "83                                   네, 제가 주문한 게 그거예요!   \n",
              "86               같은 팀 직원에게 정말 평이 좋은 식당 정보를 미리 알아두었습니다.   \n",
              "87                                                 >마.   \n",
              "88    이번에 다양한 스텐 서빙카 주문에 대한 정확한 납기 기일을 문의하고자 연락 드렸습니다.   \n",
              "89                                             맘스 하우스.   \n",
              "93   그러면 이제 옆에 이제 보면 이렇게 창문이 있으니까 창문으로 이렇게, 이렇게 봤어요...   \n",
              "96                                            >눈치 챘구나?   \n",
              "97                                     미끼를 던졌다고 해야 되나?   \n",
              "98           방금 해당하는 파일을 보내드렸습니다만, 다른 궁금하신 신제품은 없으신가요?   \n",
              "100                                           >빨리, 빨리.   \n",
              "102                                             >대박이다.   \n",
              "106   그의 말에 따르면, 당신의 식품 보조 식품은 품질이 우수하고 가격이 저렴하다고 합니다.   \n",
              "107                                     불편함을 끼쳐 죄송합니다.   \n",
              "112                       제가 운전이 서툴러서 주차할 때 어려움이 많습니다.   \n",
              "113                    나는 그들이 게임에 그렇게 애착을 가지길 원하지 않는다.   \n",
              "116                                    넘어갈 질문이 이런 거예요.   \n",
              "\n",
              "                                                    en  \\\n",
              "1               You know what the funniest picture is.   \n",
              "2                                          >Underwear?   \n",
              "3    I wont buy a lot though since the price is sti...   \n",
              "4    Dear AAA, I really want to apologize for my an...   \n",
              "7                         Yes, the is big data is big.   \n",
              "9    We apologize for canceling the contract with y...   \n",
              "10                              >Let me show you this.   \n",
              "13   If you are willing to order frozen dumplings, ...   \n",
              "16   We have taken old, proven concept to come up w...   \n",
              "18                    > Even now, everyone is nodding.   \n",
              "19      >Let me know if you can't do it, just give up.   \n",
              "24                                  >Bro, what's that?   \n",
              "25   Hi, I am AAA representative of BBB Kitchenware...   \n",
              "26                                     > WaWooYoungmi.   \n",
              "29   Flexibility is the main advantages of steel st...   \n",
              "30              >Everyone, this is the second mission.   \n",
              "32                                             > Okay.   \n",
              "36   You asked for an estimate when you ordered 500...   \n",
              "38                                    >Oh, okay, okay.   \n",
              "40                 >Hey, Seok-jin didn't do it behind.   \n",
              "44                                             >Right?   \n",
              "46                                        >What, what.   \n",
              "47   Networking events are created for people who c...   \n",
              "48                                    I don't need it.   \n",
              "50                                         Here it is.   \n",
              "58   I was hoping to buy some agricultural goods in...   \n",
              "65   >No, it's not like that, he just comes out whe...   \n",
              "66                              >He's An.. what is it?   \n",
              "69                    >Nothing to say, nothing to say.   \n",
              "71   >If he gets sick and lose weight, then this pe...   \n",
              "74            I think I got caught about 3 times, too.   \n",
              "76   >Starting with that, starting with the little ...   \n",
              "79   Recently, the number of product orders has soa...   \n",
              "80   Please contact us again if there is anything e...   \n",
              "83                 Yes, that's the one that I ordered!   \n",
              "86   I knew in advance the restaurant information t...   \n",
              "87                                                >Ma.   \n",
              "88   I'm contacting you to inquire about the exact ...   \n",
              "89                                        Mom's house.   \n",
              "93   And we looked her through the windown like thi...   \n",
              "96                        >You picked up on that, huh?   \n",
              "97               Should I say that you threw the bait?   \n",
              "98   I just sent you the corresponding file, but is...   \n",
              "100                                     >Quick, quick.   \n",
              "102                                   >That's awesome.   \n",
              "106  According to him, your food supplements were h...   \n",
              "107                   I'm sorry for the inconvenience.   \n",
              "112  I am not good at driving. I'm having difficult...   \n",
              "113      I don't want them to get so attached to games   \n",
              "116           This is the question that needs to pass.   \n",
              "\n",
              "                                                    mt  \n",
              "1                 I know what the funniest picture is.  \n",
              "2                                           Underwear?  \n",
              "3    However, the price is quite high, so I will bu...  \n",
              "4    AAA, I really want to apologize for being upse...  \n",
              "7                           Yes, this is Big Data Big.  \n",
              "9    We apologize for the cancellation of our contr...  \n",
              "10                               Let me show you this.  \n",
              "13   If you are interested in ordering frozen dumpl...  \n",
              "16   We have adopted old and proven concepts to pro...  \n",
              "18   > Even now, if you look at it now, everyone no...  \n",
              "19                  Let me know if you can't, give up.  \n",
              "24                          > Hyung, what is this way?  \n",
              "25   Hello, I am the AAA representative of a BBB ki...  \n",
              "26                                 > Wow, Woo Youngmi.  \n",
              "29   Flexibility is the main advantage of steel con...  \n",
              "30               Everyone, this is the second mission.  \n",
              "32                                               >Yes.  \n",
              "36   You requested a quote when you ordered 500 FFF...  \n",
              "38                                     Oh, okay, okay.  \n",
              "40             > Hey, Seokjin didn't do it behind him.  \n",
              "44                                            > Right?  \n",
              "46                                       > What, what.  \n",
              "47   Networking events are organized for residents ...  \n",
              "48                                  You don't need it.  \n",
              "50                                          It's here.  \n",
              "58   I wanted to buy some agricultural products at ...  \n",
              "65   > No, it's not like that. He just comes out wh...  \n",
              "66                                        >What is it?  \n",
              "69             >I have nothing to say, nothing to say.  \n",
              "71   > If you get sick and lose weight, then this p...  \n",
              "74        I think I got caught about three times, too.  \n",
              "76   >Starting with that, starting with the little ...  \n",
              "79   Due to the recent surge in product orders, I t...  \n",
              "80   If you would like to know more, please contact...  \n",
              "83                         Yes, that's what I ordered!  \n",
              "86   I already knew information about restaurants t...  \n",
              "87                                                \"Ma.  \n",
              "88   This time, we have contacted you to inquire ab...  \n",
              "89                                        Mom's House.  \n",
              "93   Then, if you look next to you, there is a wind...  \n",
              "96                                  > You got it, huh?  \n",
              "97                 Should I say that I threw the bait?  \n",
              "98   We have just sent you the relevant file, but d...  \n",
              "100                               >Hurry up. Hurry up.  \n",
              "102                                  > That's awesome.  \n",
              "106  According to him, your food supplements are of...  \n",
              "107                       Sorry for the inconvenience.  \n",
              "112  I have a lot of difficulties when parking beca...  \n",
              "113   I don't want them to be so attached to the game.  \n",
              "116                         This is the next question.  "
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#기계번역과 영어번역이 다른 경우를 확인해 봤는데 큰 차이는 없는 것 같다.\n",
        "dif = df[df['mt']!=df['en']]\n",
        "dif[['ko','en','mt']].head(50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f22897ee",
      "metadata": {
        "id": "f22897ee",
        "outputId": "3d85921e-2aaa-4f15-8e22-7b24cfd287fc"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ko</th>\n",
              "      <th>en</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>원하시는 색상을 회신해 주시면 바로 제작 들어가겠습니다.</td>\n",
              "      <td>If you reply to the color you want, we will st...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>형님 제일 웃긴 그림이 뭔지 알아요.</td>\n",
              "      <td>You know what the funniest picture is.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>&gt;속옷을?</td>\n",
              "      <td>&gt;Underwear?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>그래도 가격이 꽤 비싸니까 많이 살게요.</td>\n",
              "      <td>I wont buy a lot though since the price is sti...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>AAA님, 제가 회의에서 화를 냈던 점 정말 사과드리고 싶습니다.</td>\n",
              "      <td>Dear AAA, I really want to apologize for my an...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99995</th>\n",
              "      <td>우리는 우리 제품에 대한 할랄 자격증을 취득하는 데 어려움을 겪고 있습니다.</td>\n",
              "      <td>We are having a trouble getting Halal certific...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99996</th>\n",
              "      <td>그럼 수의학 통계 자료는 어느 분께 드리면 될까요?</td>\n",
              "      <td>Then, to whom should I give the statistics for...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99997</th>\n",
              "      <td>저희는 해당 사안을 파악한 뒤 곧바로 해당 직원을 해고하였습니다.</td>\n",
              "      <td>We immediately fired the employee after identi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99998</th>\n",
              "      <td>현재 귀사는 관광여관을 매우 높은 가격에 납품하고 있습니다.</td>\n",
              "      <td>Currently, your company supplies tourist inns ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99999</th>\n",
              "      <td>&gt;네.</td>\n",
              "      <td>&gt;Yes.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100000 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               ko  \\\n",
              "0                 원하시는 색상을 회신해 주시면 바로 제작 들어가겠습니다.   \n",
              "1                            형님 제일 웃긴 그림이 뭔지 알아요.   \n",
              "2                                           >속옷을?   \n",
              "3                          그래도 가격이 꽤 비싸니까 많이 살게요.   \n",
              "4            AAA님, 제가 회의에서 화를 냈던 점 정말 사과드리고 싶습니다.   \n",
              "...                                           ...   \n",
              "99995  우리는 우리 제품에 대한 할랄 자격증을 취득하는 데 어려움을 겪고 있습니다.   \n",
              "99996                그럼 수의학 통계 자료는 어느 분께 드리면 될까요?   \n",
              "99997        저희는 해당 사안을 파악한 뒤 곧바로 해당 직원을 해고하였습니다.   \n",
              "99998           현재 귀사는 관광여관을 매우 높은 가격에 납품하고 있습니다.   \n",
              "99999                                         >네.   \n",
              "\n",
              "                                                      en  \n",
              "0      If you reply to the color you want, we will st...  \n",
              "1                 You know what the funniest picture is.  \n",
              "2                                            >Underwear?  \n",
              "3      I wont buy a lot though since the price is sti...  \n",
              "4      Dear AAA, I really want to apologize for my an...  \n",
              "...                                                  ...  \n",
              "99995  We are having a trouble getting Halal certific...  \n",
              "99996  Then, to whom should I give the statistics for...  \n",
              "99997  We immediately fired the employee after identi...  \n",
              "99998  Currently, your company supplies tourist inns ...  \n",
              "99999                                              >Yes.  \n",
              "\n",
              "[100000 rows x 2 columns]"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 120만개의 데이터 중에 상위 30만개를 사용하고자 함\n",
        "# 5어절 미만의 문장도 학습에 크게 상관 없을 것 같아서 일단 상위 30만개로 데이터 선정\n",
        "# 30만개 결과 oom발생으로 인한 데이터 축소..\n",
        "df[['ko','en']].iloc[:100000]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a676d370",
      "metadata": {
        "id": "a676d370"
      },
      "outputs": [],
      "source": [
        "#영어/한국어 데이터 전처리 정규표현식에 ㄱ부터 힣까지 추가\n",
        "#숫자가 필요한 경우도 있기에 숫자도 포함\n",
        "#문장 앞뒤 Start, end 시퀀스 생성\n",
        "def preprocess_sentence(sentence, s_token=False, e_token=False):\n",
        "    sentence = sentence.lower().strip()\n",
        "\n",
        "    sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
        "    sentence = re.sub(r'[\" \"]+', \" \", sentence)\n",
        "    sentence = re.sub(r\"[^a-zA-Z?.!,ㄱ-ㅎ가-힣0-9]+\", \" \", sentence)\n",
        "\n",
        "    sentence = sentence.strip()\n",
        "\n",
        "    if s_token:\n",
        "        sentence = '<start> ' + sentence\n",
        "\n",
        "    if e_token:\n",
        "        sentence += ' <end>'\n",
        "\n",
        "    return sentence\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "be0578d0",
      "metadata": {
        "id": "be0578d0",
        "outputId": "caae3e4b-3a11-4af8-eddf-3a796286ab64"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ko</th>\n",
              "      <th>en</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>원하시는 색상을 회신해 주시면 바로 제작 들어가겠습니다.</td>\n",
              "      <td>If you reply to the color you want, we will st...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>형님 제일 웃긴 그림이 뭔지 알아요.</td>\n",
              "      <td>You know what the funniest picture is.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>&gt;속옷을?</td>\n",
              "      <td>&gt;Underwear?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>그래도 가격이 꽤 비싸니까 많이 살게요.</td>\n",
              "      <td>I wont buy a lot though since the price is sti...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>AAA님, 제가 회의에서 화를 냈던 점 정말 사과드리고 싶습니다.</td>\n",
              "      <td>Dear AAA, I really want to apologize for my an...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                     ko  \\\n",
              "0       원하시는 색상을 회신해 주시면 바로 제작 들어가겠습니다.   \n",
              "1                  형님 제일 웃긴 그림이 뭔지 알아요.   \n",
              "2                                 >속옷을?   \n",
              "3                그래도 가격이 꽤 비싸니까 많이 살게요.   \n",
              "4  AAA님, 제가 회의에서 화를 냈던 점 정말 사과드리고 싶습니다.   \n",
              "\n",
              "                                                  en  \n",
              "0  If you reply to the color you want, we will st...  \n",
              "1             You know what the funniest picture is.  \n",
              "2                                        >Underwear?  \n",
              "3  I wont buy a lot though since the price is sti...  \n",
              "4  Dear AAA, I really want to apologize for my an...  "
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data = df[['ko','en']].iloc[:30000] #데이터 추출\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e2699563",
      "metadata": {
        "id": "e2699563",
        "outputId": "b3d59636-3d94-42c5-fedc-68b8f16c091b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "네 .\n",
            "yes .\n"
          ]
        }
      ],
      "source": [
        "#숫자 필요한 예시\n",
        "#30만개 기준때 작업한 거\n",
        "print(preprocess_sentence(data['ko'][99999]))\n",
        "print(preprocess_sentence(data['en'][99999]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "86cd9184",
      "metadata": {
        "id": "86cd9184",
        "outputId": "b46d30fb-bc5c-493d-adea-e4b8ac2d455c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 30000/30000 [00:01<00:00, 19774.22it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "kor: 빨리 , 빨리 .\n",
            "eng: <start> quick , quick . <end>\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "kor_corpus = []\n",
        "eng_corpus = []\n",
        "\n",
        "for i in tqdm(range(len(data))):\n",
        "    kor_corpus.append(preprocess_sentence(data['ko'][i]))\n",
        "    eng_corpus.append(preprocess_sentence(data['en'][i], s_token=True, e_token=True))\n",
        "\n",
        "print(\"kor:\", kor_corpus[100])   # go away !\n",
        "print(\"eng:\", eng_corpus[100])   # <start> salga de aqu ! <end>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0bc51c10",
      "metadata": {
        "id": "0bc51c10"
      },
      "outputs": [],
      "source": [
        "#토큰화\n",
        "def tokenize(corpus):\n",
        "    tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='')\n",
        "    tokenizer.fit_on_texts(corpus)\n",
        "\n",
        "    tensor = tokenizer.texts_to_sequences(corpus)\n",
        "\n",
        "    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, padding='post')\n",
        "\n",
        "    return tensor, tokenizer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f3fc6f71",
      "metadata": {
        "id": "f3fc6f71"
      },
      "outputs": [],
      "source": [
        "#데이터 토큰화 처리 및 데이터 셋 분할 진행\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "kor_tokenizer = tokenize(kor_corpus)[1]\n",
        "eng_tokenizer = tokenize(eng_corpus)[1]\n",
        "\n",
        "kor_tensor = tokenize(kor_corpus)[0]\n",
        "eng_tensor = tokenize(eng_corpus)[0]\n",
        "\n",
        "kor_train, kor_val, eng_train, eng_val = \\\n",
        "train_test_split(kor_tensor, eng_tensor, test_size=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1ac9460c",
      "metadata": {
        "id": "1ac9460c",
        "outputId": "0c066086-95fb-4074-d2c8-128484ef7f3d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([ 413, 1147, 1523,  196,   80,  856, 5759,    1,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0], dtype=int32)"
            ]
          },
          "execution_count": 86,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "kor_tensor[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "81d30aaf",
      "metadata": {
        "id": "81d30aaf",
        "outputId": "d5139917-c701-48cd-bef3-8a588872cdbc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "슝~\n"
          ]
        }
      ],
      "source": [
        "class BahdanauAttention(tf.keras.layers.Layer):\n",
        "    def __init__(self, units):\n",
        "        super(BahdanauAttention, self).__init__()\n",
        "        self.w_dec = tf.keras.layers.Dense(units)\n",
        "        self.w_enc = tf.keras.layers.Dense(units)\n",
        "        self.w_com = tf.keras.layers.Dense(1)\n",
        "\n",
        "    def call(self, h_enc, h_dec):\n",
        "        # h_enc shape: [batch x length x units]\n",
        "        # h_dec shape: [batch x units]\n",
        "\n",
        "        h_enc = self.w_enc(h_enc)\n",
        "        h_dec = tf.expand_dims(h_dec, 1)\n",
        "        h_dec = self.w_dec(h_dec)\n",
        "\n",
        "        score = self.w_com(tf.nn.tanh(h_dec + h_enc))\n",
        "\n",
        "        attn = tf.nn.softmax(score, axis=1)\n",
        "\n",
        "        context_vec = attn * h_enc\n",
        "        context_vec = tf.reduce_sum(context_vec, axis=1)\n",
        "\n",
        "        return context_vec, attn\n",
        "\n",
        "print(\"슝~\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "15050e56",
      "metadata": {
        "id": "15050e56"
      },
      "outputs": [],
      "source": [
        "class Encoder(tf.keras.Model):\n",
        "    def __init__(self, vocab_size, embedding_dim, enc_units):\n",
        "        super(Encoder, self).__init__()\n",
        "\n",
        "        self.enc_units = enc_units\n",
        "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "        self.gru = tf.keras.layers.GRU(enc_units,\n",
        "                                       return_sequences=True)\n",
        "\n",
        "    def call(self, x):\n",
        "        out = self.embedding(x)\n",
        "        out = self.gru(out)\n",
        "\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f955b3b4",
      "metadata": {
        "id": "f955b3b4"
      },
      "outputs": [],
      "source": [
        "class Decoder(tf.keras.Model):\n",
        "    def __init__(self, vocab_size, embedding_dim, dec_units):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.dec_units = dec_units\n",
        "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "        self.gru = tf.keras.layers.GRU(dec_units,\n",
        "                                       return_sequences=True,\n",
        "                                       return_state=True)\n",
        "        self.fc = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "        self.attention = BahdanauAttention(self.dec_units)\n",
        "\n",
        "    def call(self, x, h_dec, enc_out):\n",
        "        context_vec, attn = self.attention(enc_out, h_dec)\n",
        "\n",
        "        out = self.embedding(x)\n",
        "        out = tf.concat([tf.expand_dims(context_vec, 1), out], axis=-1)\n",
        "\n",
        "        out, h_dec = self.gru(out)\n",
        "        out = tf.reshape(out, (-1, out.shape[2]))\n",
        "        out = self.fc(out)\n",
        "\n",
        "        return out, h_dec, attn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "71987bf1",
      "metadata": {
        "id": "71987bf1",
        "outputId": "027c2e4c-daba-4f1b-ffcf-4a76b3d1c3fb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Encoder Output: (64, 30, 1024)\n",
            "Decoder Output: (64, 13921)\n",
            "Decoder Hidden State: (64, 1024)\n",
            "Attention: (64, 30, 1)\n"
          ]
        }
      ],
      "source": [
        "# 코드를 실행하세요.\n",
        "\n",
        "BATCH_SIZE     = 64\n",
        "SRC_VOCAB_SIZE = len(kor_tokenizer.index_word) + 1\n",
        "TGT_VOCAB_SIZE = len(eng_tokenizer.index_word) + 1\n",
        "\n",
        "units         = 1024 #데이터 10만개 기준 256\n",
        "embedding_dim = 512 #데이터 10만개 기준 256\n",
        "\n",
        "encoder = Encoder(SRC_VOCAB_SIZE, embedding_dim, units)\n",
        "decoder = Decoder(TGT_VOCAB_SIZE, embedding_dim, units)\n",
        "\n",
        "# sample input\n",
        "sequence_len = 30 #문장길이 분포 최대 30어절\n",
        "\n",
        "sample_kor = tf.random.uniform((BATCH_SIZE, sequence_len))\n",
        "sample_output = encoder(sample_kor)\n",
        "\n",
        "print ('Encoder Output:', sample_output.shape)\n",
        "\n",
        "sample_state = tf.random.uniform((BATCH_SIZE, units))\n",
        "\n",
        "sample_logits, h_dec, attn = decoder(tf.random.uniform((BATCH_SIZE, 1)),\n",
        "                                     sample_state, sample_output)\n",
        "\n",
        "print ('Decoder Output:', sample_logits.shape)\n",
        "print ('Decoder Hidden State:', h_dec.shape)\n",
        "print ('Attention:', attn.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "72ab0a73",
      "metadata": {
        "id": "72ab0a73",
        "outputId": "bdb66dd0-9cc5-4d16-8f45-70d98beb3e48"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "슝~\n"
          ]
        }
      ],
      "source": [
        "#옵티마이저 및 로스\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits=True, reduction='none')\n",
        "\n",
        "def loss_function(real, pred):\n",
        "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "    loss = loss_object(real, pred)\n",
        "\n",
        "    mask = tf.cast(mask, dtype=loss.dtype)\n",
        "    loss *= mask\n",
        "\n",
        "    return tf.reduce_mean(loss)\n",
        "\n",
        "print(\"슝~\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2b7ee240",
      "metadata": {
        "id": "2b7ee240",
        "outputId": "d15ffcde-3b29-4d50-9be5-311e847dd763"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "슝~\n"
          ]
        }
      ],
      "source": [
        "#train step\n",
        "@tf.function\n",
        "def train_step(src, tgt, encoder, decoder, optimizer, dec_tok):\n",
        "    bsz = src.shape[0]\n",
        "    loss = 0\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "        kor_out = encoder(src)\n",
        "        h_dec = kor_out[:, -1]\n",
        "\n",
        "        dec_src = tf.expand_dims([dec_tok.word_index['<start>']] * bsz, 1)\n",
        "\n",
        "        for t in range(1, tgt.shape[1]):\n",
        "            pred, h_dec, _ = decoder(dec_src, h_dec, kor_out)\n",
        "\n",
        "            loss += loss_function(tgt[:, t], pred)\n",
        "            dec_src = tf.expand_dims(tgt[:, t], 1)\n",
        "\n",
        "    batch_loss = (loss / int(tgt.shape[1]))\n",
        "\n",
        "    variables = encoder.trainable_variables + decoder.trainable_variables\n",
        "    gradients = tape.gradient(loss, variables)\n",
        "    optimizer.apply_gradients(zip(gradients, variables))\n",
        "\n",
        "    return batch_loss\n",
        "\n",
        "print(\"슝~\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f198d2f3",
      "metadata": {
        "id": "f198d2f3",
        "outputId": "f369715d-4e25-490e-d6db-f31e9dbe3f8d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Once deleted, variables cannot be recovered. Proceed (y/[n])? y\n"
          ]
        }
      ],
      "source": [
        "# %reset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4558dddd",
      "metadata": {
        "id": "4558dddd",
        "outputId": "953c1f6a-b452-4418-cbd1-c4384ab4f746"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch  1: 100%|██████████| 375/375 [04:20<00:00,  1.44it/s, Loss 1.0285]\n",
            "Test Epoch  1: 100%|██████████| 94/94 [01:00<00:00,  1.55it/s, Test Loss 1.0456]\n",
            "Epoch  2: 100%|██████████| 375/375 [04:20<00:00,  1.44it/s, Loss 0.9893]\n",
            "Test Epoch  2: 100%|██████████| 94/94 [00:24<00:00,  3.82it/s, Test Loss 1.0209]\n",
            "Epoch  3: 100%|██████████| 375/375 [04:19<00:00,  1.44it/s, Loss 0.9534]\n",
            "Test Epoch  3: 100%|██████████| 94/94 [00:24<00:00,  3.82it/s, Test Loss 1.0061]\n",
            "Epoch  4: 100%|██████████| 375/375 [04:20<00:00,  1.44it/s, Loss 0.9239]\n",
            "Test Epoch  4: 100%|██████████| 94/94 [00:24<00:00,  3.81it/s, Test Loss 0.9966]\n",
            "Epoch  5: 100%|██████████| 375/375 [04:20<00:00,  1.44it/s, Loss 0.8949]\n",
            "Test Epoch  5: 100%|██████████| 94/94 [00:24<00:00,  3.81it/s, Test Loss 0.9889]\n",
            "Epoch  6: 100%|██████████| 375/375 [04:20<00:00,  1.44it/s, Loss 0.8686]\n",
            "Test Epoch  6: 100%|██████████| 94/94 [00:24<00:00,  3.81it/s, Test Loss 0.9793]\n",
            "Epoch  7: 100%|██████████| 375/375 [04:20<00:00,  1.44it/s, Loss 0.8434]\n",
            "Test Epoch  7: 100%|██████████| 94/94 [00:24<00:00,  3.80it/s, Test Loss 0.9714]\n",
            "Epoch  8: 100%|██████████| 375/375 [04:20<00:00,  1.44it/s, Loss 0.8179]\n",
            "Test Epoch  8: 100%|██████████| 94/94 [00:24<00:00,  3.81it/s, Test Loss 0.9685]\n",
            "Epoch  9: 100%|██████████| 375/375 [04:20<00:00,  1.44it/s, Loss 0.7926]\n",
            "Test Epoch  9: 100%|██████████| 94/94 [00:24<00:00,  3.81it/s, Test Loss 0.9691]\n",
            "Epoch 10: 100%|██████████| 375/375 [04:20<00:00,  1.44it/s, Loss 0.7679]\n",
            "Test Epoch 10: 100%|██████████| 94/94 [00:24<00:00,  3.82it/s, Test Loss 0.9639]\n",
            "Epoch 11: 100%|██████████| 375/375 [04:20<00:00,  1.44it/s, Loss 0.7438]\n",
            "Test Epoch 11: 100%|██████████| 94/94 [00:24<00:00,  3.81it/s, Test Loss 0.9653]\n",
            "Epoch 12: 100%|██████████| 375/375 [04:20<00:00,  1.44it/s, Loss 0.7190]\n",
            "Test Epoch 12: 100%|██████████| 94/94 [00:24<00:00,  3.81it/s, Test Loss 0.9682]\n",
            "Epoch 13: 100%|██████████| 375/375 [04:20<00:00,  1.44it/s, Loss 0.6941]\n",
            "Test Epoch 13: 100%|██████████| 94/94 [00:24<00:00,  3.80it/s, Test Loss 0.9720]\n",
            "Epoch 14: 100%|██████████| 375/375 [04:20<00:00,  1.44it/s, Loss 0.6684]\n",
            "Test Epoch 14: 100%|██████████| 94/94 [00:24<00:00,  3.80it/s, Test Loss 0.9778]\n",
            "Epoch 15: 100%|██████████| 375/375 [04:20<00:00,  1.44it/s, Loss 0.6428]\n",
            "Test Epoch 15: 100%|██████████| 94/94 [00:24<00:00,  3.80it/s, Test Loss 0.9850]\n",
            "Epoch 16: 100%|██████████| 375/375 [04:20<00:00,  1.44it/s, Loss 0.6166]\n",
            "Test Epoch 16: 100%|██████████| 94/94 [00:24<00:00,  3.81it/s, Test Loss 0.9894]\n",
            "Epoch 17: 100%|██████████| 375/375 [04:20<00:00,  1.44it/s, Loss 0.5928]\n",
            "Test Epoch 17: 100%|██████████| 94/94 [00:24<00:00,  3.80it/s, Test Loss 0.9980]\n",
            "Epoch 18: 100%|██████████| 375/375 [04:20<00:00,  1.44it/s, Loss 0.5661]\n",
            "Test Epoch 18: 100%|██████████| 94/94 [00:24<00:00,  3.80it/s, Test Loss 1.0070]\n",
            "Epoch 19: 100%|██████████| 375/375 [04:20<00:00,  1.44it/s, Loss 0.5400]\n",
            "Test Epoch 19: 100%|██████████| 94/94 [00:24<00:00,  3.80it/s, Test Loss 1.0191]\n",
            "Epoch 20: 100%|██████████| 375/375 [04:20<00:00,  1.44it/s, Loss 0.5167]\n",
            "Test Epoch 20: 100%|██████████| 94/94 [00:24<00:00,  3.81it/s, Test Loss 1.0226]\n",
            "Epoch 21: 100%|██████████| 375/375 [04:20<00:00,  1.44it/s, Loss 0.4921]\n",
            "Test Epoch 21: 100%|██████████| 94/94 [00:24<00:00,  3.80it/s, Test Loss 1.0367]\n",
            "Epoch 22: 100%|██████████| 375/375 [04:20<00:00,  1.44it/s, Loss 0.4702]\n",
            "Test Epoch 22: 100%|██████████| 94/94 [00:24<00:00,  3.80it/s, Test Loss 1.0445]\n",
            "Epoch 23: 100%|██████████| 375/375 [04:20<00:00,  1.44it/s, Loss 0.4493]\n",
            "Test Epoch 23: 100%|██████████| 94/94 [00:24<00:00,  3.80it/s, Test Loss 1.0550]\n",
            "Epoch 24: 100%|██████████| 375/375 [04:20<00:00,  1.44it/s, Loss 0.4275]\n",
            "Test Epoch 24: 100%|██████████| 94/94 [00:24<00:00,  3.81it/s, Test Loss 1.0665]\n",
            "Epoch 25: 100%|██████████| 375/375 [04:20<00:00,  1.44it/s, Loss 0.4081]\n",
            "Test Epoch 25: 100%|██████████| 94/94 [00:24<00:00,  3.80it/s, Test Loss 1.0773]\n",
            "Epoch 26: 100%|██████████| 375/375 [04:20<00:00,  1.44it/s, Loss 0.3876]\n",
            "Test Epoch 26: 100%|██████████| 94/94 [00:24<00:00,  3.80it/s, Test Loss 1.0893]\n",
            "Epoch 27: 100%|██████████| 375/375 [04:20<00:00,  1.44it/s, Loss 0.3720]\n",
            "Test Epoch 27: 100%|██████████| 94/94 [00:24<00:00,  3.80it/s, Test Loss 1.1048]\n",
            "Epoch 28: 100%|██████████| 375/375 [04:20<00:00,  1.44it/s, Loss 0.3520]\n",
            "Test Epoch 28: 100%|██████████| 94/94 [00:24<00:00,  3.80it/s, Test Loss 1.1124]\n",
            "Epoch 29: 100%|██████████| 375/375 [04:20<00:00,  1.44it/s, Loss 0.3345]\n",
            "Test Epoch 29: 100%|██████████| 94/94 [00:24<00:00,  3.80it/s, Test Loss 1.1328]\n",
            "Epoch 30: 100%|██████████| 375/375 [04:20<00:00,  1.44it/s, Loss 0.3174]\n",
            "Test Epoch 30: 100%|██████████| 94/94 [00:24<00:00,  3.80it/s, Test Loss 1.1393]\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "\n",
        "@tf.function\n",
        "def eval_step(src, tgt, encoder, decoder, eng_tok):\n",
        "    bsz = src.shape[0]\n",
        "    loss = 0\n",
        "\n",
        "    kor_out = encoder(src)\n",
        "\n",
        "    h_dec = kor_out[:, -1]\n",
        "\n",
        "    eng_src = tf.expand_dims([eng_tok.word_index['<start>']] * bsz, 1)\n",
        "\n",
        "    for t in range(1, tgt.shape[1]):\n",
        "        pred, h_dec, _ = decoder(eng_src, h_dec, kor_out)\n",
        "\n",
        "        loss += loss_function(tgt[:, t], pred)\n",
        "        eng_src = tf.expand_dims(tgt[:, t], 1)\n",
        "\n",
        "    batch_loss = (loss / int(tgt.shape[1]))\n",
        "\n",
        "    return batch_loss\n",
        "\n",
        "\n",
        "# Training Process\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "EPOCHS = 30\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    total_loss = 0\n",
        "\n",
        "    idx_list = list(range(0, kor_train.shape[0], BATCH_SIZE))\n",
        "    random.shuffle(idx_list)\n",
        "    t = tqdm(idx_list)\n",
        "\n",
        "    for (batch, idx) in enumerate(t):\n",
        "        batch_loss = train_step(kor_train[idx:idx+BATCH_SIZE],\n",
        "                                eng_train[idx:idx+BATCH_SIZE],\n",
        "                                encoder,\n",
        "                                decoder,\n",
        "                                optimizer,\n",
        "                                eng_tokenizer)\n",
        "\n",
        "        total_loss += batch_loss\n",
        "\n",
        "        t.set_description_str('Epoch %2d' % (epoch + 1))\n",
        "        t.set_postfix_str('Loss %.4f' % (total_loss.numpy() / (batch + 1)))\n",
        "\n",
        "    test_loss = 0\n",
        "\n",
        "    idx_list = list(range(0, kor_val.shape[0], BATCH_SIZE))\n",
        "    random.shuffle(idx_list)\n",
        "    t = tqdm(idx_list)\n",
        "\n",
        "    for (test_batch, idx) in enumerate(t):\n",
        "        test_batch_loss = eval_step(kor_val[idx:idx+BATCH_SIZE],\n",
        "                                    eng_val[idx:idx+BATCH_SIZE],\n",
        "                                    encoder,\n",
        "                                    decoder,\n",
        "                                    eng_tokenizer)\n",
        "\n",
        "        test_loss += test_batch_loss\n",
        "\n",
        "        t.set_description_str('Test Epoch %2d' % (epoch + 1))\n",
        "        t.set_postfix_str('Test Loss %.4f' % (test_loss.numpy() / (test_batch + 1)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8ca72fa8",
      "metadata": {
        "id": "8ca72fa8",
        "outputId": "f4e28ca8-4024-4f12-e719-b888964c1c9d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input: 이거 번역이 잘 되려나 모르겠네\n",
            "Predicted translation: this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_31/4071588706.py:45: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
            "  ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
            "/tmp/ipykernel_31/4071588706.py:46: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
            "  ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
            "/opt/conda/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:240: RuntimeWarning: Glyph 51060 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/opt/conda/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:240: RuntimeWarning: Glyph 44144 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/opt/conda/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:240: RuntimeWarning: Glyph 48264 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/opt/conda/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:240: RuntimeWarning: Glyph 50669 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/opt/conda/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:240: RuntimeWarning: Glyph 51096 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/opt/conda/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:240: RuntimeWarning: Glyph 46104 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/opt/conda/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:240: RuntimeWarning: Glyph 47140 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/opt/conda/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:240: RuntimeWarning: Glyph 45208 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/opt/conda/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:240: RuntimeWarning: Glyph 47784 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/opt/conda/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:240: RuntimeWarning: Glyph 47476 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/opt/conda/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:240: RuntimeWarning: Glyph 44192 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/opt/conda/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:240: RuntimeWarning: Glyph 45348 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/opt/conda/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:203: RuntimeWarning: Glyph 51060 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/opt/conda/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:203: RuntimeWarning: Glyph 44144 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/opt/conda/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:203: RuntimeWarning: Glyph 48264 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/opt/conda/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:203: RuntimeWarning: Glyph 50669 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/opt/conda/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:203: RuntimeWarning: Glyph 51096 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/opt/conda/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:203: RuntimeWarning: Glyph 46104 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/opt/conda/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:203: RuntimeWarning: Glyph 47140 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/opt/conda/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:203: RuntimeWarning: Glyph 45208 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/opt/conda/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:203: RuntimeWarning: Glyph 47784 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/opt/conda/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:203: RuntimeWarning: Glyph 47476 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/opt/conda/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:203: RuntimeWarning: Glyph 44192 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/opt/conda/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:203: RuntimeWarning: Glyph 45348 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "def evaluate(sentence, encoder, decoder):\n",
        "    attention = np.zeros((eng_train.shape[-1], kor_train.shape[-1]))\n",
        "\n",
        "    sentence = preprocess_sentence(sentence)\n",
        "    inputs = kor_tokenizer.texts_to_sequences([sentence.split()])\n",
        "    inputs = tf.keras.preprocessing.sequence.pad_sequences(inputs,\n",
        "                                                           maxlen=kor_train.shape[-1],\n",
        "                                                           padding='post')\n",
        "\n",
        "    result = ''\n",
        "\n",
        "    kor_out = encoder(inputs)\n",
        "\n",
        "    eng_hidden = kor_out[:, -1]\n",
        "    eng_input = tf.expand_dims([eng_tokenizer.word_index['<start>']], 0)\n",
        "\n",
        "    for t in range(eng_train.shape[-1]):\n",
        "        predictions, eng_hidden, attention_weights = decoder(eng_input,\n",
        "                                                             eng_hidden,\n",
        "                                                             kor_out)\n",
        "\n",
        "        attention_weights = tf.reshape(attention_weights, (-1, ))\n",
        "        attention[t] = attention_weights.numpy()\n",
        "\n",
        "        predicted_id = \\\n",
        "        tf.argmax(tf.math.softmax(predictions, axis=-1)[0]).numpy()\n",
        "\n",
        "        result += eng_tokenizer.index_word[predicted_id] + ' '\n",
        "\n",
        "        if eng_tokenizer.index_word[predicted_id] == '<end>':\n",
        "            return result, sentence, attention\n",
        "\n",
        "        dec_input = tf.expand_dims([predicted_id], 0)\n",
        "\n",
        "    return result, sentence, attention\n",
        "\n",
        "\n",
        "def plot_attention(attention, sentence, predicted_sentence):\n",
        "    fig = plt.figure(figsize=(10,10))\n",
        "    ax = fig.add_subplot(1, 1, 1)\n",
        "    ax.matshow(attention, cmap='viridis')\n",
        "\n",
        "    fontdict = {'fontsize': 14}\n",
        "\n",
        "    ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
        "    ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
        "\n",
        "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def translate(sentence, encoder, decoder):\n",
        "    result, sentence, attention = evaluate(sentence, encoder, decoder)\n",
        "\n",
        "    print('Input: %s' % (sentence))\n",
        "    print('Predicted translation: {}'.format(result))\n",
        "\n",
        "    attention = attention[:len(result.split()), :len(sentence.split())]\n",
        "    plot_attention(attention, sentence.split(), result.split(' '))\n",
        "\n",
        "\n",
        "translate(\"이거 번역이 잘 되려나 모르겠네\", encoder, decoder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "922d23ca",
      "metadata": {
        "id": "922d23ca",
        "outputId": "2fe5066c-426e-4689-94b3-d26ed52328f9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input: 나는 괜찮아\n",
            "Predicted translation: it it it it it it it it it it it it it it it it it it it it it it it it it it it it it it it it it it it it it it it it it it it it it it it it it it it it it it it it it it it it it \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_31/4071588706.py:45: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
            "  ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
            "/tmp/ipykernel_31/4071588706.py:46: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
            "  ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.rcParams[\"font.family\"] = \"NanumGothic\" #맑은 고딕으로 폰트 변경\n",
        "translate(\"나는 괜찮아\", encoder, decoder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "be614df9",
      "metadata": {
        "id": "be614df9"
      },
      "outputs": [],
      "source": [
        "from matplotlib import font_manager\n",
        "for font in font_manager.fontManager.ttflist:\n",
        "    if 'Malgun' in font.name:\n",
        "        print(font.name, font.fname)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e3370f9a",
      "metadata": {
        "id": "e3370f9a",
        "outputId": "280c3e84-9323-4e33-ace1-dc7dd04102d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Once deleted, variables cannot be recovered. Proceed (y/[n])? y\n"
          ]
        }
      ],
      "source": [
        "#커널 죽어버렸네..\n",
        "#데이터 축소할게요..\n",
        "#데이터 10만개는 돌아갈만 하지 않나..?\n",
        "#아 왜!\n",
        "# print('ㅜㅜ')\n",
        "%reset"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "463ab768",
      "metadata": {
        "id": "463ab768"
      },
      "source": [
        "# 다시 시작"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dbb4e36c",
      "metadata": {
        "id": "dbb4e36c",
        "outputId": "5f5fbe25-c69b-4ac7-adb7-b4e69d65cee1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 30000/30000 [00:01<00:00, 29351.25it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "kor: 빨리 , 빨리 .\n",
            "eng: <start> quick , quick . <end>\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "import json, pandas as pd\n",
        "from konlpy.tag import Mecab\n",
        "\n",
        "\n",
        "\n",
        "data_path = os.getenv('HOME')+'/aiffel/korean_english_aihub' #파일경로설정\n",
        "\n",
        "with open(data_path+'/일상생활및구어체_한영_train_set.json') as f:\n",
        "    js = json.loads(f.read()) ## json 라이브러리 이용\n",
        "\n",
        "\n",
        "num_data = 30000\n",
        "\n",
        "df = pd.DataFrame(js['data']) #데이터 프레임 생성\n",
        "data = df[['ko','en']].iloc[:num_data] #데이터 추출\n",
        "\n",
        "enc_corpus = []\n",
        "dec_corpus = []\n",
        "\n",
        "for i in tqdm(range(len(data))):\n",
        "    enc_corpus.append((preprocess_sentence(data['ko'][i])))\n",
        "    dec_corpus.append(preprocess_sentence(data['en'][i], s_token=True, e_token=True))\n",
        "\n",
        "print(\"kor:\", enc_corpus[100])   # go away !\n",
        "print(\"eng:\", dec_corpus[100])   # <start> salga de aqu ! <end>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1af3a592",
      "metadata": {
        "id": "1af3a592",
        "outputId": "d6366637-b32f-4e30-a5b5-5a34a933c71a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 30000/30000 [00:04<00:00, 7427.87it/s] \n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "mec = Mecab()\n",
        "\n",
        "mec.morphs(enc_corpus[0])\n",
        "\n",
        "X_mec_test = []\n",
        "for sentence in tqdm(enc_corpus):\n",
        "    tokenized_sentence = mec.morphs(sentence) # 토큰화\n",
        "#     stopwords_removed_sentence = [word for word in tokenized_sentence if not word in stopwords] # 불용어 제거\n",
        "    X_mec_test.append(tokenized_sentence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3f05688e",
      "metadata": {
        "id": "3f05688e"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "\n",
        "# X_mec_test[:3]\n",
        "enc_tokenizer = Tokenizer()\n",
        "enc_tokenizer.fit_on_texts(X_mec_test)\n",
        "enc_tensor = enc_tokenizer.texts_to_sequences(X_mec_test)\n",
        "enc_tensor = tf.keras.preprocessing.sequence.pad_sequences(enc_tensor, padding='post')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "74c7d297",
      "metadata": {
        "id": "74c7d297"
      },
      "outputs": [],
      "source": [
        "#토큰화 이부분에서 한국어 부분만 따로 처리해야함\n",
        "def tokenize(corpus):\n",
        "    tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='')\n",
        "    tokenizer.fit_on_texts(corpus)\n",
        "\n",
        "    tensor = tokenizer.texts_to_sequences(corpus)\n",
        "\n",
        "    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, padding='post')\n",
        "\n",
        "    return tensor, tokenizer\n",
        "\n",
        "\n",
        "#데이터 토큰화 처리 및 데이터 셋 분할 진행\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# kor_tokenizer = tokenize(kor_corpus)[1]\n",
        "dec_tokenizer = tokenize(dec_corpus)[1]\n",
        "\n",
        "# kor_tensor = tokenize(kor_corpus)[0]\n",
        "dec_tensor = tokenize(dec_corpus)[0]\n",
        "\n",
        "enc_train, enc_val, dec_train, dec_val = \\\n",
        "train_test_split(enc_tensor, dec_tensor, test_size=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "57168135",
      "metadata": {
        "id": "57168135",
        "outputId": "b1260999-af09-485d-e60a-e620bb9d2c17"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[ 188,    3,   27, ...,    0,    0,    0],\n",
              "       [ 128,   53,  849, ...,    0,    0,    0],\n",
              "       [5636,    2,   16, ...,    0,    0,    0],\n",
              "       ...,\n",
              "       [  93,    8,   48, ...,    0,    0,    0],\n",
              "       [ 280, 1356,    2, ...,    0,    0,    0],\n",
              "       [ 581,    4,   15, ...,    0,    0,    0]], dtype=int32)"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "enc_tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e1aa170d",
      "metadata": {
        "id": "e1aa170d"
      },
      "outputs": [],
      "source": [
        "#bahdanau_attention\n",
        "class BahdanauAttention(tf.keras.layers.Layer):\n",
        "    def __init__(self, units):\n",
        "        super(BahdanauAttention, self).__init__()\n",
        "        self.w_dec = tf.keras.layers.Dense(units)\n",
        "        self.w_enc = tf.keras.layers.Dense(units)\n",
        "        self.w_com = tf.keras.layers.Dense(1)\n",
        "\n",
        "    def call(self, h_enc, h_dec):\n",
        "        # h_enc shape: [batch x length x units]\n",
        "        # h_dec shape: [batch x units]\n",
        "\n",
        "        h_enc = self.w_enc(h_enc)\n",
        "        h_dec = tf.expand_dims(h_dec, 1)\n",
        "        h_dec = self.w_dec(h_dec)\n",
        "\n",
        "        score = self.w_com(tf.nn.tanh(h_dec + h_enc))\n",
        "\n",
        "        attn = tf.nn.softmax(score, axis=1)\n",
        "\n",
        "        context_vec = attn * h_enc\n",
        "        context_vec = tf.reduce_sum(context_vec, axis=1)\n",
        "\n",
        "        return context_vec, attn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e5dbe1b7",
      "metadata": {
        "id": "e5dbe1b7"
      },
      "outputs": [],
      "source": [
        "class Encoder(tf.keras.Model):\n",
        "    def __init__(self, vocab_size, embedding_dim, enc_units):\n",
        "        super(Encoder, self).__init__()\n",
        "\n",
        "        self.enc_units = enc_units\n",
        "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "        self.gru = tf.keras.layers.GRU(enc_units,\n",
        "                                       return_sequences=True)\n",
        "\n",
        "    def call(self, x):\n",
        "        out = self.embedding(x)\n",
        "        out = self.gru(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "class Decoder(tf.keras.Model):\n",
        "    def __init__(self, vocab_size, embedding_dim, dec_units):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.dec_units = dec_units\n",
        "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "        self.gru = tf.keras.layers.GRU(dec_units,\n",
        "                                       return_sequences=True,\n",
        "                                       return_state=True)\n",
        "        self.fc = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "        self.attention = BahdanauAttention(self.dec_units)\n",
        "\n",
        "    def call(self, x, h_dec, enc_out):\n",
        "        context_vec, attn = self.attention(enc_out, h_dec)\n",
        "\n",
        "        out = self.embedding(x)\n",
        "        out = tf.concat([tf.expand_dims(context_vec, 1), out], axis=-1)\n",
        "\n",
        "        out, h_dec = self.gru(out)\n",
        "        out = tf.reshape(out, (-1, out.shape[2]))\n",
        "        out = self.fc(out)\n",
        "\n",
        "        return out, h_dec, attn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "40223615",
      "metadata": {
        "id": "40223615",
        "outputId": "d55f5a47-0f06-43bd-c6b7-e4a82faf5198"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Encoder Output: (64, 30, 1024)\n",
            "Decoder Output: (64, 13921)\n",
            "Decoder Hidden State: (64, 1024)\n",
            "Attention: (64, 30, 1)\n"
          ]
        }
      ],
      "source": [
        "BATCH_SIZE     = 64\n",
        "SRC_VOCAB_SIZE = len(enc_tokenizer.index_word) + 1\n",
        "TGT_VOCAB_SIZE = len(dec_tokenizer.index_word) + 1\n",
        "\n",
        "units         = 1024\n",
        "embedding_dim = 512\n",
        "\n",
        "encoder = Encoder(SRC_VOCAB_SIZE, embedding_dim, units)\n",
        "decoder = Decoder(TGT_VOCAB_SIZE, embedding_dim, units)\n",
        "\n",
        "# sample input\n",
        "sequence_len = 30\n",
        "\n",
        "sample_enc = tf.random.uniform((BATCH_SIZE, sequence_len))\n",
        "sample_output = encoder(sample_enc)\n",
        "\n",
        "print ('Encoder Output:', sample_output.shape)\n",
        "\n",
        "sample_state = tf.random.uniform((BATCH_SIZE, units))\n",
        "\n",
        "sample_logits, h_dec, attn = decoder(tf.random.uniform((BATCH_SIZE, 1)),\n",
        "                                     sample_state, sample_output)\n",
        "\n",
        "print ('Decoder Output:', sample_logits.shape)\n",
        "print ('Decoder Hidden State:', h_dec.shape)\n",
        "print ('Attention:', attn.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c66cfc39",
      "metadata": {
        "id": "c66cfc39",
        "outputId": "d9602293-747c-4e64-efa8-10f7b48b3d7a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "슝~\n"
          ]
        }
      ],
      "source": [
        "optimizer = tf.keras.optimizers.Adam()\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits=True, reduction='none')\n",
        "\n",
        "def loss_function(real, pred):\n",
        "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "    loss = loss_object(real, pred)\n",
        "\n",
        "    mask = tf.cast(mask, dtype=loss.dtype)\n",
        "    loss *= mask\n",
        "\n",
        "    return tf.reduce_mean(loss)\n",
        "\n",
        "print(\"슝~\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "08c7e3c8",
      "metadata": {
        "id": "08c7e3c8",
        "outputId": "f5ade77b-3daf-43e2-9fab-168101a9ff8d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "슝~\n"
          ]
        }
      ],
      "source": [
        "@tf.function\n",
        "def train_step(src, tgt, encoder, decoder, optimizer, dec_tok):\n",
        "    bsz = src.shape[0]\n",
        "    loss = 0\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "        enc_out = encoder(src)\n",
        "        h_dec = enc_out[:, -1]\n",
        "\n",
        "        dec_src = tf.expand_dims([dec_tok.word_index['<start>']] * bsz, 1)\n",
        "\n",
        "        for t in range(1, tgt.shape[1]):\n",
        "            pred, h_dec, _ = decoder(dec_src, h_dec, enc_out)\n",
        "\n",
        "            loss += loss_function(tgt[:, t], pred)\n",
        "            dec_src = tf.expand_dims(tgt[:, t], 1)\n",
        "\n",
        "    batch_loss = (loss / int(tgt.shape[1]))\n",
        "\n",
        "    variables = encoder.trainable_variables + decoder.trainable_variables\n",
        "    gradients = tape.gradient(loss, variables)\n",
        "    optimizer.apply_gradients(zip(gradients, variables))\n",
        "\n",
        "    return batch_loss\n",
        "\n",
        "print(\"슝~\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ea54ace8",
      "metadata": {
        "id": "ea54ace8",
        "outputId": "c8e03455-1d8a-471a-a921-9147784964ae"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch  1: 100%|██████████| 375/375 [06:55<00:00,  1.11s/it, Loss 1.3616]\n",
            "Test Epoch  1: 100%|██████████| 94/94 [01:10<00:00,  1.34it/s, Test Loss 1.3239]\n",
            "Epoch  2: 100%|██████████| 375/375 [05:47<00:00,  1.08it/s, Loss 1.3404]\n",
            "Test Epoch  2: 100%|██████████| 94/94 [00:32<00:00,  2.85it/s, Test Loss 1.3310]\n",
            "Epoch  3: 100%|██████████| 375/375 [05:46<00:00,  1.08it/s, Loss 1.3422]\n",
            "Test Epoch  3: 100%|██████████| 94/94 [00:33<00:00,  2.85it/s, Test Loss 1.3338]\n",
            "Epoch  4: 100%|██████████| 375/375 [05:47<00:00,  1.08it/s, Loss 1.3425]\n",
            "Test Epoch  4: 100%|██████████| 94/94 [00:33<00:00,  2.85it/s, Test Loss 1.3394]\n",
            "Epoch  5: 100%|██████████| 375/375 [05:46<00:00,  1.08it/s, Loss 1.3412]\n",
            "Test Epoch  5: 100%|██████████| 94/94 [00:33<00:00,  2.85it/s, Test Loss 1.3359]\n",
            "Epoch  6: 100%|██████████| 375/375 [05:47<00:00,  1.08it/s, Loss 1.3034]\n",
            "Test Epoch  6: 100%|██████████| 94/94 [00:33<00:00,  2.83it/s, Test Loss 1.2372]\n",
            "Epoch  7: 100%|██████████| 375/375 [05:46<00:00,  1.08it/s, Loss 1.2324]\n",
            "Test Epoch  7: 100%|██████████| 94/94 [00:33<00:00,  2.83it/s, Test Loss 1.2043]\n",
            "Epoch  8: 100%|██████████| 375/375 [05:46<00:00,  1.08it/s, Loss 1.1967]\n",
            "Test Epoch  8: 100%|██████████| 94/94 [00:33<00:00,  2.84it/s, Test Loss 1.1781]\n",
            "Epoch  9: 100%|██████████| 375/375 [05:47<00:00,  1.08it/s, Loss 1.1609]\n",
            "Test Epoch  9: 100%|██████████| 94/94 [00:33<00:00,  2.82it/s, Test Loss 1.1449]\n",
            "Epoch 10: 100%|██████████| 375/375 [05:47<00:00,  1.08it/s, Loss 1.1258]\n",
            "Test Epoch 10: 100%|██████████| 94/94 [00:33<00:00,  2.84it/s, Test Loss 1.1214]\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "# Define eval_step\n",
        "\n",
        "@tf.function\n",
        "def eval_step(src, tgt, encoder, decoder, dec_tok):\n",
        "    bsz = src.shape[0]\n",
        "    loss = 0\n",
        "\n",
        "    enc_out = encoder(src)\n",
        "\n",
        "    h_dec = enc_out[:, -1]\n",
        "\n",
        "    dec_src = tf.expand_dims([dec_tok.word_index['<start>']] * bsz, 1)\n",
        "\n",
        "    for t in range(1, tgt.shape[1]):\n",
        "        pred, h_dec, _ = decoder(dec_src, h_dec, enc_out)\n",
        "\n",
        "        loss += loss_function(tgt[:, t], pred)\n",
        "        dec_src = tf.expand_dims(tgt[:, t], 1)\n",
        "\n",
        "    batch_loss = (loss / int(tgt.shape[1]))\n",
        "\n",
        "    return batch_loss\n",
        "\n",
        "\n",
        "# Training Process\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "EPOCHS = 10\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    total_loss = 0\n",
        "\n",
        "    idx_list = list(range(0, enc_train.shape[0], BATCH_SIZE))\n",
        "    random.shuffle(idx_list)\n",
        "    t = tqdm(idx_list)\n",
        "\n",
        "    for (batch, idx) in enumerate(t):\n",
        "        batch_loss = train_step(enc_train[idx:idx+BATCH_SIZE],\n",
        "                                dec_train[idx:idx+BATCH_SIZE],\n",
        "                                encoder,\n",
        "                                decoder,\n",
        "                                optimizer,\n",
        "                                dec_tokenizer)\n",
        "\n",
        "        total_loss += batch_loss\n",
        "\n",
        "        t.set_description_str('Epoch %2d' % (epoch + 1))\n",
        "        t.set_postfix_str('Loss %.4f' % (total_loss.numpy() / (batch + 1)))\n",
        "\n",
        "    test_loss = 0\n",
        "\n",
        "    idx_list = list(range(0, enc_val.shape[0], BATCH_SIZE))\n",
        "    random.shuffle(idx_list)\n",
        "    t = tqdm(idx_list)\n",
        "\n",
        "    for (test_batch, idx) in enumerate(t):\n",
        "        test_batch_loss = eval_step(enc_val[idx:idx+BATCH_SIZE],\n",
        "                                    dec_val[idx:idx+BATCH_SIZE],\n",
        "                                    encoder,\n",
        "                                    decoder,\n",
        "                                    dec_tokenizer)\n",
        "\n",
        "        test_loss += test_batch_loss\n",
        "\n",
        "        t.set_description_str('Test Epoch %2d' % (epoch + 1))\n",
        "        t.set_postfix_str('Test Loss %.4f' % (test_loss.numpy() / (test_batch + 1)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fdbe4290",
      "metadata": {
        "id": "fdbe4290",
        "outputId": "fef10123-986e-4d43-d7c6-9ba029b87c44"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch  1: 100%|██████████| 375/375 [05:47<00:00,  1.08it/s, Loss 1.0925]\n",
            "Epoch  2: 100%|██████████| 375/375 [05:47<00:00,  1.08it/s, Loss 1.0958]\n",
            "Epoch  3: 100%|██████████| 375/375 [05:47<00:00,  1.08it/s, Loss 1.0915]\n",
            "Epoch  4: 100%|██████████| 375/375 [05:46<00:00,  1.08it/s, Loss 1.0622]\n",
            "Epoch  5: 100%|██████████| 375/375 [05:46<00:00,  1.08it/s, Loss 1.0435]\n",
            "Epoch  6: 100%|██████████| 375/375 [05:46<00:00,  1.08it/s, Loss 1.0261]\n",
            "Epoch  7: 100%|██████████| 375/375 [05:46<00:00,  1.08it/s, Loss 1.0112]\n",
            "Epoch  8: 100%|██████████| 375/375 [05:47<00:00,  1.08it/s, Loss 1.0094]\n",
            "Epoch  9: 100%|██████████| 375/375 [05:46<00:00,  1.08it/s, Loss 0.9968]\n",
            "Epoch 10: 100%|██████████| 375/375 [05:47<00:00,  1.08it/s, Loss 1.0415]\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm    # tqdm\n",
        "import random\n",
        "\n",
        "EPOCHS = 10\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    total_loss = 0\n",
        "\n",
        "    idx_list = list(range(0, enc_train.shape[0], BATCH_SIZE))\n",
        "    random.shuffle(idx_list)\n",
        "    t = tqdm(idx_list)    # tqdm\n",
        "\n",
        "    for (batch, idx) in enumerate(t):\n",
        "        batch_loss = train_step(enc_train[idx:idx+BATCH_SIZE],\n",
        "                                dec_train[idx:idx+BATCH_SIZE],\n",
        "                                encoder,\n",
        "                                decoder,\n",
        "                                optimizer,\n",
        "                                dec_tokenizer)\n",
        "\n",
        "        total_loss += batch_loss\n",
        "\n",
        "        t.set_description_str('Epoch %2d' % (epoch + 1))    # tqdm\n",
        "        t.set_postfix_str('Loss %.4f' % (total_loss.numpy() / (batch + 1)))    # tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "996992fc",
      "metadata": {
        "id": "996992fc",
        "outputId": "6b1e5fa6-8a0a-4645-d817-3488c88c59fd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([4732,  355,  118,   30,   11,  177,    2,  101,   70,    3,    4,\n",
              "         22,   60,   24,   21,   71,   59,   13, 1159,    5,  306,   22,\n",
              "         58,  175,    1,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
              "      dtype=int32)"
            ]
          },
          "execution_count": 60,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "kor_train[1]\n",
        "\n",
        "\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "\n",
        "mec.morphs(sentence)\n",
        "\n",
        "# X_mec_test[:3]\n",
        "kor_tokenizer = Tokenizer()\n",
        "kor_tokenizer.fit_on_texts(X_mec_test)\n",
        "kor_tensor = tokenizer_mec.texts_to_sequences(X_mec_test)\n",
        "kor_tensor = tf.keras.preprocessing.sequence.pad_sequences(kor_tensor, padding='post')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "879b021e",
      "metadata": {
        "id": "879b021e"
      },
      "outputs": [],
      "source": [
        "def evaluate(sentence, encoder, decoder):\n",
        "    attention = np.zeros((dec_train.shape[-1], enc_train.shape[-1]))\n",
        "\n",
        "    sentence = preprocess_sentence(sentence)\n",
        "    inputs = enc_tokenizer.texts_to_sequences([sentence.split()])\n",
        "    inputs = tf.keras.preprocessing.sequence.pad_sequences(inputs,\n",
        "                                                           maxlen=enc_train.shape[-1],\n",
        "                                                           padding='post')\n",
        "\n",
        "    result = ''\n",
        "\n",
        "    enc_out = encoder(inputs)\n",
        "\n",
        "    dec_hidden = enc_out[:, -1]\n",
        "    dec_input = tf.expand_dims([dec_tokenizer.word_index['<start>']], 0)\n",
        "\n",
        "    for t in range(dec_train.shape[-1]):\n",
        "        predictions, dec_hidden, attention_weights = decoder(dec_input,\n",
        "                                                             dec_hidden,\n",
        "                                                             enc_out)\n",
        "\n",
        "        attention_weights = tf.reshape(attention_weights, (-1, ))\n",
        "        attention[t] = attention_weights.numpy()\n",
        "\n",
        "        predicted_id = \\\n",
        "        tf.argmax(tf.math.softmax(predictions, axis=-1)[0]).numpy()\n",
        "\n",
        "        result += dec_tokenizer.index_word[predicted_id] + ' '\n",
        "\n",
        "        if dec_tokenizer.index_word[predicted_id] == '<end>':\n",
        "            return result, sentence, attention\n",
        "\n",
        "        dec_input = tf.expand_dims([predicted_id], 0)\n",
        "\n",
        "    return result, sentence, attention\n",
        "\n",
        "\n",
        "def plot_attention(attention, sentence, predicted_sentence):\n",
        "    fig = plt.figure(figsize=(10,10))\n",
        "    ax = fig.add_subplot(1, 1, 1)\n",
        "    ax.matshow(attention, cmap='viridis')\n",
        "\n",
        "    fontdict = {'fontsize': 14}\n",
        "\n",
        "    ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
        "    ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
        "\n",
        "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def translate(sentence, encoder, decoder):\n",
        "    result, sentence, attention = evaluate(sentence, encoder, decoder)\n",
        "\n",
        "    print('Input: %s' % (sentence))\n",
        "    print('Predicted translation: {}'.format(result))\n",
        "\n",
        "    attention = attention[:len(result.split()), :len(sentence.split())]\n",
        "    plot_attention(attention, sentence.split(), result.split(' '))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fdd4b7d5",
      "metadata": {
        "id": "fdd4b7d5",
        "outputId": "9b834d8d-a95a-41c0-a164-e19e73bbc915"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([ 111,    7,   95,   32, 2680,   23,   20,  146,   83,   18,    1,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
              "      dtype=int32)"
            ]
          },
          "execution_count": 86,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "kor_train[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6a40ea23",
      "metadata": {
        "id": "6a40ea23"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "60f27d58",
      "metadata": {
        "id": "60f27d58",
        "outputId": "d2fd8f55-2705-402b-c475-6e95abf630ca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input: 글쎄요 , 저희는 트럭 한 대에 5 , 000개의 제품을 가지고 있습니다 .\n",
            "Predicted translation: i m the company . <end> \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_118/601835555.py:45: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
            "  ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
            "/tmp/ipykernel_118/601835555.py:46: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
            "  ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# translate(\"이거 뭘 하든 같은 단어만 나올 삘인데?\", encoder, decoder)\n",
        "plt.rcParams[\"font.family\"] = \"NanumGothic\" #맑은 고딕으로 폰트 변경\n",
        "str_txt = enc_corpus[75]\n",
        "translate(str_txt, encoder, decoder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5cda257e",
      "metadata": {
        "id": "5cda257e",
        "outputId": "97495324-597d-445e-895e-661618dd17c6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input: 이건 제대로 되는건지 잘 모르겠네요\n",
            "Predicted translation: the company . <end> \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_76/3675406126.py:45: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
            "  ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
            "/tmp/ipykernel_76/3675406126.py:46: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
            "  ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input: 안녕하세요 여러분 제가 질문이 있는데 이게 맞는지 모르겠어요\n",
            "Predicted translation: hello , i have a company . <end> \n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.rcParams[\"font.family\"] = \"NanumGothic\" #맑은 고딕으로 폰트 변경\n",
        "translate(\"이건 제대로 되는건지 잘 모르겠네요\", encoder, decoder)\n",
        "translate(\"안녕하세요 여러분 제가 질문이 있는데 이게 맞는지 모르겠어요\", encoder, decoder)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d56b1610",
      "metadata": {
        "id": "d56b1610"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "61b57688",
      "metadata": {
        "id": "61b57688"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "88dfa469",
      "metadata": {
        "id": "88dfa469"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8bd214c7",
      "metadata": {
        "id": "8bd214c7",
        "outputId": "f7a12c49-f251-479f-8c31-b1d076bf6cc0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/3750 [01:49<?, ?it/s]\n"
          ]
        },
        {
          "ename": "ResourceExhaustedError",
          "evalue": " OOM when allocating tensor with shape[1024,33434] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node gradient_tape/decoder/dense/MatMul_81 (defined at tmp/ipykernel_31/3221489718.py:22) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_step_167762]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node gradient_tape/decoder/dense/MatMul_81:\n decoder/Reshape_51 (defined at tmp/ipykernel_31/285261603.py:20)\n\nFunction call stack:\ntrain_step\n",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipykernel_31/1295518775.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         batch_loss = train_step(kor_train[idx:idx+BATCH_SIZE],\n\u001b[0m\u001b[1;32m     15\u001b[0m                                 \u001b[0meng_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m                                 \u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    948\u001b[0m         \u001b[0;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m         \u001b[0;31m# stateless function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    951\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m       \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiltered_flat_args\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3037\u001b[0m       (graph_function,\n\u001b[1;32m   3038\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 3039\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   3040\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   3041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1961\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1962\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1963\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1964\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1965\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
            "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    589\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 591\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mResourceExhaustedError\u001b[0m:  OOM when allocating tensor with shape[1024,33434] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node gradient_tape/decoder/dense/MatMul_81 (defined at tmp/ipykernel_31/3221489718.py:22) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_step_167762]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node gradient_tape/decoder/dense/MatMul_81:\n decoder/Reshape_51 (defined at tmp/ipykernel_31/285261603.py:20)\n\nFunction call stack:\ntrain_step\n"
          ]
        }
      ],
      "source": [
        "#30만개 문장 돌렸을 경우 발생했던\n",
        "from tqdm import tqdm    # tqdm\n",
        "import random\n",
        "\n",
        "EPOCHS = 10\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    total_loss = 0\n",
        "\n",
        "    idx_list = list(range(0, kor_train.shape[0], BATCH_SIZE))\n",
        "    random.shuffle(idx_list)\n",
        "    t = tqdm(idx_list)    # tqdm\n",
        "\n",
        "    for (batch, idx) in enumerate(t):\n",
        "        batch_loss = train_step(kor_train[idx:idx+BATCH_SIZE],\n",
        "                                eng_train[idx:idx+BATCH_SIZE],\n",
        "                                encoder,\n",
        "                                decoder,\n",
        "                                optimizer,\n",
        "                                eng_tokenizer)\n",
        "\n",
        "        total_loss += batch_loss\n",
        "\n",
        "        t.set_description_str('Epoch %2d' % (epoch + 1))    # tqdm\n",
        "        t.set_postfix_str('Loss %.4f' % (total_loss.numpy() / (batch + 1)))    # tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "831ac87a",
      "metadata": {
        "id": "831ac87a",
        "outputId": "2b2c1d20-5e5d-43b7-9661-860c30bcca09"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch  1: 100%|██████████| 375/375 [06:58<00:00,  1.12s/it, Loss 1.3474]\n",
            "Test Epoch  1: 100%|██████████| 94/94 [01:10<00:00,  1.33it/s, Test Loss 1.3282]\n",
            "Epoch  2: 100%|██████████| 375/375 [05:48<00:00,  1.08it/s, Loss 1.3265]\n",
            "Test Epoch  2: 100%|██████████| 94/94 [00:33<00:00,  2.83it/s, Test Loss 1.3573]\n",
            "Epoch  3: 100%|██████████| 375/375 [05:47<00:00,  1.08it/s, Loss 1.3290]\n",
            "Test Epoch  3: 100%|██████████| 94/94 [00:33<00:00,  2.83it/s, Test Loss 1.3571]\n",
            "Epoch  4: 100%|██████████| 375/375 [05:48<00:00,  1.08it/s, Loss 1.3298]\n",
            "Test Epoch  4: 100%|██████████| 94/94 [00:33<00:00,  2.82it/s, Test Loss 1.3583]\n",
            "Epoch  5: 100%|██████████| 375/375 [05:47<00:00,  1.08it/s, Loss 1.3295]\n",
            "Test Epoch  5: 100%|██████████| 94/94 [00:33<00:00,  2.83it/s, Test Loss 1.3620]\n",
            "Epoch  6: 100%|██████████| 375/375 [05:48<00:00,  1.08it/s, Loss 1.3297]\n",
            "Test Epoch  6: 100%|██████████| 94/94 [00:33<00:00,  2.82it/s, Test Loss 1.3628]\n",
            "Epoch  7: 100%|██████████| 375/375 [05:47<00:00,  1.08it/s, Loss 1.3298]\n",
            "Test Epoch  7: 100%|██████████| 94/94 [00:33<00:00,  2.83it/s, Test Loss 1.3641]\n",
            "Epoch  8: 100%|██████████| 375/375 [05:47<00:00,  1.08it/s, Loss 1.3321]\n",
            "Test Epoch  8: 100%|██████████| 94/94 [00:33<00:00,  2.79it/s, Test Loss 1.5002]\n",
            "Epoch  9: 100%|██████████| 375/375 [05:49<00:00,  1.07it/s, Loss 1.2033]\n",
            "Test Epoch  9: 100%|██████████| 94/94 [00:33<00:00,  2.80it/s, Test Loss 1.1531]\n",
            "Epoch 10: 100%|██████████| 375/375 [05:49<00:00,  1.07it/s, Loss 1.0900]\n",
            "Test Epoch 10: 100%|██████████| 94/94 [00:33<00:00,  2.80it/s, Test Loss 1.0830]\n"
          ]
        }
      ],
      "source": [
        "# Define eval_step\n",
        "#이전기록\n",
        "import random\n",
        "\n",
        "@tf.function\n",
        "def eval_step(src, tgt, encoder, decoder, dec_tok):\n",
        "    bsz = src.shape[0]\n",
        "    loss = 0\n",
        "\n",
        "    enc_out = encoder(src)\n",
        "\n",
        "    h_dec = enc_out[:, -1]\n",
        "\n",
        "    dec_src = tf.expand_dims([dec_tok.word_index['<start>']] * bsz, 1)\n",
        "\n",
        "    for t in range(1, tgt.shape[1]):\n",
        "        pred, h_dec, _ = decoder(dec_src, h_dec, enc_out)\n",
        "\n",
        "        loss += loss_function(tgt[:, t], pred)\n",
        "        dec_src = tf.expand_dims(tgt[:, t], 1)\n",
        "\n",
        "    batch_loss = (loss / int(tgt.shape[1]))\n",
        "\n",
        "    return batch_loss\n",
        "\n",
        "\n",
        "# Training Process\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "EPOCHS = 10\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    total_loss = 0\n",
        "\n",
        "    idx_list = list(range(0, kor_train.shape[0], BATCH_SIZE))\n",
        "    random.shuffle(idx_list)\n",
        "    t = tqdm(idx_list)\n",
        "\n",
        "    for (batch, idx) in enumerate(t):\n",
        "        batch_loss = train_step(kor_train[idx:idx+BATCH_SIZE],\n",
        "                                eng_train[idx:idx+BATCH_SIZE],\n",
        "                                encoder,\n",
        "                                decoder,\n",
        "                                optimizer,\n",
        "                                eng_tokenizer)\n",
        "\n",
        "        total_loss += batch_loss\n",
        "\n",
        "        t.set_description_str('Epoch %2d' % (epoch + 1))\n",
        "        t.set_postfix_str('Loss %.4f' % (total_loss.numpy() / (batch + 1)))\n",
        "\n",
        "    test_loss = 0\n",
        "\n",
        "    idx_list = list(range(0, kor_val.shape[0], BATCH_SIZE))\n",
        "    random.shuffle(idx_list)\n",
        "    t = tqdm(idx_list)\n",
        "\n",
        "    for (test_batch, idx) in enumerate(t):\n",
        "        test_batch_loss = eval_step(kor_val[idx:idx+BATCH_SIZE],\n",
        "                                    eng_val[idx:idx+BATCH_SIZE],\n",
        "                                    encoder,\n",
        "                                    decoder,\n",
        "                                    eng_tokenizer)\n",
        "\n",
        "        test_loss += test_batch_loss\n",
        "\n",
        "        t.set_description_str('Test Epoch %2d' % (epoch + 1))\n",
        "        t.set_postfix_str('Test Loss %.4f' % (test_loss.numpy() / (test_batch + 1)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2462fb07",
      "metadata": {
        "id": "2462fb07"
      },
      "outputs": [],
      "source": [
        "for epoch in range(EPOCHS):\n",
        "    total_loss = 0\n",
        "\n",
        "    idx_list = list(range(0, kor_train.shape[0], BATCH_SIZE))\n",
        "    random.shuffle(idx_list)\n",
        "    t = tqdm(idx_list)\n",
        "\n",
        "    for (batch, idx) in enumerate(t):\n",
        "        batch_loss = train_step(kor_train[idx:idx+BATCH_SIZE],\n",
        "                                eng_train[idx:idx+BATCH_SIZE],\n",
        "                                encoder,\n",
        "                                decoder,\n",
        "                                optimizer,\n",
        "                                eng_tokenizer)\n",
        "\n",
        "        total_loss += batch_loss\n",
        "\n",
        "        t.set_description_str('Epoch %2d' % (epoch + 1))\n",
        "        t.set_postfix_str('Loss %.4f' % (total_loss.numpy() / (batch + 1)))\n",
        "\n",
        "    test_loss = 0\n",
        "\n",
        "    idx_list = list(range(0, kor_val.shape[0], BATCH_SIZE))\n",
        "    random.shuffle(idx_list)\n",
        "    t = tqdm(idx_list)\n",
        "\n",
        "    for (test_batch, idx) in enumerate(t):\n",
        "        test_batch_loss = eval_step(kor_val[idx:idx+BATCH_SIZE],\n",
        "                                    eng_val[idx:idx+BATCH_SIZE],\n",
        "                                    encoder,\n",
        "                                    decoder,\n",
        "                                    eng_tokenizer)\n",
        "\n",
        "        test_loss += test_batch_loss\n",
        "\n",
        "        t.set_description_str('Test Epoch %2d' % (epoch + 1))\n",
        "        t.set_postfix_str('Test Loss %.4f' % (test_loss.numpy() / (test_batch + 1)))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}