{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/minsung6333/AIFFEL_Project/blob/main/8_HuggingFace_%E1%84%8F%E1%85%A5%E1%84%89%E1%85%B3%E1%84%90%E1%85%A5%E1%86%B7_%E1%84%91%E1%85%B3%E1%84%85%E1%85%A9%E1%84%8C%E1%85%A6%E1%86%A8%E1%84%90%E1%85%B3_%E1%84%86%E1%85%A1%E1%86%AB%E1%84%83%E1%85%B3%E1%86%AF%E1%84%80%E1%85%B5_%5B%ED%94%84%EB%A1%9C%EC%A0%9D%ED%8A%B8%5D.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# HuggingFace 커스텀 프로젝트 만들기\n",
        "한국어 데이터셋에 도전해보겠습니다.\n",
        "\n",
        "앞서 본 GLUE benchmark의 한국어 버전 KLUE benchmark를 들어보신 적 있나요?\n",
        "\n",
        "GLUE와 마찬가지로 한국어 자연어처리에 대한 이해도를 높이기 위해 만들어진 데이터셋 benchmark입니다. 총 8가지의 데이터셋이 있습니다. 다만 이번 시간에 진행할 프로젝트는 KLUE의 dataset을 활용하는 것이 아닌, model(klue/ber-base)를 활용하여 NSMC(Naver Sentiment Movie Corpus) task를 도전해보겠습니다."
      ],
      "metadata": {
        "id": "b44afSQ3b9JM"
      },
      "id": "b44afSQ3b9JM"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eeb1d206",
      "metadata": {
        "id": "eeb1d206"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "4b6f5eae",
      "metadata": {
        "id": "4b6f5eae"
      },
      "source": [
        "# 1. 라이브러리 버전 확인"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0fc66478",
      "metadata": {
        "id": "0fc66478",
        "outputId": "f2ff5f5d-2369-4b7a-be25-ffa6e85225c6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.6.0\n",
            "1.21.4\n",
            "4.11.3\n",
            "1.14.0\n"
          ]
        }
      ],
      "source": [
        "import tensorflow\n",
        "import numpy\n",
        "import transformers\n",
        "import datasets\n",
        "\n",
        "print(tensorflow.__version__)\n",
        "print(numpy.__version__)\n",
        "print(transformers.__version__)\n",
        "print(datasets.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fc6c9712",
      "metadata": {
        "id": "fc6c9712"
      },
      "source": [
        "# STEP 1. NSMC 데이터 분석 및 Huggingface dataset 구성\n",
        "---\n",
        "데이터셋은 깃허브에서 다운받거나, Huggingface datasets에서 가져올 수 있습니다. 앞에서 배운 방법들을 활용해봅시다!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "72efbffd",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "1d4685cc9eca4d6685a37105030e718e",
            "edf11f97f5a4429f9841ece42a63cf3c",
            "c3ffba8673fd49fb8c079a45e9981d6b",
            "a9c55bac57f941b9b1ed6a8c02fabf90",
            "2d76b5a1b90c4f27ae2b76ba05ff7f18",
            "cd9ba993814b40408af92c1018266128",
            "",
            "7286bd48247743d4851780ffd9b59541"
          ]
        },
        "id": "72efbffd",
        "outputId": "55801027-97e8-4808-e0fe-c764f09c5d3c"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1d4685cc9eca4d6685a37105030e718e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.36k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "edf11f97f5a4429f9841ece42a63cf3c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/807 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using custom data configuration default\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading and preparing dataset nsmc/default (download: 18.62 MiB, generated: 20.90 MiB, post-processed: Unknown size, total: 39.52 MiB) to /aiffel/.cache/huggingface/datasets/nsmc/default/1.1.0/bfd4729bf1a67114e5267e6916b9e4807010aeb238e4a3c2b95fbfa3a014b5f3...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c3ffba8673fd49fb8c079a45e9981d6b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a9c55bac57f941b9b1ed6a8c02fabf90",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/6.33M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2d76b5a1b90c4f27ae2b76ba05ff7f18",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/2.12M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cd9ba993814b40408af92c1018266128",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0 examples [00:00, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0 examples [00:00, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset nsmc downloaded and prepared to /aiffel/.cache/huggingface/datasets/nsmc/default/1.1.0/bfd4729bf1a67114e5267e6916b9e4807010aeb238e4a3c2b95fbfa3a014b5f3. Subsequent calls will reuse this data.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7286bd48247743d4851780ffd9b59541",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['id', 'document', 'label'],\n",
            "        num_rows: 150000\n",
            "    })\n",
            "    test: Dataset({\n",
            "        features: ['id', 'document', 'label'],\n",
            "        num_rows: 50000\n",
            "    })\n",
            "})\n"
          ]
        }
      ],
      "source": [
        "# import datasets\n",
        "from datasets import load_dataset\n",
        "from datasets import list_datasets, load_dataset, list_metrics, load_metric\n",
        "from huggingface_hub.hf_api import HfFolder\n",
        "\n",
        "\n",
        "huggingface_nsmc_dataset = load_dataset('nsmc')\n",
        "print(huggingface_nsmc_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "93e6f7c7",
      "metadata": {
        "id": "93e6f7c7",
        "outputId": "570618bd-b52e-46a5-d117-33a33add25ec"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['id', 'document', 'label']"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train = huggingface_nsmc_dataset['train']\n",
        "cols = train.column_names\n",
        "cols"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0a17b73e",
      "metadata": {
        "id": "0a17b73e",
        "outputId": "6d9c4b07-4fa4-4266-810e-8a0354fab629"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['id', 'document', 'label'],\n",
              "    num_rows: 150000\n",
              "})"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e801ce3c",
      "metadata": {
        "id": "e801ce3c",
        "outputId": "286fea6f-8b42-45a8-ff61-a68b219828cc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['id', 'document', 'label'],\n",
              "    num_rows: 50000\n",
              "})"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test = huggingface_nsmc_dataset['test']\n",
        "test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a596b982",
      "metadata": {
        "id": "a596b982",
        "outputId": "b80c42e6-0cbc-4ee1-ee94-dba74d7a552d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "id : 9976970\n",
            "document : 아 더빙.. 진짜 짜증나네요 목소리\n",
            "label : 0\n",
            "\n",
            "\n",
            "id : 3819312\n",
            "document : 흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나\n",
            "label : 1\n",
            "\n",
            "\n",
            "id : 10265843\n",
            "document : 너무재밓었다그래서보는것을추천한다\n",
            "label : 0\n",
            "\n",
            "\n",
            "id : 9045019\n",
            "document : 교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정\n",
            "label : 0\n",
            "\n",
            "\n",
            "id : 6483659\n",
            "document : 사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 던스트가 너무나도 이뻐보였다\n",
            "label : 1\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for i in range(5):\n",
        "    for col in cols:\n",
        "        print(col, \":\", train[col][i])\n",
        "    print('\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e4477918",
      "metadata": {
        "id": "e4477918",
        "outputId": "1e672688-3dca-484e-933a-af3474c67571"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "150000"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "931d586d",
      "metadata": {
        "id": "931d586d",
        "outputId": "644ca3b4-a04b-488a-a4a7-1217c1cf8402"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "id : 6270596\n",
            "document : 굳 ㅋ\n",
            "label : 1\n",
            "\n",
            "\n",
            "id : 9274899\n",
            "document : GDNTOPCLASSINTHECLUB\n",
            "label : 0\n",
            "\n",
            "\n",
            "id : 8544678\n",
            "document : 뭐야 이 평점들은.... 나쁘진 않지만 10점 짜리는 더더욱 아니잖아\n",
            "label : 0\n",
            "\n",
            "\n",
            "id : 6825595\n",
            "document : 지루하지는 않은데 완전 막장임... 돈주고 보기에는....\n",
            "label : 0\n",
            "\n",
            "\n",
            "id : 6723715\n",
            "document : 3D만 아니었어도 별 다섯 개 줬을텐데.. 왜 3D로 나와서 제 심기를 불편하게 하죠??\n",
            "label : 0\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for i in range(5):\n",
        "    for col in cols:\n",
        "        print(col, \":\", test[col][i])\n",
        "    print('\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0f1fee6f",
      "metadata": {
        "id": "0f1fee6f"
      },
      "source": [
        "- train/test 동일한 형식으로 되어있음\n",
        "- train 150k test 50k로 되어있음"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9fd4aece",
      "metadata": {
        "id": "9fd4aece"
      },
      "source": [
        "# STEP 2. klue/bert-base model 및 tokenizer 불러오기\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2d112441",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "c3ac0709abf34239bf2cb16a3e1c8162",
            "3e6f86414dcf465390a633ff8cafaaea",
            "4a19332a1de44993affbb482af1dde81",
            "89cb00f2326e4cdd93e2eab339ae6077",
            "a144fdcb6cd542b294b1a171b14cda14",
            "16b22da62bf44052b7dbe2f560e7aed0"
          ]
        },
        "id": "2d112441",
        "outputId": "27603b54-b59d-4bfd-84cd-14693bbfe1ca"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c3ac0709abf34239bf2cb16a3e1c8162",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/289 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3e6f86414dcf465390a633ff8cafaaea",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/425 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4a19332a1de44993affbb482af1dde81",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/243k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "89cb00f2326e4cdd93e2eab339ae6077",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/483k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a144fdcb6cd542b294b1a171b14cda14",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/125 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "16b22da62bf44052b7dbe2f560e7aed0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/424M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at klue/bert-base were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at klue/bert-base and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "import transformers\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "\n",
        "model_checkpoint = \"klue/bert-base\"\n",
        "num_labels = 2\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, use_fast=True)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_checkpoint, num_labels=num_labels)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aaab0db0",
      "metadata": {
        "id": "aaab0db0"
      },
      "source": [
        "# STEP 3. 위에서 불러온 tokenizer으로 데이터셋을 전처리하고, model 학습 진행해 보기\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b8fcb996",
      "metadata": {
        "id": "b8fcb996"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "len(train['document'])\n",
        "\n",
        "train_dataset = pd.DataFrame({'id':train['id'],\n",
        "                             'document':train['document'],\n",
        "                             'label':train['label']})\n",
        "\n",
        "test_dataset_none = pd.DataFrame({'id':test['id'],\n",
        "                             'document':test['document'],\n",
        "                             'label':test['label']})\n",
        "\n",
        "# student_card\n",
        "train_dataset[:5]\n",
        "val_dataset = test_dataset_none[:int(len(test_dataset_none)/2)]\n",
        "test_dataset = test_dataset_none[int(len(test_dataset_none)/2):]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ae1316ed",
      "metadata": {
        "id": "ae1316ed",
        "outputId": "3b28d460-9d04-4ffd-b94e-87a7ed9323c6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "150000\n",
            "25000\n",
            "25000\n"
          ]
        }
      ],
      "source": [
        "print(len(train_dataset))\n",
        "print(len(val_dataset))\n",
        "print(len(test_dataset))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2dcd7516",
      "metadata": {
        "id": "2dcd7516",
        "outputId": "274ae739-acc8-4ec8-82f6-775b073ebb64"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>document</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>9976970</td>\n",
              "      <td>아 더빙.. 진짜 짜증나네요 목소리</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3819312</td>\n",
              "      <td>흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10265843</td>\n",
              "      <td>너무재밓었다그래서보는것을추천한다</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9045019</td>\n",
              "      <td>교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6483659</td>\n",
              "      <td>사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149995</th>\n",
              "      <td>6222902</td>\n",
              "      <td>인간이 문제지.. 소는 뭔죄인가..</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149996</th>\n",
              "      <td>8549745</td>\n",
              "      <td>평점이 너무 낮아서...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149997</th>\n",
              "      <td>9311800</td>\n",
              "      <td>이게 뭐요? 한국인은 거들먹거리고 필리핀 혼혈은 착하다?</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149998</th>\n",
              "      <td>2376369</td>\n",
              "      <td>청춘 영화의 최고봉.방황과 우울했던 날들의 자화상</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149999</th>\n",
              "      <td>9619869</td>\n",
              "      <td>한국 영화 최초로 수간하는 내용이 담긴 영화</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>150000 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "              id                                           document  label\n",
              "0        9976970                                아 더빙.. 진짜 짜증나네요 목소리      0\n",
              "1        3819312                  흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나      1\n",
              "2       10265843                                  너무재밓었다그래서보는것을추천한다      0\n",
              "3        9045019                      교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정      0\n",
              "4        6483659  사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...      1\n",
              "...          ...                                                ...    ...\n",
              "149995   6222902                                인간이 문제지.. 소는 뭔죄인가..      0\n",
              "149996   8549745                                      평점이 너무 낮아서...      1\n",
              "149997   9311800                    이게 뭐요? 한국인은 거들먹거리고 필리핀 혼혈은 착하다?      0\n",
              "149998   2376369                        청춘 영화의 최고봉.방황과 우울했던 날들의 자화상      1\n",
              "149999   9619869                           한국 영화 최초로 수간하는 내용이 담긴 영화      0\n",
              "\n",
              "[150000 rows x 3 columns]"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "93756a63",
      "metadata": {
        "id": "93756a63"
      },
      "outputs": [],
      "source": [
        "from datasets import Dataset\n",
        "\n",
        "# DataFrame 데이터를 dict 내부에 list로 변경\n",
        "train_dataset = train_dataset.to_dict(orient='list')\n",
        "val_dataset = val_dataset.to_dict('list')\n",
        "test_dataset = test_dataset.to_dict('list')\n",
        "\n",
        "# Hugging Face dataset으로 변환\n",
        "tf_train_dataset = Dataset.from_dict(train_dataset)\n",
        "tf_val_dataset = Dataset.from_dict(val_dataset)\n",
        "tf_test_dataset = Dataset.from_dict(test_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "369114e2",
      "metadata": {
        "id": "369114e2"
      },
      "outputs": [],
      "source": [
        "from datasets import Dataset, DatasetDict\n",
        "\n",
        "# 분할된 데이터셋을 DatasetDict 형태로 조합\n",
        "hf_dataset_dict = DatasetDict({\n",
        "    'train': tf_train_dataset,\n",
        "    'validation': tf_val_dataset,\n",
        "    'test': tf_test_dataset\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d3549dd7",
      "metadata": {
        "id": "d3549dd7",
        "outputId": "a0fcf7f1-597f-481c-9b60-0c81d76f898c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['id', 'document', 'label'],\n",
              "        num_rows: 150000\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['id', 'document', 'label'],\n",
              "        num_rows: 25000\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['id', 'document', 'label'],\n",
              "        num_rows: 25000\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "hf_dataset_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eaa927f8",
      "metadata": {
        "id": "eaa927f8",
        "outputId": "c79c07e3-8512-417b-bfb0-65609a4570cd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "id : 9976970\n",
            "document : 아 더빙.. 진짜 짜증나네요 목소리\n",
            "label : 0\n",
            "\n",
            "\n",
            "id : 3819312\n",
            "document : 흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나\n",
            "label : 1\n",
            "\n",
            "\n",
            "id : 10265843\n",
            "document : 너무재밓었다그래서보는것을추천한다\n",
            "label : 0\n",
            "\n",
            "\n",
            "id : 9045019\n",
            "document : 교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정\n",
            "label : 0\n",
            "\n",
            "\n",
            "id : 6483659\n",
            "document : 사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 던스트가 너무나도 이뻐보였다\n",
            "label : 1\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# 훈련 데이터셋 확인\n",
        "for i in range(5):\n",
        "    for column in hf_dataset_dict['train'].column_names:\n",
        "        print(column, \":\", hf_dataset_dict['train'][column][i])\n",
        "    print('\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6c90c748",
      "metadata": {
        "id": "6c90c748"
      },
      "outputs": [],
      "source": [
        "# 훈련데이터로부터 샘플을 불러와 토크나이저 적용\n",
        "\n",
        "# 변환 함수 정의\n",
        "def transform(data):\n",
        "    return tokenizer(\n",
        "        data['document'],\n",
        "        truncation=True,\n",
        "        padding='max_length',\n",
        "        max_length = 80,\n",
        "        return_token_type_ids=False,\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e5c30556",
      "metadata": {
        "id": "e5c30556",
        "outputId": "d2d1e772-3767-4ba4-cdcb-cd1b55df1956"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(huggingface_nsmc_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f17b7f0e",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "d3af369ebc4b415e97c006917d49f7ea",
            "aa26665658d442a589ce2466c0c50eab"
          ]
        },
        "id": "f17b7f0e",
        "outputId": "65d38f70-2904-400d-b811-5908066a506b"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d3af369ebc4b415e97c006917d49f7ea",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/150 [00:00<?, ?ba/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "aa26665658d442a589ce2466c0c50eab",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/50 [00:00<?, ?ba/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "hf_dataset = huggingface_nsmc_dataset.map(transform, batched=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "22fea5e7",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "fafb263689bd479e83358b14776ae5e5",
            "829533ea07ed4bef9270ef47fce376d6",
            "f63b025e6e3a43c195121da75587e559"
          ]
        },
        "id": "22fea5e7",
        "outputId": "93108330-59f9-4c2f-f29f-7dfd6bdf783d"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fafb263689bd479e83358b14776ae5e5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/150 [00:00<?, ?ba/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "829533ea07ed4bef9270ef47fce376d6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/25 [00:00<?, ?ba/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f63b025e6e3a43c195121da75587e559",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/25 [00:00<?, ?ba/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "hf_dataset = hf_dataset_dict.map(transform, batched=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4dbb5771",
      "metadata": {
        "id": "4dbb5771",
        "outputId": "8f307d1a-2fec-4572-bc40-9d9c53d1469d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['id', 'document', 'label'],\n",
              "    num_rows: 50000\n",
              "})"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# hf_train_dataset\n",
        "train\n",
        "test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "32d7ab41",
      "metadata": {
        "id": "32d7ab41"
      },
      "outputs": [],
      "source": [
        "# 훈련, 검증, 테스트 데이터셋 분할\n",
        "hf_train_dataset = hf_dataset['train']\n",
        "hf_val_dataset = hf_dataset['validation']\n",
        "hf_test_dataset = hf_dataset['test']\n",
        "\n",
        "# hf_train_dataset = hf_dataset['train']\n",
        "\n",
        "# hf_test_dataset = hf_dataset['test']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a390fd05",
      "metadata": {
        "id": "a390fd05"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from transformers import Trainer, TrainingArguments\n",
        "\n",
        "output_dir = os.getenv('HOME')+'/aiffel/prj'\n",
        "\n",
        "training_arguments = TrainingArguments(\n",
        "    output_dir,                                         # output이 저장될 경로\n",
        "    evaluation_strategy=\"epoch\",           #evaluation하는 빈도\n",
        "    learning_rate = 2e-5,                         #learning_rate\n",
        "    per_device_train_batch_size = 16,   # 각 device 당 batch size\n",
        "    per_device_eval_batch_size = 16,    # evaluation 시에 batch size\n",
        "    num_train_epochs = 3,                     # train 시킬 총 epochs\n",
        "    weight_decay = 0.01,                        # weight decay\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d65f2123",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "2c95036d4ba140ca9ed5c1806af8f785"
          ]
        },
        "id": "d65f2123",
        "outputId": "3cbd6f51-6be7-4ad5-872c-1ef93383bcb4"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2c95036d4ba140ca9ed5c1806af8f785",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.86k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from datasets import load_metric\n",
        "metric = load_metric('glue', 'mrpc')\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    predictions,labels = eval_pred\n",
        "    predictions = np.argmax(predictions, axis=1)\n",
        "    return metric.compute(predictions=predictions, references = labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7299841a",
      "metadata": {
        "id": "7299841a"
      },
      "source": [
        "# STEP 4. Fine-tuning을 통하여 모델 성능(accuarcy) 향상시키기\n",
        "---\n",
        "데이터 전처리, TrainingArguments 등을 조정하여 모델의 정확도를 90% 이상으로 끌어올려봅시다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f7b5eaad",
      "metadata": {
        "id": "f7b5eaad",
        "outputId": "f8daa7f7-dbd8-4283-d3c6-b75df88b5638"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The following columns in the training set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: id, document.\n",
            "***** Running training *****\n",
            "  Num examples = 150000\n",
            "  Num Epochs = 3\n",
            "  Instantaneous batch size per device = 16\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 28125\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='869' max='28125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [  869/28125 03:28 < 1:49:28, 4.15 it/s, Epoch 0.09/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-500\n",
            "Configuration saved in /aiffel/aiffel/prj/checkpoint-500/config.json\n",
            "Model weights saved in /aiffel/aiffel/prj/checkpoint-500/pytorch_model.bin\n"
          ]
        }
      ],
      "source": [
        "trainer = Trainer(\n",
        "    model=model,           # 학습시킬 model\n",
        "    args=training_arguments,           # TrainingArguments을 통해 설정한 arguments\n",
        "    train_dataset=hf_train_dataset,    # training dataset\n",
        "    eval_dataset=hf_val_dataset,       # evaluation dataset\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "105f65ac",
      "metadata": {
        "id": "105f65ac"
      },
      "source": [
        "# STEP 5. Bucketing을 적용하여 학습시키고, STEP 4의 결과와의 비교\n",
        "---\n",
        "- 아래 링크를 바탕으로 bucketing과 dynamic padding이 무엇인지 알아보고, 이들을 적용하여 model을 학습시킵니다.\n",
        "\n",
        "    - Data Collator\n",
        "\n",
        "    - Trainer.TrainingArguments 의 group_by_length\n",
        "\n",
        "- STEP 4에 학습한 결과와 bucketing을 적용하여 학습시킨 결과를 비교해보고, 모델 성능 향상과 훈련 시간 두 가지 측면에서 각각 어떤 이점이 있는지 비교해봅시다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "da4f37ad",
      "metadata": {
        "id": "da4f37ad"
      },
      "outputs": [],
      "source": [
        "# 테스트 데이터로 평가\n",
        "trainer.evaluate(hf_test_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4d2992fe",
      "metadata": {
        "id": "4d2992fe"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9114d99a",
      "metadata": {
        "id": "9114d99a"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}